{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from logging import raiseExceptions\n",
    "from tokenize import Double\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "import numpy as np\n",
    "import meshplot as mp\n",
    "import torch\n",
    "torch.manual_seed(125)\n",
    "import random\n",
    "random.seed(125)\n",
    "import torch_f as torch_f\n",
    "from modelovae import Node, GRASSEncoder, GRASSDecoder, traverseFeatures, deserialize\n",
    "from meshSubplot import sTree, plotTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_gpu = True\n",
    "device = torch.device(\"cuda:0\" if use_gpu and torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def count_fn(f):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        wrapper.count += 1\n",
    "        return f(*args, **kwargs)\n",
    "    wrapper.count = 0\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def traverse(root, tree):\n",
    "       \n",
    "        if root is not None:\n",
    "            traverse(root.left, tree)\n",
    "            tree.append((root.radius, root.data))\n",
    "            traverse(root.right, tree)\n",
    "            return tree\n",
    "\n",
    "def traversem(root):\n",
    "       \n",
    "        if root is not None:\n",
    "            traversem(root.left)\n",
    "            print(root)\n",
    "            traversem(root.right)\n",
    "            return \n",
    "\n",
    "def traverse_2(tree1, tree2, t_l):\n",
    "       \n",
    "        if tree1 is not None:\n",
    "            traverse_2(tree1.left, tree2.left, t_l)\n",
    "            if tree2:\n",
    "                t_l.append((tree1.radius, tree2.radius))\n",
    "                print((tree1.radius, tree2.radius))\n",
    "            else:\n",
    "                t_l.append(tree1.radius)\n",
    "                print((tree1.radius))\n",
    "            traverse_2(tree1.right, tree2, t_l)\n",
    "            return t_l\n",
    "            \n",
    "\n",
    "def traverse_conexiones(root, tree):\n",
    "        \"\"\"\n",
    "        traverse function will print all the node in the tree.\n",
    "        \"\"\"\n",
    "        if root is not None:\n",
    "            traverse_conexiones(root.left, tree)\n",
    "            if root.right is not None:\n",
    "                tree.append((root.data, root.right.data))\n",
    "            if root.left is not None:\n",
    "                tree.append((root.data, root.left.data))\n",
    "            traverse_conexiones(root.right, tree)\n",
    "            return tree\n",
    "\n",
    "\n",
    "@count_fn\n",
    "def createNode(data, radius, position = None, left = None, right = None, cl_prob = None, ce = None, mse=None):\n",
    "        \"\"\"\n",
    "        Utility function to create a node.\n",
    "        \"\"\"\n",
    "        return Node(data, radius, left, right)\n",
    "\n",
    "\n",
    "def read_tree(filename, dir):\n",
    "    #with open('./prof6/' +filename, \"r\") as f:\n",
    "    #with open('./trees/' +filename, \"r\") as f:\n",
    "    #with open('./' +dir +'/' +filename, \"r\") as f:\n",
    "    with open(dir +'/' +filename, \"r\") as f:\n",
    "        byte = f.read() \n",
    "        return byte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_structure_fold(fold, root):\n",
    "    \n",
    "    \n",
    "    def encode_node(node):\n",
    "        \n",
    "        if node is None:\n",
    "            return\n",
    "        \n",
    "        if node.isLeaf():\n",
    "            return fold.add('leafEncoder', node.radius)\n",
    "        else:\n",
    "            left = encode_node(node.left)\n",
    "            right = encode_node(node.right)\n",
    "            if left is not None and right is not None:\n",
    "                return fold.add('bifurcationEncoder', node.radius, right, left)\n",
    "            elif right is not None:\n",
    "                return fold.add('internalEncoder', node.radius, right)\n",
    "            elif left is not None:\n",
    "                return fold.add('internalEncoder', node.radius, left)\n",
    "        \n",
    "\n",
    "    encoding = encode_node(root)\n",
    "    \n",
    "    #return encoding\n",
    "    return fold.add('sampleEncoder', encoding)\n",
    "\n",
    "def encode_structure(root, Grassencoder):\n",
    "        \n",
    "    def encode_node(node, Grassencoder):\n",
    "          \n",
    "        if node is None:\n",
    "            return\n",
    "        if node.is_leaf():\n",
    "            return Grassencoder.leafEncoder(node.radius.reshape(-1,4))\n",
    "        else :\n",
    "            left = encode_node(node.left, Grassencoder)\n",
    "            right = encode_node(node.right, Grassencoder)\n",
    "            if left is not None and right is not None:\n",
    "                return Grassencoder.bifurcationEncoder(node.radius.reshape(-1,4), right, left)\n",
    "            if right is not None:\n",
    "                return Grassencoder.internalEncoder(node.radius.reshape(-1,4), right)\n",
    "            if left is not None:\n",
    "                return Grassencoder.internalEncoder(node.radius.reshape(-1,4), left)\n",
    "\n",
    "    encoding = encode_node(root, Grassencoder)\n",
    "    return encoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef number_nodes(data_loader, batch_size):\\n    n_no = []\\n    qzero = 0\\n    qOne = 0\\n    qtwo = 0\\n    for batch in data_loader:\\n        for tree in batch:\\n            count = []\\n            n = tree.count_nodes(tree, count)\\n            n_no.append(len(n))\\n            li = []\\n            tree.traverseInorderChilds(tree, li)\\n            zero = [a for a in li if a == 0]\\n            one = [a for a in li if a == 1]\\n            two = [a for a in li if a == 2]\\n            qzero += len(zero)\\n            qOne += len(one)\\n            qtwo += len(two)\\n\\n    nprom = np.mean(n_no)\\n    qzero /= len(data_loader)*batch_size\\n    qOne /= len(data_loader)*batch_size\\n    qtwo /= len(data_loader)*batch_size\\n    if round(qzero) == 0:\\n        qzero = 1\\n    if round(qOne) == 0:\\n        qOne = 1\\n    if round(qtwo) == 0:\\n        qtwo = 1\\n    mult = torch.tensor([1/round(qzero),1/round(qOne),1/round(qtwo)], device = device)\\n    return mult\\n    '"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def numerar_nodos(root, count):\n",
    "    if root is not None:\n",
    "        numerar_nodos(root.left, count)\n",
    "        root.data = len(count)\n",
    "        count.append(1)\n",
    "        numerar_nodos(root.right, count)\n",
    "        return \n",
    "\n",
    "\n",
    "def traversefeatures(root, features):\n",
    "       \n",
    "    if root is not None:\n",
    "        traversefeatures(root.left, features)\n",
    "        features.append(root.radius)\n",
    "        traversefeatures(root.right, features)\n",
    "        return features\n",
    "\n",
    "def norm(root, minx, miny, minz, minr, maxx, maxy, maxz, maxr):\n",
    "    \n",
    "    if root is not None:\n",
    "        mx = minx.clone().detach()\n",
    "        my = miny.clone().detach()\n",
    "        mz = minz.clone().detach()\n",
    "        mr = minr.clone().detach()\n",
    "        Mx = maxx.clone().detach()\n",
    "        My = maxy.clone().detach()\n",
    "        Mz = maxz.clone().detach()\n",
    "        Mr = maxr.clone().detach()\n",
    "       \n",
    "        root.radius[0] = (root.radius[0] - minx)/(maxx - minx)\n",
    "        root.radius[1] = (root.radius[1] - miny)/(maxy - miny)\n",
    "        root.radius[2] = (root.radius[2] - minz)/(maxz - minz)\n",
    "        root.radius[3] = (root.radius[3] - minr)/(maxr - minr)\n",
    "        \n",
    "        norm(root.left, mx, my, mz, mr, Mx, My, Mz, Mr)\n",
    "        norm(root.right, mx, my, mz, mr, Mx, My, Mz, Mr)\n",
    "        return \n",
    "\n",
    "def normalize_features(root):\n",
    "    features = []\n",
    "    features = traversefeatures(root, features)\n",
    "    \n",
    "    x = [tensor[0] for tensor in features]\n",
    "    y = [tensor[1] for tensor in features]\n",
    "    z = [tensor[2] for tensor in features]\n",
    "    r = [tensor[3] for tensor in features]\n",
    " \n",
    "    norm(root, min(x), min(y), min(z), min(r), max(x), max(y), max(z), max(r))\n",
    "\n",
    "    return \n",
    "\n",
    "def traversefeatures(root, features):\n",
    "       \n",
    "    if root is not None:\n",
    "        traversefeatures(root.left, features)\n",
    "        features.append(root.radius)\n",
    "        traversefeatures(root.right, features)\n",
    "        return features\n",
    "\n",
    "def calcularLossAtributo(nodo, radio):\n",
    "    if nodo is None:\n",
    "        return\n",
    "    radio = radio.reshape(-1,4)\n",
    "    nodo = nodo.radius.reshape(-1,4)\n",
    "    l2    = nn.MSELoss()\n",
    "   \n",
    "    mse = l2(radio, nodo)\n",
    "    return mse\n",
    "\n",
    "def searchNode(node, key):\n",
    "     \n",
    "    if (node == None):\n",
    "        return False\n",
    " \n",
    "    if (node.data == key):\n",
    "        return node\n",
    "        \n",
    " \n",
    "    \"\"\" then recur on left subtree \"\"\"\n",
    "    res1 = searchNode(node.left, key)\n",
    "    # node found, no need to look further\n",
    "    if res1:\n",
    "        return res1\n",
    " \n",
    "    \"\"\" node is not found in left,\n",
    "    so recur on right subtree \"\"\"\n",
    "    res2 = searchNode(node.right, key)\n",
    "    return res2\n",
    "\n",
    "def getLevelUtil(node, data, level):\n",
    "    if (node == None):\n",
    "        return 0\n",
    " \n",
    "    if (node.data == data):\n",
    "        return level\n",
    " \n",
    "    downlevel = getLevelUtil(node.left, data, level + 1)\n",
    "\n",
    "    if (downlevel != 0):\n",
    "        return downlevel\n",
    " \n",
    "    downlevel = getLevelUtil(node.right, data, level + 1)\n",
    "    return downlevel\n",
    " \n",
    "# Returns level of given data value\n",
    " \n",
    " \n",
    "def getLevel(node, data):\n",
    "    return getLevelUtil(node, data, 1)\n",
    " \n",
    "\n",
    "def set_tree_level(data_loader):\n",
    "    for d in data_loader:\n",
    "        for data in d:\n",
    "            count = []\n",
    "            numerar_nodos(data, count)\n",
    "            c = []\n",
    "            n_nodes = data.count_nodes(data, c)\n",
    "            for x in range(0, len(n_nodes)):\n",
    "                level = getLevel(data, x)\n",
    "                if (level):\n",
    "                    node = searchNode(data, x)\n",
    "                    node.level = getLevel(data, x)\n",
    "                else:\n",
    "                    print(x, \"is not present in tree\")\n",
    "            tree_level = []\n",
    "            data.get_tree_level(data, tree_level)\n",
    "            data.set_tree_level(data, sum(tree_level))\n",
    "\n",
    "def calcularLossEstructura(cl_p, original, mult):\n",
    "        \n",
    "        if original is None:\n",
    "            return\n",
    "        ce = nn.CrossEntropyLoss(weight = mult)\n",
    "\n",
    "        if original.childs() == 0:\n",
    "            vector = [1, 0, 0] \n",
    "        if original.childs() == 1:\n",
    "            vector = [0, 1, 0]\n",
    "        if original.childs() == 2:\n",
    "            vector = [0, 0, 1] \n",
    "\n",
    "\n",
    "        c = ce(cl_p, torch.tensor(vector, device=device, dtype = torch.float).reshape(1, 3))\n",
    "        return c\n",
    "\n",
    "'''\n",
    "def number_nodes(data_loader, batch_size):\n",
    "    n_no = []\n",
    "    qzero = 0\n",
    "    qOne = 0\n",
    "    qtwo = 0\n",
    "    for batch in data_loader:\n",
    "        for tree in batch:\n",
    "            count = []\n",
    "            n = tree.count_nodes(tree, count)\n",
    "            n_no.append(len(n))\n",
    "            li = []\n",
    "            tree.traverseInorderChilds(tree, li)\n",
    "            zero = [a for a in li if a == 0]\n",
    "            one = [a for a in li if a == 1]\n",
    "            two = [a for a in li if a == 2]\n",
    "            qzero += len(zero)\n",
    "            qOne += len(one)\n",
    "            qtwo += len(two)\n",
    "\n",
    "    nprom = np.mean(n_no)\n",
    "    qzero /= len(data_loader)*batch_size\n",
    "    qOne /= len(data_loader)*batch_size\n",
    "    qtwo /= len(data_loader)*batch_size\n",
    "    if round(qzero) == 0:\n",
    "        qzero = 1\n",
    "    if round(qOne) == 0:\n",
    "        qOne = 1\n",
    "    if round(qtwo) == 0:\n",
    "        qtwo = 1\n",
    "    mult = torch.tensor([1/round(qzero),1/round(qOne),1/round(qtwo)], device = device)\n",
    "    return mult\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_collate(batch):\n",
    "    return batch\n",
    "\n",
    "\n",
    "class tDataset(Dataset):\n",
    "    def __init__(self, l, dir, transform=None):\n",
    "        self.names = l\n",
    "        self.transform = transform\n",
    "        self.data = [] #lista con las strings de todos los arboles\n",
    "        for file in self.names:\n",
    "            self.data.append(read_tree(file, dir))\n",
    "        self.trees = []\n",
    "        for tree in self.data:\n",
    "            deserial = deserialize(tree)\n",
    "            #normalize_features(deserial)\n",
    "            self.trees.append(deserial)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.names)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        #file = self.names[idx]\n",
    "        #string = read_tree(file)\n",
    "        tree = self.trees[idx]\n",
    "        return tree\n",
    "\n",
    "batch_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_testing(v, max, decoder, mult, min):\n",
    "    def decode_node(v, max, decoder, mult, min, nbif):\n",
    "\n",
    "        cl = decoder.nodeClassifier(v)\n",
    "        _, label = torch.max(cl, 1)\n",
    "        label = label.data\n",
    "        \n",
    "        \n",
    "        if label == 1 and createNode.count <= max:\n",
    "            #print(\"label 1\")\n",
    "            right, radius = decoder.internalDecoder(v)\n",
    "                \n",
    "            d = createNode(1, radius) \n",
    "            \n",
    "            d.right = decode_node(right, max, decoder, mult, min, nbif = nbif)\n",
    "            return d\n",
    "\n",
    "        elif label == 2 and createNode.count <= max:\n",
    "            #print(\"label 2\")\n",
    "            left, right, radius = decoder.bifurcationDecoder(v)\n",
    "                \n",
    "            d = createNode(1, radius)\n",
    "            \n",
    "            d.right = decode_node(right, max, decoder, mult, min, nbif = nbif+1)\n",
    "            d.left = decode_node(left, max, decoder, mult, min, nbif = nbif+1)\n",
    "        \n",
    "            return d\n",
    "\n",
    "        elif label == 0 : ##output del classifier\n",
    "            #print(\"label 0\")\n",
    "            if nbif >= 2:\n",
    "                #print(\"mayor que min\")\n",
    "                radio = decoder.featureDecoder(v)\n",
    "                return createNode(1,radio)\n",
    "        \n",
    "            else:\n",
    "                #print(\"menor que min\")\n",
    "                left, right, radius = decoder.bifurcationDecoder(v)\n",
    "                d = createNode(1, radius)\n",
    "                d.right = decode_node(right, max, decoder, mult, min, nbif = nbif+1)\n",
    "                d.left = decode_node(left, max, decoder, mult, min, nbif = nbif+1)\n",
    "                return d\n",
    "\n",
    "        '''\n",
    "        elif label == 0 : ##output del classifier\n",
    "            print(\"0\", createNode.count)\n",
    "            radio = decoder.featureDecoder(v)\n",
    "            return createNode(1,radio)  \n",
    "        '''\n",
    "\n",
    "    createNode.count = 0\n",
    "    dec = decode_node (v, max, decoder, mult, min, nbif = 0)\n",
    "\n",
    "    return dec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_testing2(v, max, decoder, mult):\n",
    "    def decode_node(v, max, decoder, mult):\n",
    "        \n",
    "        cl = decoder.nodeClassifier(v)\n",
    "        _, label = torch.max(cl, 1)\n",
    "        label = label.data\n",
    "        \n",
    "        if label == 0 and createNode.count <= max: ##output del classifier\n",
    "           \n",
    "            radio = decoder.featureDecoder(v)\n",
    "            \n",
    "            return createNode(1,radio)\n",
    "\n",
    "        elif label == 1 and createNode.count <= max:\n",
    "       \n",
    "            right, radius = decoder.internalDecoder(v)\n",
    "                \n",
    "            d = createNode(1, radius) \n",
    "            \n",
    "            d.right = decode_node(right, max, decoder, mult)\n",
    "            \n",
    "\n",
    "            return d\n",
    "       \n",
    "        elif label == 2 and createNode.count <= max:\n",
    "            left, right, radius = decoder.bifurcationDecoder(v)\n",
    "                \n",
    "            d = createNode(1, radius)\n",
    "            \n",
    "            d.right = decode_node(right, max, decoder, mult)\n",
    "            d.left = decode_node(left, max, decoder, mult)\n",
    "            \n",
    "           \n",
    "            return d\n",
    "\n",
    "    createNode.count = 0\n",
    "    v = decoder.sample_decoder(v)\n",
    "    dec = decode_node (v, max, decoder, mult)\n",
    "\n",
    "    return dec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance(node1, node2):\n",
    "    \"\"\"\n",
    "    Calculates the Euclidean distance between two nodes\n",
    "    \"\"\"\n",
    "    if node1 is not None and node2 is not None:\n",
    "        dist = ((node1.radius[0]-node2.radius[0])**2 + \n",
    "                (node1.radius[1]-node2.radius[1])**2 + \n",
    "                (node1.radius[2]-node2.radius[2])**2)**0.5\n",
    "    else:\n",
    "        dist = 0\n",
    "    return dist\n",
    "\n",
    "def total_length(root, node, d):\n",
    "    '''\n",
    "    calcula la distancia del primer a ultimo nodo, arbol sin bifurcaciones\n",
    "    '''\n",
    "    if node.left:\n",
    "        total_length(root, node.left, d)\n",
    "    if node.isLeaf():\n",
    "        #d = distance(root, node)\n",
    "        d.append(distance(root, node))\n",
    "        return \n",
    "    if node.right:\n",
    "        total_length(root, node.right, d)\n",
    "\n",
    "def total_path_length(node):\n",
    "    \"\"\"\n",
    "    Calculates the total path length of the tree\n",
    "    \"\"\"\n",
    "    if node is None:\n",
    "        return 0\n",
    "    else:\n",
    "        return distance(node, node.left) + total_path_length(node.left) + distance(node, node.right) + total_path_length(node.right)\n",
    "\n",
    "def tortuosity(root):\n",
    "    \"\"\"\n",
    "    Calculates the tortuosity of the tree\n",
    "    \"\"\"\n",
    "    total_path_length_value = total_path_length(root)\n",
    "    d = []\n",
    "    max_path_length_value = total_length(root,root, d)\n",
    "    return total_path_length_value / d[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 19957\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b91088f3d4b4029a1acd1f881cec49c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Output(), Output()))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "##Decoder\n",
    "a = [1.,1.,1.]\n",
    "mult = torch.Tensor(a)\n",
    "latent_size = 64\n",
    "Grassdecoder = GRASSDecoder(latent_size=latent_size, hidden_size=256, mult = mult.to(device))\n",
    "Grassdecoder = Grassdecoder.to(device)\n",
    "Grassdecoder.eval()\n",
    "\n",
    "checkpoint = torch.load(\"output/AneuriskP15eps02-best-nuevoweight.pth\")\n",
    "#checkpoint = torch.load(\"outputs/modelo-best-nueva.pth\")\n",
    "#checkpoint = torch.load(\"outputs/10arboles.pth\")\n",
    "Grassdecoder.load_state_dict(checkpoint['decoder_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "print(\"epoch\", epoch)\n",
    " \n",
    "\n",
    "i = 0\n",
    "d = None\n",
    "n = 1\n",
    "radios = []\n",
    "with torch.no_grad():\n",
    "    for i in range(2*n):\n",
    "        noise = torch.randn(batch_size, latent_size).to(device)\n",
    "        generated_images = decode_testing2(noise, 100, Grassdecoder, mult)\n",
    "        count = []\n",
    "        numerar_nodos(generated_images, count)\n",
    "        #generated_images.traverseInorder(generated_images)\n",
    "        if d is None:\n",
    "            d = sTree(generated_images, True, c = \"black\", s = [n,2,i])\n",
    "        else:\n",
    "            sTree(generated_images, True, c = \"black\", s = [n,2,i], d=d)\n",
    "          \n",
    "\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'p' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mp\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'p' is not defined"
     ]
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test con input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 33051\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df383a97304e4ddfb9238efe1bed59f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Output(), Output()))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8db75310e54c426dbb73dfc23c76390f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Output(), Output()))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abb08a4419094a5a8c26e1b9f0e9602d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Output(), Output()))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec77af4e09234e6599e7fd674b6d102f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Output(), Output()))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6eda463dd3614319bfde28304df0702a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Output(), Output()))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c63acb8f70145ef87d7b1e37b3295e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Output(), Output()))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcbc5bea730f4e88aa80e123870bf5fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Output(), Output()))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "145d87739ec54acb86424795135eb19a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Output(), Output()))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a71455001832458590c4ff93ce11c8f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Output(), Output()))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2616c80e9f124332bfa9d53c63558eda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Output(), Output()))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#1-2-4\n",
    "#t_list = os.listdir(\"./arboles/p5n/\" )[:2] #+ os.listdir(\"./arboles/p2v/\" )[2:3]\n",
    "t_list = os.listdir(\"resample_Eps02/p10/\" )[:5]\n",
    "dataset = tDataset(t_list, \"resample_Eps02/p10/\")\n",
    "data_loader = DataLoader(dataset, batch_size = batch_size, shuffle=True, collate_fn=my_collate)\n",
    "a = [1.,1.,1.]\n",
    "mult = torch.Tensor(a)\n",
    "\n",
    "#checkpoint = torch.load(\"outputs/server/64.pth\")\n",
    "checkpoint = torch.load(\"outputs/modelo-best-nueva.pth\")\n",
    "#checkpoint = torch.load(\"outputs/10arboles.pth\")\n",
    "#set_tree_level(data_loader)\n",
    "latent_size = 16\n",
    "feature_size = latent_size \n",
    "##Encoder\n",
    "Grassencoder = GRASSEncoder(input_size = 4, feature_size=feature_size, hidden_size=512)\n",
    "Grassencoder = Grassencoder.to(device)\n",
    "\n",
    "##Decoder\n",
    "Grassdecoder = GRASSDecoder(latent_size=latent_size, hidden_size=256, mult = mult.to(device))\n",
    "Grassdecoder = Grassdecoder.to(device)\n",
    "\n",
    "Grassencoder.load_state_dict(checkpoint['encoder_state_dict'])\n",
    "Grassdecoder.load_state_dict(checkpoint['decoder_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "#loss = checkpoint['loss']\n",
    "print(\"epoch\", epoch)\n",
    "Grassencoder.eval()\n",
    "Grassdecoder.eval()\n",
    "\n",
    "i = 0\n",
    "d = None\n",
    "encodeados = []\n",
    "for batch in data_loader:\n",
    "    for input in batch:\n",
    "        enc_fold = torch_f.Fold(device)\n",
    "        enc_fold_nodes = []\n",
    "        enc_fold_nodes.append(encode_structure_fold(enc_fold, input))\n",
    "        enc_fold_nodes = enc_fold.apply(Grassencoder, [enc_fold_nodes])\n",
    "        encoded = enc_fold_nodes[0]\n",
    "        #encoded, kld = torch.chunk(encoded, 2, 1)\n",
    "        encoded = torch.split(encoded, latent_size, 1)\n",
    "        encodeados.append(encoded)\n",
    "        #print(\"encoded\", encoded[0])\n",
    "        decoded = decode_testing(encoded[0], 100, Grassdecoder, mult)\n",
    "        \n",
    "        count = []\n",
    "        numerar_nodos(decoded, count)\n",
    "        c = []\n",
    "        n_nodes = len(input.countNodes(input,c))\n",
    "\n",
    "        if d is None:\n",
    "            d = sTree(input, False, c = \"black\", s = [10,2,i])\n",
    "        else:\n",
    "            sTree(input, False, c = \"black\", s = [10,2,i], d=d)\n",
    "            \n",
    "        #input.traverseInorder(input)\n",
    "        sTree(decoded, True,  s = [10,2,i+1], c = \"black\", d=d)\n",
    "        #print(\"radius\" ,input.radius)\n",
    "        #graph = nx.Graph()\n",
    "        #input.toGraph( graph, 0, False)\n",
    "        #nx.write_gpickle(graph, \"./profundidad10/grafos/\" +str(i)+\".gpickle\" )\n",
    "        i += 2\n",
    "#d.save(\"dplot.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "tDataset.__init__() missing 1 required positional argument: 'dir'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m t_list \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mArteryObjAN175-15_tree.dat\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mArteryObjAN192-4_tree.dat\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mArteryObjAN157-11_tree.dat\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mArteryObjAN172-13_tree.dat\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mArteryObjAN196-6_tree.dat\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mArteryObjAN172-15_tree.dat\u001b[39m\u001b[39m'\u001b[39m, \n\u001b[0;32m      2\u001b[0m \u001b[39m'\u001b[39m\u001b[39mArteryObjAN189-2_tree.dat\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mArteryObjAN174-17_tree.dat\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mArteryObjAN174-9_tree.dat\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mArteryObjAN163-7_tree.dat\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m      3\u001b[0m \u001b[39m#t_list = ['ArteryObjAN175-15_tree.dat', 'ArteryObjAN192-4_tree.dat']\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[39m#t_list = ['ArteryObjAN1-7_tree.dat']\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m dataset \u001b[39m=\u001b[39m tDataset(t_list)\n\u001b[0;32m      6\u001b[0m data_loader \u001b[39m=\u001b[39m DataLoader(dataset, batch_size \u001b[39m=\u001b[39m batch_size, shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, collate_fn\u001b[39m=\u001b[39mmy_collate)\n\u001b[0;32m      7\u001b[0m i\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m\n",
      "\u001b[1;31mTypeError\u001b[0m: tDataset.__init__() missing 1 required positional argument: 'dir'"
     ]
    }
   ],
   "source": [
    "t_list = ['ArteryObjAN175-15_tree.dat', 'ArteryObjAN192-4_tree.dat', 'ArteryObjAN157-11_tree.dat', 'ArteryObjAN172-13_tree.dat', 'ArteryObjAN196-6_tree.dat', 'ArteryObjAN172-15_tree.dat', \n",
    "'ArteryObjAN189-2_tree.dat', 'ArteryObjAN174-17_tree.dat', 'ArteryObjAN174-9_tree.dat', 'ArteryObjAN163-7_tree.dat']\n",
    "#t_list = ['ArteryObjAN175-15_tree.dat', 'ArteryObjAN192-4_tree.dat']\n",
    "#t_list = ['ArteryObjAN1-7_tree.dat']\n",
    "dataset = tDataset(t_list)\n",
    "data_loader = DataLoader(dataset, batch_size = batch_size, shuffle=True, collate_fn=my_collate)\n",
    "i=0\n",
    "d = None\n",
    "for batch in data_loader:\n",
    "    for input in batch:\n",
    "        if d is None:\n",
    "            #d = sTree(input, False, c = \"red\", s = [2,2,i])\n",
    "            d = sTree(input, False, c = \"red\", s = [10,10,i])\n",
    "        else:\n",
    "            sTree(input, False, c = \"red\", s = [10,10,1], d=d)\n",
    "            #sTree(input, False, c = \"red\", s = [2,2,1], d=d)\n",
    "\n",
    "        i += 1\n",
    "#d.save(\"data.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'vm' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n vm ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "plotTree(generated_images, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'vm' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n vm ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "print(generated_images.right.radius)\n",
    "generated_images.radius\n",
    "#print(generated_images.left.radius)\n",
    "#print(generated_images.left.right.radius)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'vm' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n vm ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "plotTree(input, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'vm' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n vm ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "'''\n",
    "def plotTree( root, dec ):\n",
    "    graph = nx.Graph()\n",
    "    root.toGraph( graph, 0, dec)\n",
    "    edges=nx.get_edge_attributes(graph,'procesada')\n",
    "   \n",
    "    p = mp.plot( np.array([ graph.nodes[v]['posicion'] for v in graph.nodes]), shading={'point_size':0.1}, return_plot=True)\n",
    "    print(\"nodes\", graph.nodes)\n",
    "    for arista in graph.edges:\n",
    "        p.add_lines( graph.nodes[arista[0]]['posicion'], graph.nodes[arista[1]]['posicion'])\n",
    "\n",
    "    return \n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'vm' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n vm ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "def getCountAtLevel (node, curr, desired, n):\n",
    "    # If this node doesn't exist, must be zero.\n",
    "    if node is None: \n",
    "        return 0\n",
    "\n",
    "    # If this node is at desired level, must be one.\n",
    "    if curr == desired: \n",
    "        n.append(node)\n",
    "        return n\n",
    "\n",
    "    # Otherwise sum of nodes at that level in left and right sub-trees.\n",
    "    getCountAtLevel (node.left,  curr+1, desired, n)\n",
    "    getCountAtLevel (node.right, curr+1, desired, n)\n",
    "    return n\n",
    "\n",
    "def cr(root):\n",
    "    h = root.height(root)\n",
    "    for i in range(0, h): #i es el nivel del nodo\n",
    "        n = []\n",
    "        #print(\"nodos en nivel \", i, getCountAtLevel(root, 0, i, n))\n",
    "        c = getCountAtLevel(root, 0, i, n)\n",
    "        #print(\"level\", i)\n",
    "        for j in range(len(c)):# j es el j esimo nodo en ese nivel\n",
    "            #c[j].radius = [i*3.+j+i,i*3.-j,i*1.,i*1.]\n",
    "            #c[j].radius = [i*3.+j,i*1.+j,i*1.+j,i*1.]\n",
    "            x = j+1.\n",
    "            y = i+1.\n",
    "            z = 1.\n",
    "            r = 1.\n",
    "            #print(\"i,j\", i, j)\n",
    "            #print(\"radius\", x,y,z,r)\n",
    "            c[j].radius = torch.Tensor([x,y,z,r])\n",
    "            #c[j].radius = [x,y,z,r]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'vm' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n vm ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "cr(input)\n",
    "#input.traverseInorder(input)\n",
    "graph = nx.Graph()\n",
    "input.toGraph( graph, 0, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'vm' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n vm ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "input = Node(1, radius = torch.tensor((1,1,1,0.5), device = device))\n",
    "input.right = Node (2,radius = torch.tensor((1.5, 2, 2, 0.5), device = device))\n",
    "input.right.right = Node(3, radius = torch.tensor((2,2.5,3,0.5), device = device))\n",
    "\n",
    "input.right.right.right = Node(4, radius = torch.tensor((2.5,3,3.5,0.5), device = device))\n",
    "input.right.right.right.right = Node(6, radius = torch.tensor((3,3.2,3.5,0.5), device = device))\n",
    "input.right.right.right.right = Node(10, radius = torch.tensor((3.3,3.2,3.5,0.5), device = device))\n",
    "\n",
    "input.right.right.left = Node(5, radius = torch.tensor((2.5,2.4,2,0.5), device = device))\n",
    "input.right.right.left.right = Node(7, radius = torch.tensor((2.7,2.3,2,0.5), device = device))\n",
    "input.right.right.left.right.right = Node(8, radius = torch.tensor((3.2,2.3,1.9,0.5), device = device))\n",
    "input.right.right.left.right.right.right = Node(9, radius = torch.tensor((3.6,2.3,1.9,0.5), device = device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'vm' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n vm ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "t_list = os.listdir(\"./Trees/\" )[4:5]\n",
    "#t_list = ['ArteryObjAN1-7_tree.dat']\n",
    "print(t_list)\n",
    "dataset = tDataset(t_list, 'Trees')\n",
    "data_loader = DataLoader(dataset, batch_size = batch_size, shuffle=True, collate_fn=my_collate)\n",
    "input = iter(data_loader).next()\n",
    "input\n",
    "input = input[0]\n",
    "cr(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'vm' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n vm ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "plotTree(input, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'vm' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n vm ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "plotTree(input, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'vm' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n vm ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "graph = nx.Graph()\n",
    "input[0].toGraph( graph, 0, False)\n",
    "nx.write_gpickle(graph, \"grafo-overview.gpickle\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'vm' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n vm ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "d = None\n",
    "n = 5\n",
    "for batch in data_loader:\n",
    "    for input in batch:\n",
    "        '''\n",
    "        if d is None:\n",
    "            d = sTree(input, False, c = \"red\", s = [20,2,i])\n",
    "        else:\n",
    "            sTree(input, False, c = \"red\", s = [20,2,i], d=d)\n",
    "            '''\n",
    "        cr(input)\n",
    "        print(input.radius)\n",
    "        #sTree(input, False,  s = [20,2,i+1], c = \"black\", d=d)\n",
    "        serial = input.serialize(input)\n",
    "        file = open(\"./rectas/\" + str(i) +\"-nl.dat\", \"w\")\n",
    "        file.write(serial)\n",
    "        file.close() \n",
    "        i += 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'vm' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n vm ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'vm' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n vm ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "t_list = os.listdir(\"./Trees/\")[50:51]\n",
    "dataset = tDataset(t_list)\n",
    "data_loader = DataLoader(dataset, batch_size = batch_size, shuffle=True, collate_fn=my_collate)\n",
    "\n",
    "\n",
    "for batch in data_loader:\n",
    "    for input in batch:\n",
    "        print(\"input, height\",t_list, input.height(input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'vm' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n vm ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "t_list = os.listdir(\"./Trees/\")[67:68]\n",
    "#t_list = ['ArteryObjAN1-7_tree.dat']\n",
    "dataset = tDataset(t_list)\n",
    "data_loader = DataLoader(dataset, batch_size = batch_size, shuffle=True, collate_fn=my_collate)\n",
    "\n",
    "\n",
    "for batch in data_loader:\n",
    "    for input in batch:\n",
    "        print(\"input, height\",t_list, input.height(input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'vm' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n vm ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
