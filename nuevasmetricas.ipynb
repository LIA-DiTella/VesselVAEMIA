{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial import distance\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from logging import raiseExceptions\n",
    "from tokenize import Double\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "torch.manual_seed(125)\n",
    "import random\n",
    "random.seed(125)\n",
    "import torch_f as torch_f\n",
    "from modelovae import Node, GRASSEncoder, GRASSDecoder, deserialize\n",
    "import seaborn as sns\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MMD Calculation:\n",
    "\n",
    "The function calculate_mmd computes the minimum distance between samples from the real and generated datasets and averages these minimum distances to return the MMD.\n",
    "\n",
    "\n",
    "Coverage Calculation:\n",
    "\n",
    "The function calculate_coverage counts how many real samples have at least one generated sample within a specified threshold and computes the coverage ratio.\n",
    "\n",
    "\n",
    "1-NNA Calculation:\n",
    "\n",
    "The function calculate_1_nna combines both real and generated samples, computes the nearest neighbors, and calculates the accuracy based on how many nearest neighbors match the label of the real samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_gpu = True\n",
    "device = torch.device(\"cuda:0\" if use_gpu and torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_tree(filename, dir):\n",
    "    with open('./' +dir +'/' +filename, \"r\") as f:\n",
    "        byte = f.read() \n",
    "        return byte\n",
    "\n",
    "def numerar_nodos(root, count):\n",
    "    if root is not None:\n",
    "        numerar_nodos(root.left, count)\n",
    "        root.data = len(count)\n",
    "        count.append(1)\n",
    "        numerar_nodos(root.right, count)\n",
    "        return \n",
    "\n",
    "def count_fn(f):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        wrapper.count += 1\n",
    "        return f(*args, **kwargs)\n",
    "    wrapper.count = 0\n",
    "    return wrapper\n",
    "\n",
    "@count_fn\n",
    "def createNode(data, radius,left = None, right = None):\n",
    "        \"\"\"\n",
    "        Utility function to create a node.\n",
    "        \"\"\"\n",
    "        return Node(data, radius, left, right)\n",
    "\n",
    "def count_nodes(self):\n",
    "        \"\"\"Recursively counts the number of nodes in the tree.\"\"\"\n",
    "        count = 1  # Count the current node\n",
    "        if self.left:\n",
    "            count += count_nodes(self.left)  # Count left subtree\n",
    "        if self.right:\n",
    "            count += count_nodes(self.right)  # Count right subtree\n",
    "        return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_testing(v, max, decoder, mult, min):\n",
    "    def decode_node(v, max, decoder, mult, min):\n",
    "\n",
    "        cl = decoder.nodeClassifier(v)\n",
    "        _, label = torch.max(cl, 1)\n",
    "        label = label.data\n",
    "        \n",
    "        \n",
    "        if label == 1 and createNode.count <= max:\n",
    "\n",
    "            right, radius = decoder.internalDecoder(v)\n",
    "                \n",
    "            d = createNode(1, radius) \n",
    "            \n",
    "            d.right = decode_node(right, max, decoder, mult, min)\n",
    "            return d\n",
    "\n",
    "        elif label == 2 and createNode.count <= max:\n",
    "\n",
    "            left, right, radius = decoder.bifurcationDecoder(v)\n",
    "                \n",
    "            d = createNode(1, radius)\n",
    "            \n",
    "            d.right = decode_node(right, max, decoder, mult, min)\n",
    "            d.left = decode_node(left, max, decoder, mult, min)\n",
    "        \n",
    "            return d\n",
    "\n",
    "        elif label == 0 : ##output del classifier\n",
    "     \n",
    "            if createNode.count>min:\n",
    "                #print(\"mayor que min\")\n",
    "                radio = decoder.featureDecoder(v)\n",
    "                return createNode(1,radio)\n",
    "        \n",
    "            else:\n",
    "                #print(\"menor que min\")\n",
    "                right, radius = decoder.internalDecoder(v)\n",
    "                d = createNode(1, radius) \n",
    "                d.right = decode_node(right, max, decoder, mult, min)\n",
    "                return d\n",
    "\n",
    "        '''\n",
    "        elif label == 0 : ##output del classifier\n",
    "            print(\"0\", createNode.count)\n",
    "            radio = decoder.featureDecoder(v)\n",
    "            return createNode(1,radio)  \n",
    "        '''\n",
    "\n",
    "    createNode.count = 0\n",
    "    v = decoder.sample_decoder(v)\n",
    "    dec = decode_node (v, max, decoder, mult, min)\n",
    "\n",
    "    return dec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from scipy.spatial import distance\n",
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "\n",
    "def extract_node_features(tree):\n",
    "    features = []\n",
    "\n",
    "    def traverse(node):\n",
    "        if node is not None:\n",
    "            # Assuming node.radius is a list or array-like with [x, y, z, r]\n",
    "            features.append(node.radius.cpu())\n",
    "            traverse(node.left)\n",
    "            traverse(node.right)\n",
    "\n",
    "    traverse(tree)\n",
    "    return np.array(features)\n",
    "\n",
    "def calculate_mmd_trees(real_trees, generated_trees):\n",
    "    # Extract features from each tree\n",
    "    real_features = [extract_node_features(tree) for tree in real_trees]\n",
    "    generated_features = [extract_node_features(tree) for tree in generated_trees]\n",
    "    mmd_values = []\n",
    "    \n",
    "    # Iterate over each generated tree\n",
    "    for g_features in generated_features:\n",
    "        # Calculate distances from the generated tree to all real trees\n",
    "        distances = []\n",
    "        for r_features in real_features:\n",
    "            # Compute pairwise distances between the current generated tree and a real tree\n",
    "            g_features = g_features.reshape(-1,4)\n",
    "            pairwise_dist = pairwise_distances(g_features, r_features)\n",
    "            # Find the minimum distance to any node in the real tree\n",
    "            min_distance = np.min(pairwise_dist)\n",
    "            distances.append(min_distance)\n",
    "        \n",
    "        # Take the minimum distance across all real trees\n",
    "        mmd_values.append(np.min(distances))\n",
    "\n",
    "    # Average MMD over all generated trees\n",
    "    mmd_value = np.mean(mmd_values)\n",
    "    \n",
    "    return mmd_value\n",
    "\n",
    "\n",
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "def calculate_coverage(real_trees, generated_trees):\n",
    "    \"\"\"\n",
    "    Calculate the Coverage (COV) between real and generated trees.\n",
    "    \n",
    "    Parameters:\n",
    "    - real_trees: List of original trees (reference set).\n",
    "    - generated_trees: List of generated trees (target set).\n",
    "    \n",
    "    Returns:\n",
    "    - coverage: Fraction of real trees matched by generated trees.\n",
    "    \"\"\"\n",
    "    # Extract features for real and generated trees\n",
    "    real_features = [extract_node_features(tree) for tree in real_trees]\n",
    "    generated_features = [extract_node_features(tree).reshape(-1,4) for tree in generated_trees]\n",
    "\n",
    "    # Flatten the lists of features\n",
    "    real_features_flat = np.vstack(real_features)\n",
    "    generated_features_flat = np.vstack(generated_features)\n",
    "\n",
    "    # Compute pairwise distances between generated and real trees\n",
    "    distances = pairwise_distances(generated_features_flat, real_features_flat)\n",
    "\n",
    "    # For each generated tree, find the nearest real tree\n",
    "    nearest_neighbors = np.argmin(distances, axis=1)\n",
    "\n",
    "    # Identify unique real trees that are matched\n",
    "    matched_real_trees = set(nearest_neighbors)\n",
    "\n",
    "    # Calculate coverage\n",
    "    coverage = len(matched_real_trees) / len(real_trees)\n",
    "    \n",
    "    return coverage\n",
    "\n",
    "\n",
    "def calculate_1_nna(real_trees, generated_trees):\n",
    "    \"\"\"\n",
    "    Calculate the 1-Nearest Neighbor Accuracy (1-NNA) between real and generated trees.\n",
    "    \n",
    "    Parameters:\n",
    "    - real_trees: List of original trees (reference set).\n",
    "    - generated_trees: List of generated trees (target set).\n",
    "    \n",
    "    Returns:\n",
    "    - accuracy: 1-NNA accuracy score.\n",
    "    \"\"\"\n",
    "    # Extract features for real and generated trees\n",
    "    real_features = [extract_node_features(tree) for tree in real_trees]\n",
    "    generated_features = [extract_node_features(tree).reshape(-1,4) for tree in generated_trees]\n",
    "\n",
    "    # Flatten the lists of features\n",
    "    real_features_flat = np.vstack(real_features)\n",
    "    generated_features_flat = np.vstack(generated_features)\n",
    "\n",
    "    # Combine real and generated features\n",
    "    combined_features = np.vstack((real_features_flat, generated_features_flat))\n",
    "\n",
    "    # Compute pairwise distances\n",
    "    distances = pairwise_distances(combined_features)\n",
    "\n",
    "    # Leave-one-out nearest neighbor classification\n",
    "    total_correct = 0\n",
    "    total_samples = len(real_trees) + len(generated_trees)\n",
    "\n",
    "    # Calculate for generated trees\n",
    "    for i in range(len(generated_trees)):\n",
    "        # Remove the current generated tree from the combined set\n",
    "        remaining = np.delete(combined_features, len(real_trees) + i, axis=0)\n",
    "        nearest_neighbor_index = np.argmin(distances[len(real_trees) + i, :len(real_trees) + len(generated_trees) - 1])\n",
    "        if nearest_neighbor_index < len(real_trees):\n",
    "            total_correct += 1  # Found nearest neighbor in real trees\n",
    "\n",
    "    # Calculate for real trees\n",
    "    for i in range(len(real_trees)):\n",
    "        # Remove the current real tree from the combined set\n",
    "        remaining = np.delete(combined_features, i, axis=0)\n",
    "        nearest_neighbor_index = np.argmin(distances[i, :len(real_trees) + len(generated_trees) - 1])\n",
    "        if nearest_neighbor_index >= len(real_trees):\n",
    "            total_correct += 1  # Found nearest neighbor in generated trees\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = total_correct / total_samples\n",
    "    \n",
    "    return accuracy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_collate(batch):\n",
    "    return batch\n",
    "\n",
    "\n",
    "class tDataset(Dataset):\n",
    "    def __init__(self, l, dir, transform=None):\n",
    "        self.names = l\n",
    "        self.transform = transform\n",
    "        self.data = [] #lista con las strings de todos los arboles\n",
    "        for file in self.names:\n",
    "            self.data.append(read_tree(file, dir))\n",
    "        self.trees = []\n",
    "\n",
    "        for tree in self.data:\n",
    "            deserial = deserialize(tree)\n",
    "            self.trees.append(deserial)\n",
    "            \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.names)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        #file = self.names[idx]\n",
    "        #string = read_tree(file)\n",
    "        tree = self.trees[idx]\n",
    "        name = self.names[idx]\n",
    "        return tree\n",
    "\n",
    "batch_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_evaluate(real_dataset, n_samples, latent_size, decoder, mult, threshold):\n",
    "    real_trees = real_dataset.trees\n",
    "    generated_trees = []\n",
    "    # Generate synthetic samples\n",
    "    with torch.no_grad():\n",
    "        for _ in range(n_samples):\n",
    "            noise = torch.randn(1, latent_size).to(device)  # Assuming batch size of 1 for each generated sample\n",
    "            generated_tree = decode_testing(noise, 200, decoder, mult, 20)  # Modify this function as needed\n",
    "            count = []\n",
    "            numerar_nodos(generated_tree, count)\n",
    "            generated_trees.append(generated_tree)\n",
    "            #print(count_nodes(generated_tree))\n",
    "\n",
    "\n",
    "    # Calculate metrics\n",
    "    mmd = calculate_mmd_trees(real_trees, generated_trees)\n",
    "    coverage = calculate_coverage(real_trees, generated_trees)\n",
    "    accuracy = calculate_1_nna(real_trees, generated_trees)\n",
    "\n",
    "    return mmd, coverage, accuracy #, coverage, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_11068\\2137478011.py:19: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(\"output/\" + dataset_name + \"-best.pth\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum Matching Distance (MMD): 0.013743375428020954\n",
      "Coverage (COV): 11.75\n",
      "1-Nearest Neighbor Accuracy (1-NNA): 0.01\n"
     ]
    }
   ],
   "source": [
    "dataset_name = \"Intra\"  # Replace with your dataset name\n",
    "p = str(10)\n",
    "eps = str(0)+str(1)\n",
    "d = \"data/paper/\" + dataset_name + \"P\" +p + \"eps\" + eps\n",
    "file_list = os.listdir(d)[:100]\n",
    " \n",
    "#data_loader = DataLoader(dataset, batch_size = batch_size, shuffle=True, collate_fn=my_collate)\n",
    "\n",
    "# Create dataset\n",
    "real_dataset = tDataset(file_list, d)\n",
    "\n",
    "# Initialize decoder\n",
    "a = [1., 1., 1.]\n",
    "mult = torch.Tensor(a).to(device)\n",
    "latent_size = 64\n",
    "Grassdecoder = GRASSDecoder(latent_size=latent_size, hidden_size=256, mult=mult)\n",
    "Grassdecoder = Grassdecoder.to(device)\n",
    "Grassdecoder.eval()\n",
    "checkpoint = torch.load(\"output/\" + dataset_name + \"-best.pth\")\n",
    "Grassdecoder.load_state_dict(checkpoint['decoder_state_dict'])\n",
    "\n",
    "\n",
    "# Generate synthetic trees and evaluate\n",
    "n_samples = 100\n",
    "threshold = 1.5  # Adjust as necessary\n",
    "mmd, coverage, accuracy = generate_and_evaluate(real_dataset, n_samples, latent_size, Grassdecoder, mult, threshold)\n",
    "\n",
    "# Print results\n",
    "print(f\"Minimum Matching Distance (MMD): {mmd}\")\n",
    "print(f\"Coverage (COV): {coverage:.2f}\")\n",
    "print(f\"1-Nearest Neighbor Accuracy (1-NNA): {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation_metrics_3d import lgan_mmd_cov\n",
    "\n",
    "import torch\n",
    "\n",
    "def _pairwise_EMD_CD_trees(ref_trees, sample_trees, batch_size):\n",
    "    \"\"\"\n",
    "    Compute the pairwise Earth Mover's Distance (EMD) and Chamfer Distance (CD) between\n",
    "    reference and sample trees.\n",
    "\n",
    "    Args:\n",
    "    - ref_trees (list[Node]): List of reference trees (real data).\n",
    "    - sample_trees (list[Node]): List of sample trees (synthetic data).\n",
    "    - batch_size (int): Batch size for computations.\n",
    "\n",
    "    Returns:\n",
    "    - M_rs_cd (torch.Tensor): Pairwise Chamfer Distance matrix.\n",
    "    - M_rs_emd (torch.Tensor): Pairwise Earth Mover's Distance matrix.\n",
    "    \"\"\"\n",
    "    num_ref, num_sample = len(ref_trees), len(sample_trees)\n",
    "    M_rs_cd = torch.zeros((num_ref, num_sample))\n",
    "    M_rs_emd = torch.zeros((num_ref, num_sample))\n",
    "\n",
    "    for i, ref_tree in enumerate(ref_trees):\n",
    "        for j, sample_tree in enumerate(sample_trees):\n",
    "            # Calculate Chamfer Distance between the reference and sample tree\n",
    "            M_rs_cd[i, j] = compute_chamfer_distance(ref_tree, sample_tree)\n",
    "\n",
    "            # Calculate Earth Mover's Distance between the reference and sample tree\n",
    "            M_rs_emd[i, j] = compute_earth_mover_distance(ref_tree, sample_tree)\n",
    "\n",
    "    return M_rs_cd, M_rs_emd\n",
    "\n",
    "def compute_chamfer_distance(tree1, tree2):\n",
    "    \"\"\"\n",
    "    Compute Chamfer Distance (CD) between two trees.\n",
    "\n",
    "    Args:\n",
    "    - tree1 (Node): Root node of the first tree.\n",
    "    - tree2 (Node): Root node of the second tree.\n",
    "\n",
    "    Returns:\n",
    "    - cd (float): Chamfer Distance between the two trees.\n",
    "    \"\"\"\n",
    "    nodes1 = extract_tree_nodes(tree1)\n",
    "    nodes2 = extract_tree_nodes(tree2)\n",
    "\n",
    "    # Calculate distance from each node in nodes1 to the closest node in nodes2\n",
    "\n",
    "    dist1 = torch.tensor([min(torch.norm(n1.radius[:3] - n2.radius[0][:3]).item() for n2 in nodes2) for n1 in nodes1])\n",
    "\n",
    "    # Calculate distance from each node in nodes2 to the closest node in nodes1\n",
    "    dist2 = torch.tensor([min(torch.norm(n2.radius[0][:3] - n1.radius[:3]).item() for n1 in nodes1) for n2 in nodes2])\n",
    "\n",
    "    # Chamfer Distance is the mean of these closest distances\n",
    "    cd = (dist1.mean() + dist2.mean()).item()\n",
    "    return cd\n",
    "\n",
    "def compute_earth_mover_distance(tree1, tree2):\n",
    "    \"\"\"\n",
    "    Compute Earth Mover's Distance (EMD) between two trees.\n",
    "\n",
    "    Args:\n",
    "    - tree1 (Node): Root node of the first tree.\n",
    "    - tree2 (Node): Root node of the second tree.\n",
    "\n",
    "    Returns:\n",
    "    - emd (float): Earth Mover's Distance between the two trees.\n",
    "    \"\"\"\n",
    "    nodes1 = extract_tree_nodes(tree1)\n",
    "    nodes2 = extract_tree_nodes(tree2)\n",
    "\n",
    "    # Calculate EMD as the sum of distances of corresponding nodes\n",
    "    emd_distances = [torch.norm(n1.radius[:3] - n2.radius[0][:3]).item() for n1, n2 in zip(nodes1, nodes2)]\n",
    "    emd = sum(emd_distances) / len(emd_distances) if emd_distances else 0.0\n",
    "    return emd\n",
    "\n",
    "def extract_tree_nodes(root):\n",
    "    \"\"\"\n",
    "    Extract all nodes from a binary tree using breadth-first traversal.\n",
    "\n",
    "    Args:\n",
    "    - root (Node): Root node of the tree.\n",
    "\n",
    "    Returns:\n",
    "    - nodes (list[Node]): List of all nodes in the tree.\n",
    "    \"\"\"\n",
    "    nodes = []\n",
    "    queue = [root]\n",
    "    while queue:\n",
    "        current = queue.pop(0)\n",
    "        nodes.append(current)\n",
    "        \n",
    "        # Enqueue left and right children if they exist\n",
    "        if current.left is not None:\n",
    "            queue.append(current.left)\n",
    "        if current.right is not None:\n",
    "            queue.append(current.right)\n",
    "    \n",
    "    return nodes\n",
    "\n",
    "import torch\n",
    "\n",
    "def knn_trees(M_real_real, M_real_synth, M_synth_synth, k=1, sqrt=False):\n",
    "    \"\"\"\n",
    "    Computes the 1-Nearest Neighbor accuracy using precomputed pairwise distances.\n",
    "\n",
    "    Args:\n",
    "    - M_real_real (torch.Tensor): Pairwise distance matrix between real trees (N_real x N_real).\n",
    "    - M_real_synth (torch.Tensor): Pairwise distance matrix between real and synthetic trees (N_real x N_synth).\n",
    "    - M_synth_synth (torch.Tensor): Pairwise distance matrix between synthetic trees (N_synth x N_synth).\n",
    "    - k (int): Number of neighbors to consider.\n",
    "    - sqrt (bool): If True, will take the square root of distances to return to original units.\n",
    "\n",
    "    Returns:\n",
    "    - results (dict): Dictionary with 1-NN accuracy.\n",
    "    \"\"\"\n",
    "    if sqrt:\n",
    "        M_real_real = torch.sqrt(M_real_real)\n",
    "        M_real_synth = torch.sqrt(M_real_synth)\n",
    "        M_synth_synth = torch.sqrt(M_synth_synth)\n",
    "    \n",
    "    # 1-NN accuracy calculation\n",
    "    N_real = M_real_synth.size(0)\n",
    "    N_synth = M_real_synth.size(1)\n",
    "    \n",
    "    # Concatenate distances between real and synthetic trees\n",
    "    distances = torch.cat((M_real_real, M_real_synth), dim=1)\n",
    "    correct = 0\n",
    "\n",
    "    # For each synthetic tree, find the nearest neighbor among real trees\n",
    "    for i in range(N_synth):\n",
    "        nn_index = torch.argmin(M_real_synth[:, i])  # Nearest real tree index for each synthetic tree\n",
    "        if nn_index < N_real:  # If the nearest neighbor is among real trees\n",
    "            correct += 1\n",
    "    \n",
    "    accuracy = correct / float(N_synth)\n",
    "    return {\"acc\": accuracy}\n",
    "\n",
    "\n",
    "def compute_all_metrics_trees(sample_trees, ref_trees, batch_size, logger):\n",
    "    \"\"\"\n",
    "    Computes Minimum Matching Distance (MMD), Coverage, and 1-Nearest Neighbor Accuracy metrics\n",
    "    between sample (synthetic) and reference (real) trees.\n",
    "    \n",
    "    Args:\n",
    "    - sample_trees (list[Node]): Generated synthetic trees.\n",
    "    - ref_trees (list[Node]): Real trees from the dataset.\n",
    "    - batch_size (int): Batch size for metric computation.\n",
    "    - logger (tuple): Logger and output directory for saving logs or intermediate results.\n",
    "    \n",
    "    Returns:\n",
    "    - dict: A dictionary containing calculated metrics:\n",
    "      - \"EMD\": Minimum Matching Distance and Coverage metrics for EMD.\n",
    "      - \"CD\": Minimum Matching Distance and Coverage metrics for CD.\n",
    "      - \"1-NN-CD-acc\": 1-Nearest Neighbor Accuracy based on Chamfer Distance.\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    logger, orig_trees_dir = logger  # Unpack logger and directory for tree data\n",
    "\n",
    "    print(\"Calculating Pairwise EMD and CD distances...\")\n",
    "    # Compute the pairwise Earth Mover's Distance (EMD) and Chamfer Distance (CD)\n",
    "    M_rs_cd, M_rs_emd = _pairwise_EMD_CD_trees(ref_trees, sample_trees, batch_size)\n",
    "\n",
    "    # Calculate EMD-based metrics\n",
    "    res_emd = lgan_mmd_cov(M_rs_emd.t())\n",
    "    results.update({\n",
    "        \"EMD\": res_emd\n",
    "    })\n",
    "\n",
    "    # Calculate CD-based metrics\n",
    "    res_cd = lgan_mmd_cov(M_rs_cd.t())\n",
    "    results.update({\n",
    "        \"CD\": res_cd\n",
    "    })\n",
    "\n",
    "    # Print each metric for verification\n",
    "    for metric, value in results.items():\n",
    "        print(f\"[{metric}] {value}\")\n",
    "\n",
    "    # Calculate 1-Nearest Neighbor (1-NN) Accuracy using Chamfer Distance\n",
    "    print(\"Calculating 1-Nearest Neighbor Accuracy (1-NN-CD)...\")\n",
    "    one_nn_cd_res = knn_trees(M_rs_cd, M_rs_cd, M_rs_cd, 1, sqrt=False)\n",
    "    results.update(\n",
    "        {\"1-NN-CD-acc\": one_nn_cd_res[\"acc\"]}  # Assumes \"acc\" key contains 1-NN accuracy\n",
    "    )\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_11068\\2940608638.py:48: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(f\"output/{dataset_name}-best.pth\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Pairwise EMD and CD distances...\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "# Assuming other necessary imports like the GRASSDecoder and any helper functions\n",
    "\n",
    "def generate_and_evaluate(real_dataset, n_samples, latent_size, decoder, mult, threshold, batch_size, logger):\n",
    "    # Extract real trees from the dataset\n",
    "    real_trees = real_dataset.trees  # Adjust based on how tDataset stores trees\n",
    "    generated_trees = []\n",
    "\n",
    "    # Generate synthetic trees\n",
    "    with torch.no_grad():\n",
    "        for _ in range(n_samples):\n",
    "            noise = torch.randn(1, latent_size).to(device)  # Batch size of 1 per generated sample\n",
    "            generated_tree = decode_testing(noise, 200, decoder, mult, 20)  # Generate a synthetic tree\n",
    "            count = []\n",
    "            numerar_nodos(generated_tree, count)  # Ensure nodes are correctly numbered\n",
    "            generated_trees.append(generated_tree)\n",
    "\n",
    "    # Calculate metrics\n",
    "    results = compute_all_metrics_trees(generated_trees, real_trees, batch_size, logger)\n",
    "\n",
    "    # Extract individual metrics from the results dictionary\n",
    "    mmd = results['EMD']['lgan_mmd']  # Minimum Matching Distance\n",
    "    coverage = results['EMD']['lgan_cov']  # Coverage\n",
    "    accuracy = results.get(\"1-NN-CD-acc\", 0.0)  # 1-Nearest Neighbor Accuracy, default to 0 if missing\n",
    "\n",
    "    return mmd, coverage, accuracy\n",
    "\n",
    "# Main script for generating and evaluating trees\n",
    "dataset_name = \"Intra\"  # Replace with your dataset name\n",
    "p = str(10)\n",
    "eps = str(0) + str(1)\n",
    "d = f\"data/paper/{dataset_name}P{p}eps{eps}\"\n",
    "file_list = os.listdir(d)[:100]\n",
    "\n",
    "# Create dataset\n",
    "real_dataset = tDataset(file_list, d)\n",
    "\n",
    "# Initialize decoder\n",
    "a = [1., 1., 1.]\n",
    "mult = torch.Tensor(a).to(device)\n",
    "latent_size = 64\n",
    "Grassdecoder = GRASSDecoder(latent_size=latent_size, hidden_size=256, mult=mult)\n",
    "Grassdecoder = Grassdecoder.to(device)\n",
    "Grassdecoder.eval()\n",
    "\n",
    "# Load checkpoint\n",
    "checkpoint = torch.load(f\"output/{dataset_name}-best.pth\")\n",
    "Grassdecoder.load_state_dict(checkpoint['decoder_state_dict'])\n",
    "\n",
    "# Set parameters for generation and evaluation\n",
    "n_samples = 100\n",
    "threshold = 1.5  # Adjust if necessary\n",
    "batch_size = 32  # Set batch size for evaluation\n",
    "logger = (None, \"data/logs/\")  # Adjust logger directory if needed\n",
    "\n",
    "# Generate synthetic trees and calculate metrics\n",
    "mmd, coverage, accuracy = generate_and_evaluate(real_dataset, n_samples, latent_size, Grassdecoder, mult, threshold, batch_size, logger)\n",
    "\n",
    "# Print results\n",
    "print(f\"Minimum Matching Distance (MMD): {mmd}\")\n",
    "print(f\"Coverage (COV): {coverage:.2f}\")\n",
    "print(f\"1-Nearest Neighbor Accuracy (1-NNA): {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
