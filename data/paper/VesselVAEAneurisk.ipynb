{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "torch.manual_seed(125)\n",
    "import random\n",
    "random.seed(125)\n",
    "import torch_f as torch_f\n",
    "import modelovae as mv\n",
    "import meshSubplot as ms\n",
    "import wandb\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_gpu = True\n",
    "device = torch.device(\"cuda:0\" if use_gpu and torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encodeStructureFold(fold, root):\n",
    "    '''Folds the tree by depth, so that nodes at the same depth can go in to the \n",
    "    encoder at the same time, reducing computational cost'''\n",
    "    def encodeNode(node):\n",
    "        \n",
    "        if node is None:\n",
    "            return\n",
    "        \n",
    "        if node.isLeaf():\n",
    "            return fold.add('leafEncoder', node.radius)\n",
    "        else:\n",
    "            left = encodeNode(node.left)\n",
    "            right = encodeNode(node.right)\n",
    "            if left is not None and right is not None:\n",
    "                return fold.add('bifurcationEncoder', node.radius, right, left)\n",
    "            elif right is not None:\n",
    "                return fold.add('internalEncoder', node.radius, right)\n",
    "            elif left is not None:\n",
    "                return fold.add('internalEncoder', node.radius, left)\n",
    "        \n",
    "\n",
    "    encoding = encodeNode(root)\n",
    "    return fold.add('sampleEncoder', encoding)\n",
    "\n",
    "def encode_structure(root, Grassencoder):\n",
    "        \n",
    "    def encode_node(node, Grassencoder):\n",
    "          \n",
    "        if node is None:\n",
    "            return\n",
    "        if node.isLeaf():\n",
    "            return Grassencoder.leafEncoder(node.radius.reshape(-1,4))\n",
    "        else :\n",
    "            left = encode_node(node.left, Grassencoder)\n",
    "            right = encode_node(node.right, Grassencoder)\n",
    "            if left is not None and right is not None:\n",
    "                return Grassencoder.bifurcationEncoder(node.radius.reshape(-1,4), right, left)\n",
    "            if right is not None:\n",
    "                return Grassencoder.internalEncoder(node.radius.reshape(-1,4), right)\n",
    "            if left is not None:\n",
    "                return Grassencoder.internalEncoder(node.radius.reshape(-1,4), left)\n",
    "\n",
    "    encoding = encode_node(root, Grassencoder)\n",
    "    return Grassencoder.sampleEncoder(encoding)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def numerar_nodos(root, count):\n",
    "    if root is not None:\n",
    "        numerar_nodos(root.left, count)\n",
    "        root.data = len(count)\n",
    "        count.append(1)\n",
    "        numerar_nodos(root.right, count)\n",
    "        return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_collate(batch):\n",
    "    return batch\n",
    "\n",
    "\n",
    "class tDataset(Dataset):\n",
    "    def __init__(self, l, dir, transform=None):\n",
    "        self.names = l\n",
    "        self.transform = transform\n",
    "        self.data = [] #lista con las strings de todos los arboles\n",
    "        for file in self.names:\n",
    "            self.data.append(mv.read_tree(file, dir))\n",
    "        #\"data\" is a list of all serialized trees, \"trees\" is a list of the binary trees\n",
    "        self.trees = []\n",
    "        for tree in self.data:\n",
    "            deserial = mv.deserialize(tree)\n",
    "            c = []\n",
    "            numerar_nodos(deserial, c)\n",
    "            self.trees.append({deserial: len(c)})\n",
    "            \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.names)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        tree = self.trees[idx]\n",
    "        return tree\n",
    "\n",
    "batch_size = 4"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decodeStructureFoldGrass(fold, v, root):\n",
    "    ''' Decodes the tree in a depth first fashion, grouping nodes at the same depth\n",
    "    in order to reduce computational cost'''\n",
    "\n",
    "    def decodeNode(fold, v, node, flag):\n",
    "        multipl = np.round((node.maxlevel+1-node.level)/node.treelevel, decimals=2)\n",
    "        label = fold.add('nodeClassifier', v)\n",
    "      \n",
    "               \n",
    "        if node.childs() == 1 :\n",
    "            \n",
    "            right, radius = fold.add('internalDecoder', v).split(2)\n",
    "            \n",
    "            if node.right:\n",
    "                nodoSiguiente = node.right\n",
    "            else:\n",
    "                nodoSiguiente = node.left\n",
    "            \n",
    "            child_loss = decodeNode(fold, right, nodoSiguiente, flag = 1)\n",
    "            lossEstructura = fold.add('classifyLossEstimator', label, node)\n",
    "            lossAtributo = fold.add('calcularLossAtributo', node, radius)\n",
    "            \n",
    "           \n",
    "            losse = fold.add('vectorMult', multipl, lossEstructura)\n",
    "            loss = fold.add('vectorAdder', losse, lossAtributo)\n",
    "            loss2 = fold.add('vectorAdder', loss, child_loss)\n",
    "\n",
    "            return loss2\n",
    "        elif node.childs() == 0 : \n",
    "\n",
    "            radius = fold.add('featureDecoder', v)\n",
    "            \n",
    "            lossEstructura = fold.add('classifyLossEstimator', label, node) \n",
    "            lossAtributo = fold.add('calcularLossAtributo', node, radius)\n",
    "    \n",
    "            losse = fold.add('vectorMult', multipl, lossEstructura)\n",
    "            loss =  fold.add('vectorAdder', losse, lossAtributo)   \n",
    "\n",
    "            return loss\n",
    "            \n",
    "        \n",
    "        elif node.childs() == 2 :\n",
    "\n",
    "            left, right, radius = fold.add('bifurcationDecoder', v).split(3)\n",
    "            nodoSiguienteRight = node.right\n",
    "            nodoSiguienteLeft = node.left\n",
    "\n",
    "            if nodoSiguienteRight is not None:\n",
    "                right_loss = decodeNode(fold, right, nodoSiguienteRight, flag = 1)\n",
    "             \n",
    "            if nodoSiguienteLeft is not None:\n",
    "                left_loss  = decodeNode(fold, left, nodoSiguienteLeft, flag = 1)\n",
    "\n",
    "          \n",
    "            \n",
    "            lossEstructura = fold.add('classifyLossEstimator', label, node)\n",
    "            lossAtributo   = fold.add('calcularLossAtributo', node, radius)\n",
    "            losse = fold.add('vectorMult', multipl, lossEstructura)\n",
    "            loss = fold.add('vectorAdder', losse, lossAtributo)\n",
    "            loss2 = fold.add('vectorAdder', loss, right_loss)\n",
    "            loss3 = fold.add('vectorAdder', loss2, left_loss)\n",
    "            return loss3\n",
    "            \n",
    "    v1 = fold.add('sampleDecoder', v)\n",
    "    dec = decodeNode (fold, v1, root, flag = 0)\n",
    "    return dec\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SaveBestModel:\n",
    "    \"\"\"\n",
    "    Class to save the best model while training. If the current epoch's \n",
    "    validation loss is less than the previous least less, then save the\n",
    "    model state.\n",
    "    \"\"\"\n",
    "    def __init__(self, best_valid_loss=float('inf')):\n",
    "        self.best_valid_loss = best_valid_loss\n",
    "        \n",
    "    def __call__(\n",
    "        self, current_valid_loss, \n",
    "        epoch, encoder, decoder, optimizer\n",
    "    ):  \n",
    "        if epoch > 50:\n",
    "            if current_valid_loss < self.best_valid_loss:\n",
    "                self.best_valid_loss = current_valid_loss\n",
    "                #'classifier_state_dict': classifier.state_dict(),\n",
    "                torch.save({\n",
    "                    'epoch': epoch+1,\n",
    "                    'encoder_state_dict': encoder.state_dict(),\n",
    "                    'decoder_state_dict': decoder.state_dict(),\n",
    "                    'loss' : self.best_valid_loss,\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    }, 'output/AneuriskP5eps01-best.pth')\n",
    "\n",
    "class SaveLastModel:\n",
    "    \"\"\"\n",
    "    Class to save the model while training. \n",
    "    \"\"\"  \n",
    "    def __call__( self,  epoch, encoder, decoder, optimizer):\n",
    "        torch.save({\n",
    "            'epoch': epoch+1,\n",
    "            'encoder_state_dict': encoder.state_dict(),\n",
    "            'decoder_state_dict': decoder.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            }, 'output/AneuriskP5eps01-last.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def escalon_beta (e, corte):\n",
    "    l = np.linspace(e,e,corte)\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_Level(tree, n_nodes):\n",
    "    max_level = 0  \n",
    "    for x in range(0, n_nodes):\n",
    "        level = mv.getLevel(tree, x)\n",
    "        if level > max_level:\n",
    "            max_level = level\n",
    "        if (level):\n",
    "            node = mv.searchNode(tree, x)\n",
    "            node.level = mv.getLevel(tree, x)\n",
    "        else:\n",
    "            print(x, \"is not present in tree\")\n",
    "    tree_level = []\n",
    "    tree.getTreeLevel(tree, tree_level)\n",
    "    tree_level = [max_level - nodelevel for nodelevel in tree_level]\n",
    "    tree.setTreeLevel(tree, sum(tree_level))\n",
    "    tree.setMaxLevel(tree, max_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(epochs, data_loader, Grassencoder, Grassdecoder, opt):\n",
    " \n",
    "    save_last_model = SaveLastModel()\n",
    "    save_best_model = SaveBestModel()\n",
    "    train_loss_avg = []\n",
    "    betas = escalon_beta(.001, 400000)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "    \n",
    "        beta = betas[epoch]\n",
    "        train_loss_avg.append(0)\n",
    "\n",
    "        epochTotalLoss = 0\n",
    "        epochReconLoss = 0\n",
    "        epochKLDivLoss = 0\n",
    "        epochKLDivLossBeta = 0\n",
    "\n",
    "        for batch_idx, batch in enumerate(data_loader):            \n",
    "            \n",
    "            enc_fold = torch_f.Fold(device)\n",
    "            \n",
    "            enc_fold_nodes = []     \n",
    "            n_nodes = []\n",
    "            for tree in batch: #example es un arbolito\n",
    "                example = list(tree.keys())[0]\n",
    "                n = tree[example]#[0]\n",
    "                n_nodes.append(n)\n",
    "                enc_fold_nodes.append(encodeStructureFold(enc_fold, example))\n",
    "            \n",
    "            enc_fold_nodes = enc_fold.apply(Grassencoder, [enc_fold_nodes])\n",
    "            \n",
    "            enc_fold_nodes = torch.split(enc_fold_nodes[0], 1, 0)\n",
    "            \n",
    "            dec_fold = torch_f.Fold(device)\n",
    "            dec_fold_nodes = []\n",
    "            kld_fold_nodes = []\n",
    "\n",
    "            for tree, fnode in zip(batch, enc_fold_nodes):\n",
    "                example = list(tree.keys())[0]\n",
    "                root_code, kl_div = torch.chunk(fnode, 2, 1)\n",
    "                dec_fold_nodes.append(decodeStructureFoldGrass(dec_fold, root_code, example))\n",
    "                kld_fold_nodes.append(kl_div)\n",
    "                \n",
    "            total_loss = dec_fold.apply(Grassdecoder, [dec_fold_nodes, kld_fold_nodes])\n",
    "            n_nodes = torch.tensor(n_nodes, device = device)\n",
    "            recon_loss = torch.div(total_loss[0], n_nodes)\n",
    "            recon_loss = recon_loss.sum() / len(batch)               # avg. reconstruction loss per example\n",
    "            \n",
    "            kldiv_loss = []\n",
    "            for element in kld_fold_nodes:\n",
    "                l = torch.sum(element)\n",
    "                kldiv_loss.append(l)\n",
    "           \n",
    "            kldiv_loss = sum(kldiv_loss) / len(batch)\n",
    "           \n",
    "            total_loss = recon_loss +  beta*kldiv_loss/10\n",
    "           \n",
    "            opt.zero_grad()\n",
    "            total_loss.backward()\n",
    "            opt.step()\n",
    "            train_loss_avg[-1] += (total_loss.item())\n",
    "            epochTotalLoss += total_loss.item()\n",
    "            epochReconLoss += recon_loss.item()\n",
    "            epochKLDivLoss += kldiv_loss.item()\n",
    "            epochKLDivLossBeta += beta*kldiv_loss.item()\n",
    "\n",
    "        epochTotalLoss /= len(data_loader)\n",
    "        epochReconLoss /= len(data_loader)\n",
    "        epochKLDivLoss /= len(data_loader)\n",
    "        epochKLDivLossBeta  /= len(data_loader)\n",
    "        \n",
    "        \n",
    "        save_best_model(total_loss, epoch, Grassencoder, Grassdecoder, opt)\n",
    "        if epoch % 10 == 0: \n",
    "            wandb.log({'epoch': epoch+1, 'loss': epochTotalLoss, 'kl_div': epochKLDivLoss, 'kl_div (*beta)': epochKLDivLossBeta, 'recon_loss': epochReconLoss, 'beta': beta})\n",
    "        if epoch % 100 == 0:   \n",
    "            save_last_model(epoch, Grassencoder, Grassdecoder, opt)\n",
    "        if epoch % 100 == 0:\n",
    "            print('Epoch [%d / %d] average reconstruction error: %.10f , kl(*beta): %.10f (%.10f), reconstruction loss: %.10f' % (epoch+1, epochs, epochTotalLoss, epochKLDivLoss, epochKLDivLossBeta, epochReconLoss))\n",
    "    return \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FOR LOOP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total parameters encoder  626560\n",
      "total parameters decoder 379911\n",
      "total parameters 1006471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mpaufeldman\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\User\\Documents\\vesselvaeashish\\VesselVAE\\wandb\\run-20240208_104725-jbvvhupg</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/paufeldman/MIA/runs/jbvvhupg' target=\"_blank\">misunderstood-armadillo-40</a></strong> to <a href='https://wandb.ai/paufeldman/MIA' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/paufeldman/MIA' target=\"_blank\">https://wandb.ai/paufeldman/MIA</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/paufeldman/MIA/runs/jbvvhupg' target=\"_blank\">https://wandb.ai/paufeldman/MIA/runs/jbvvhupg</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1 / 20000] average reconstruction error: 0.1254901195 , kl(*beta): 0.0781754249 (0.0000781754), reconstruction loss: 0.1254823017\n",
      "Epoch [101 / 20000] average reconstruction error: 0.0129980951 , kl(*beta): 10.3199273872 (0.0103199274), reconstruction loss: 0.0119661023\n",
      "Epoch [201 / 20000] average reconstruction error: 0.0080264005 , kl(*beta): 10.0552392006 (0.0100552392), reconstruction loss: 0.0070208765\n",
      "Epoch [301 / 20000] average reconstruction error: 0.0055617110 , kl(*beta): 10.5345419312 (0.0105345419), reconstruction loss: 0.0045082567\n",
      "Epoch [401 / 20000] average reconstruction error: 0.0042761751 , kl(*beta): 10.5278336334 (0.0105278336), reconstruction loss: 0.0032233916\n",
      "Epoch [501 / 20000] average reconstruction error: 0.0039624495 , kl(*beta): 10.1674151802 (0.0101674152), reconstruction loss: 0.0029457079\n",
      "Epoch [601 / 20000] average reconstruction error: 0.0031293580 , kl(*beta): 9.4226463699 (0.0094226464), reconstruction loss: 0.0021870933\n",
      "Epoch [701 / 20000] average reconstruction error: 0.0024002126 , kl(*beta): 9.3738206291 (0.0093738206), reconstruction loss: 0.0014628305\n",
      "Epoch [801 / 20000] average reconstruction error: 0.0025307035 , kl(*beta): 9.6433988380 (0.0096433988), reconstruction loss: 0.0015663636\n",
      "Epoch [901 / 20000] average reconstruction error: 0.0020821152 , kl(*beta): 9.5683615685 (0.0095683616), reconstruction loss: 0.0011252789\n",
      "Epoch [1001 / 20000] average reconstruction error: 0.0021435607 , kl(*beta): 9.8216338730 (0.0098216339), reconstruction loss: 0.0011613973\n",
      "Epoch [1101 / 20000] average reconstruction error: 0.0020504463 , kl(*beta): 9.6087749863 (0.0096087750), reconstruction loss: 0.0010895687\n",
      "Epoch [1201 / 20000] average reconstruction error: 0.0015006146 , kl(*beta): 9.2578329277 (0.0092578329), reconstruction loss: 0.0005748313\n",
      "Epoch [1301 / 20000] average reconstruction error: 0.0014630817 , kl(*beta): 8.8674921989 (0.0088674922), reconstruction loss: 0.0005763324\n",
      "Epoch [1401 / 20000] average reconstruction error: 0.0014853799 , kl(*beta): 8.8204177284 (0.0088204177), reconstruction loss: 0.0006033381\n",
      "Epoch [1501 / 20000] average reconstruction error: 0.0013955997 , kl(*beta): 8.7911701965 (0.0087911702), reconstruction loss: 0.0005164827\n",
      "Epoch [1601 / 20000] average reconstruction error: 0.0012845162 , kl(*beta): 8.1811496162 (0.0081811496), reconstruction loss: 0.0004664012\n",
      "Epoch [1701 / 20000] average reconstruction error: 0.0014964763 , kl(*beta): 8.7626090050 (0.0087626090), reconstruction loss: 0.0006202154\n",
      "Epoch [1801 / 20000] average reconstruction error: 0.0017386114 , kl(*beta): 9.3424760437 (0.0093424760), reconstruction loss: 0.0008043638\n",
      "Epoch [1901 / 20000] average reconstruction error: 0.0012465921 , kl(*beta): 8.2255507660 (0.0082255508), reconstruction loss: 0.0004240370\n",
      "Epoch [2001 / 20000] average reconstruction error: 0.0012909846 , kl(*beta): 8.1388708496 (0.0081388708), reconstruction loss: 0.0004770975\n",
      "Epoch [2101 / 20000] average reconstruction error: 0.0012223786 , kl(*beta): 8.0908739090 (0.0080908739), reconstruction loss: 0.0004132911\n",
      "Epoch [2201 / 20000] average reconstruction error: 0.0011201150 , kl(*beta): 8.0061101913 (0.0080061102), reconstruction loss: 0.0003195040\n",
      "Epoch [2301 / 20000] average reconstruction error: 0.0012315212 , kl(*beta): 8.2670462990 (0.0082670463), reconstruction loss: 0.0004048165\n",
      "Epoch [2401 / 20000] average reconstruction error: 0.0012254114 , kl(*beta): 8.7420990753 (0.0087420991), reconstruction loss: 0.0003512014\n",
      "Epoch [2501 / 20000] average reconstruction error: 0.0013106500 , kl(*beta): 8.9444552231 (0.0089444552), reconstruction loss: 0.0004162045\n",
      "Epoch [2601 / 20000] average reconstruction error: 0.0012164281 , kl(*beta): 7.7179109573 (0.0077179110), reconstruction loss: 0.0004446369\n",
      "Epoch [2701 / 20000] average reconstruction error: 0.0010699656 , kl(*beta): 7.9934426498 (0.0079934426), reconstruction loss: 0.0002706213\n",
      "Epoch [2801 / 20000] average reconstruction error: 0.0011509329 , kl(*beta): 9.0561308670 (0.0090561309), reconstruction loss: 0.0002453198\n",
      "Epoch [2901 / 20000] average reconstruction error: 0.0010782603 , kl(*beta): 7.8010089302 (0.0078010089), reconstruction loss: 0.0002981594\n",
      "Epoch [3001 / 20000] average reconstruction error: 0.0011437457 , kl(*beta): 8.5501750946 (0.0085501751), reconstruction loss: 0.0002887282\n",
      "Epoch [3101 / 20000] average reconstruction error: 0.0010892345 , kl(*beta): 7.9523556137 (0.0079523556), reconstruction loss: 0.0002939989\n",
      "Epoch [3201 / 20000] average reconstruction error: 0.0012701258 , kl(*beta): 8.5731764603 (0.0085731765), reconstruction loss: 0.0004128081\n",
      "Epoch [3301 / 20000] average reconstruction error: 0.0011413448 , kl(*beta): 8.0087569427 (0.0080087569), reconstruction loss: 0.0003404691\n",
      "Epoch [3401 / 20000] average reconstruction error: 0.0010087822 , kl(*beta): 7.8082687187 (0.0078082687), reconstruction loss: 0.0002279553\n",
      "Epoch [3501 / 20000] average reconstruction error: 0.0010580268 , kl(*beta): 8.2266417885 (0.0082266418), reconstruction loss: 0.0002353626\n",
      "Epoch [3601 / 20000] average reconstruction error: 0.0010048780 , kl(*beta): 8.0498430824 (0.0080498431), reconstruction loss: 0.0001998936\n",
      "Epoch [3701 / 20000] average reconstruction error: 0.0009855315 , kl(*beta): 7.5842449188 (0.0075842449), reconstruction loss: 0.0002271070\n",
      "Epoch [3801 / 20000] average reconstruction error: 0.0010430433 , kl(*beta): 8.0713033485 (0.0080713033), reconstruction loss: 0.0002359129\n",
      "Epoch [3901 / 20000] average reconstruction error: 0.0009936522 , kl(*beta): 8.0038337517 (0.0080038338), reconstruction loss: 0.0001932688\n",
      "Epoch [4001 / 20000] average reconstruction error: 0.0009251370 , kl(*beta): 7.8278502083 (0.0078278502), reconstruction loss: 0.0001423520\n",
      "Epoch [4101 / 20000] average reconstruction error: 0.0012022867 , kl(*beta): 8.9134509087 (0.0089134509), reconstruction loss: 0.0003109415\n",
      "Epoch [4201 / 20000] average reconstruction error: 0.0010826611 , kl(*beta): 8.5765893364 (0.0085765893), reconstruction loss: 0.0002250022\n",
      "Epoch [4301 / 20000] average reconstruction error: 0.0010032677 , kl(*beta): 7.5671179771 (0.0075671180), reconstruction loss: 0.0002465558\n",
      "Epoch [4401 / 20000] average reconstruction error: 0.0013338862 , kl(*beta): 8.6321274948 (0.0086321275), reconstruction loss: 0.0004706734\n",
      "Epoch [4501 / 20000] average reconstruction error: 0.0009971133 , kl(*beta): 7.8313744354 (0.0078313744), reconstruction loss: 0.0002139758\n",
      "Epoch [4601 / 20000] average reconstruction error: 0.0009748817 , kl(*beta): 8.1037114716 (0.0081037115), reconstruction loss: 0.0001645105\n",
      "Epoch [4701 / 20000] average reconstruction error: 0.0010748397 , kl(*beta): 7.8598324776 (0.0078598325), reconstruction loss: 0.0002888564\n",
      "Epoch [4801 / 20000] average reconstruction error: 0.0014875616 , kl(*beta): 9.0545882416 (0.0090545882), reconstruction loss: 0.0005821028\n",
      "Epoch [4901 / 20000] average reconstruction error: 0.0008985656 , kl(*beta): 7.5907435989 (0.0075907436), reconstruction loss: 0.0001394912\n",
      "Epoch [5001 / 20000] average reconstruction error: 0.0010085690 , kl(*beta): 7.8990578461 (0.0078990578), reconstruction loss: 0.0002186631\n",
      "Epoch [5101 / 20000] average reconstruction error: 0.0010005445 , kl(*beta): 8.2581726456 (0.0082581726), reconstruction loss: 0.0001747272\n",
      "Epoch [5201 / 20000] average reconstruction error: 0.0009718307 , kl(*beta): 7.9632046318 (0.0079632046), reconstruction loss: 0.0001755102\n",
      "Epoch [5301 / 20000] average reconstruction error: 0.0010928505 , kl(*beta): 8.6607550430 (0.0086607550), reconstruction loss: 0.0002267749\n",
      "Epoch [5401 / 20000] average reconstruction error: 0.0009091666 , kl(*beta): 7.5320240021 (0.0075320240), reconstruction loss: 0.0001559642\n",
      "Epoch [5501 / 20000] average reconstruction error: 0.0008983311 , kl(*beta): 7.6611349487 (0.0076611349), reconstruction loss: 0.0001322176\n",
      "Epoch [5601 / 20000] average reconstruction error: 0.0009355754 , kl(*beta): 7.6332614326 (0.0076332614), reconstruction loss: 0.0001722492\n",
      "Epoch [5701 / 20000] average reconstruction error: 0.0008819556 , kl(*beta): 7.5106932259 (0.0075106932), reconstruction loss: 0.0001308862\n",
      "Epoch [5801 / 20000] average reconstruction error: 0.0008429082 , kl(*beta): 7.4422642708 (0.0074422643), reconstruction loss: 0.0000986817\n",
      "Epoch [5901 / 20000] average reconstruction error: 0.0009906141 , kl(*beta): 7.7968394661 (0.0077968395), reconstruction loss: 0.0002109301\n",
      "Epoch [6001 / 20000] average reconstruction error: 0.0009728662 , kl(*beta): 7.8551342392 (0.0078551342), reconstruction loss: 0.0001873527\n",
      "Epoch [6101 / 20000] average reconstruction error: 0.0008980198 , kl(*beta): 8.0492926598 (0.0080492927), reconstruction loss: 0.0000930905\n",
      "Epoch [6201 / 20000] average reconstruction error: 0.0010295241 , kl(*beta): 7.4941335678 (0.0074941336), reconstruction loss: 0.0002801107\n",
      "Epoch [6301 / 20000] average reconstruction error: 0.0008910792 , kl(*beta): 7.4202627373 (0.0074202627), reconstruction loss: 0.0001490529\n",
      "Epoch [6401 / 20000] average reconstruction error: 0.0009274083 , kl(*beta): 7.5262717628 (0.0075262718), reconstruction loss: 0.0001747811\n",
      "Epoch [6501 / 20000] average reconstruction error: 0.0010621044 , kl(*beta): 8.0480686760 (0.0080480687), reconstruction loss: 0.0002572974\n",
      "Epoch [6601 / 20000] average reconstruction error: 0.0008818549 , kl(*beta): 8.0550165558 (0.0080550166), reconstruction loss: 0.0000763532\n",
      "Epoch [6701 / 20000] average reconstruction error: 0.0009204240 , kl(*beta): 8.0006623650 (0.0080006624), reconstruction loss: 0.0001203577\n",
      "Epoch [6801 / 20000] average reconstruction error: 0.0008609109 , kl(*beta): 7.4910852623 (0.0074910853), reconstruction loss: 0.0001118023\n",
      "Epoch [6901 / 20000] average reconstruction error: 0.0008611349 , kl(*beta): 7.8611719894 (0.0078611720), reconstruction loss: 0.0000750177\n",
      "Epoch [7001 / 20000] average reconstruction error: 0.0008178829 , kl(*beta): 7.2395577431 (0.0072395577), reconstruction loss: 0.0000939271\n",
      "Epoch [7101 / 20000] average reconstruction error: 0.0008412964 , kl(*beta): 7.7042187500 (0.0077042187), reconstruction loss: 0.0000708745\n",
      "Epoch [7201 / 20000] average reconstruction error: 0.0009047180 , kl(*beta): 8.3502601814 (0.0083502602), reconstruction loss: 0.0000696920\n",
      "Epoch [7301 / 20000] average reconstruction error: 0.0008654133 , kl(*beta): 7.5985507965 (0.0075985508), reconstruction loss: 0.0001055582\n",
      "Epoch [7401 / 20000] average reconstruction error: 0.0008965816 , kl(*beta): 8.1597344017 (0.0081597344), reconstruction loss: 0.0000806081\n",
      "Epoch [7501 / 20000] average reconstruction error: 0.0009347181 , kl(*beta): 7.7516063881 (0.0077516064), reconstruction loss: 0.0001595574\n",
      "Epoch [7601 / 20000] average reconstruction error: 0.0008837251 , kl(*beta): 7.6762570381 (0.0076762570), reconstruction loss: 0.0001160993\n",
      "Epoch [7701 / 20000] average reconstruction error: 0.0011241783 , kl(*beta): 7.6971850967 (0.0076971851), reconstruction loss: 0.0003544598\n",
      "Epoch [7801 / 20000] average reconstruction error: 0.0017936492 , kl(*beta): 7.8832039642 (0.0078832040), reconstruction loss: 0.0010053288\n",
      "Epoch [7901 / 20000] average reconstruction error: 0.0008881617 , kl(*beta): 7.6097397041 (0.0076097397), reconstruction loss: 0.0001271877\n",
      "Epoch [8001 / 20000] average reconstruction error: 0.0009065503 , kl(*beta): 8.0999543571 (0.0080999544), reconstruction loss: 0.0000965548\n",
      "Epoch [8101 / 20000] average reconstruction error: 0.0008989931 , kl(*beta): 8.0751572800 (0.0080751573), reconstruction loss: 0.0000914773\n",
      "Epoch [8201 / 20000] average reconstruction error: 0.0011364459 , kl(*beta): 8.0359822273 (0.0080359822), reconstruction loss: 0.0003328476\n",
      "Epoch [8301 / 20000] average reconstruction error: 0.0008281571 , kl(*beta): 7.6154553413 (0.0076154553), reconstruction loss: 0.0000666115\n",
      "Epoch [8401 / 20000] average reconstruction error: 0.0008097670 , kl(*beta): 7.4389539337 (0.0074389539), reconstruction loss: 0.0000658716\n",
      "Epoch [8501 / 20000] average reconstruction error: 0.0009597929 , kl(*beta): 7.9509160233 (0.0079509160), reconstruction loss: 0.0001647013\n",
      "Epoch [8601 / 20000] average reconstruction error: 0.0009212043 , kl(*beta): 7.5404301643 (0.0075404302), reconstruction loss: 0.0001671612\n",
      "Epoch [8701 / 20000] average reconstruction error: 0.0011384550 , kl(*beta): 7.3013602257 (0.0073013602), reconstruction loss: 0.0004083190\n",
      "Epoch [8801 / 20000] average reconstruction error: 0.0008403856 , kl(*beta): 7.6945636749 (0.0076945637), reconstruction loss: 0.0000709292\n",
      "Epoch [8901 / 20000] average reconstruction error: 0.0013556832 , kl(*beta): 7.9053863525 (0.0079053864), reconstruction loss: 0.0005651445\n",
      "Epoch [9001 / 20000] average reconstruction error: 0.0008935116 , kl(*beta): 7.7791292763 (0.0077791293), reconstruction loss: 0.0001155986\n",
      "Epoch [9101 / 20000] average reconstruction error: 0.0009759860 , kl(*beta): 7.5058916855 (0.0075058917), reconstruction loss: 0.0002253968\n",
      "Epoch [9201 / 20000] average reconstruction error: 0.0008437571 , kl(*beta): 8.0220899582 (0.0080220900), reconstruction loss: 0.0000415481\n",
      "Epoch [9301 / 20000] average reconstruction error: 0.0008316051 , kl(*beta): 7.9080162048 (0.0079080162), reconstruction loss: 0.0000408034\n",
      "Epoch [9401 / 20000] average reconstruction error: 0.0010091057 , kl(*beta): 7.4389611816 (0.0074389612), reconstruction loss: 0.0002652095\n",
      "Epoch [9501 / 20000] average reconstruction error: 0.0007969436 , kl(*beta): 7.3735270119 (0.0073735270), reconstruction loss: 0.0000595909\n",
      "Epoch [9601 / 20000] average reconstruction error: 0.0008693051 , kl(*beta): 7.3802738953 (0.0073802739), reconstruction loss: 0.0001312777\n",
      "Epoch [9701 / 20000] average reconstruction error: 0.0008821897 , kl(*beta): 8.0281771660 (0.0080281772), reconstruction loss: 0.0000793719\n",
      "Epoch [9801 / 20000] average reconstruction error: 0.0008745416 , kl(*beta): 7.9533068466 (0.0079533068), reconstruction loss: 0.0000792109\n",
      "Epoch [9901 / 20000] average reconstruction error: 0.0013073225 , kl(*beta): 7.4328935623 (0.0074328936), reconstruction loss: 0.0005640331\n",
      "Epoch [10001 / 20000] average reconstruction error: 0.0009137221 , kl(*beta): 7.7002941704 (0.0077002942), reconstruction loss: 0.0001436926\n",
      "Epoch [10101 / 20000] average reconstruction error: 0.0008449218 , kl(*beta): 7.7930464363 (0.0077930464), reconstruction loss: 0.0000656171\n",
      "Epoch [10201 / 20000] average reconstruction error: 0.0010449474 , kl(*beta): 7.5192175484 (0.0075192175), reconstruction loss: 0.0002930256\n",
      "Epoch [10301 / 20000] average reconstruction error: 0.0009678652 , kl(*beta): 7.2710938835 (0.0072710939), reconstruction loss: 0.0002407558\n",
      "Epoch [10401 / 20000] average reconstruction error: 0.0008031324 , kl(*beta): 7.4118911934 (0.0074118912), reconstruction loss: 0.0000619432\n",
      "Epoch [10501 / 20000] average reconstruction error: 0.0015055729 , kl(*beta): 7.7660039902 (0.0077660040), reconstruction loss: 0.0007289725\n",
      "Epoch [10601 / 20000] average reconstruction error: 0.0008494262 , kl(*beta): 8.0287276077 (0.0080287276), reconstruction loss: 0.0000465534\n",
      "Epoch [10701 / 20000] average reconstruction error: 0.0010979746 , kl(*beta): 7.2531479645 (0.0072531480), reconstruction loss: 0.0003726597\n",
      "Epoch [10801 / 20000] average reconstruction error: 0.0012172981 , kl(*beta): 8.1054843521 (0.0081054844), reconstruction loss: 0.0004067496\n",
      "Epoch [10901 / 20000] average reconstruction error: 0.0008475474 , kl(*beta): 7.7599659348 (0.0077599659), reconstruction loss: 0.0000715508\n",
      "Epoch [11001 / 20000] average reconstruction error: 0.0008166460 , kl(*beta): 7.7509987831 (0.0077509988), reconstruction loss: 0.0000415461\n",
      "Epoch [11101 / 20000] average reconstruction error: 0.0009379183 , kl(*beta): 7.9577357292 (0.0079577357), reconstruction loss: 0.0001421447\n",
      "Epoch [11201 / 20000] average reconstruction error: 0.0014744940 , kl(*beta): 7.9456888580 (0.0079456889), reconstruction loss: 0.0006799251\n",
      "Epoch [11301 / 20000] average reconstruction error: 0.0010586431 , kl(*beta): 8.1410143280 (0.0081410143), reconstruction loss: 0.0002445417\n",
      "Epoch [11401 / 20000] average reconstruction error: 0.0008082810 , kl(*beta): 7.5407463455 (0.0075407463), reconstruction loss: 0.0000542063\n",
      "Epoch [11501 / 20000] average reconstruction error: 0.0011436729 , kl(*beta): 7.7416261673 (0.0077416262), reconstruction loss: 0.0003695102\n",
      "Epoch [11601 / 20000] average reconstruction error: 0.0007859802 , kl(*beta): 7.6184957886 (0.0076184958), reconstruction loss: 0.0000241306\n",
      "Epoch [11701 / 20000] average reconstruction error: 0.0010430108 , kl(*beta): 7.4389258385 (0.0074389258), reconstruction loss: 0.0002991181\n",
      "Epoch [11801 / 20000] average reconstruction error: 0.0008294543 , kl(*beta): 7.7170145035 (0.0077170145), reconstruction loss: 0.0000577528\n",
      "Epoch [11901 / 20000] average reconstruction error: 0.0007932332 , kl(*beta): 7.5768515396 (0.0075768515), reconstruction loss: 0.0000355480\n",
      "Epoch [12001 / 20000] average reconstruction error: 0.0009267565 , kl(*beta): 7.6315627670 (0.0076315628), reconstruction loss: 0.0001636002\n",
      "Epoch [12101 / 20000] average reconstruction error: 0.0008748979 , kl(*beta): 7.3270668411 (0.0073270668), reconstruction loss: 0.0001421912\n",
      "Epoch [12201 / 20000] average reconstruction error: 0.0008678814 , kl(*beta): 7.6704257011 (0.0076704257), reconstruction loss: 0.0001008388\n",
      "Epoch [12301 / 20000] average reconstruction error: 0.0008242050 , kl(*beta): 7.3231557274 (0.0073231557), reconstruction loss: 0.0000918894\n",
      "Epoch [12401 / 20000] average reconstruction error: 0.0011968541 , kl(*beta): 8.1504630089 (0.0081504630), reconstruction loss: 0.0003818078\n",
      "Epoch [12501 / 20000] average reconstruction error: 0.0008159931 , kl(*beta): 7.5037763977 (0.0075037764), reconstruction loss: 0.0000656154\n",
      "Epoch [12601 / 20000] average reconstruction error: 0.0013148548 , kl(*beta): 8.0297706032 (0.0080297706), reconstruction loss: 0.0005118777\n",
      "Epoch [12701 / 20000] average reconstruction error: 0.0008014667 , kl(*beta): 7.5171257782 (0.0075171258), reconstruction loss: 0.0000497541\n",
      "Epoch [12801 / 20000] average reconstruction error: 0.0008702202 , kl(*beta): 7.8834844208 (0.0078834844), reconstruction loss: 0.0000818717\n",
      "Epoch [12901 / 20000] average reconstruction error: 0.0008489503 , kl(*beta): 7.8071346092 (0.0078071346), reconstruction loss: 0.0000682368\n",
      "Epoch [13001 / 20000] average reconstruction error: 0.0008357583 , kl(*beta): 7.6439949417 (0.0076439949), reconstruction loss: 0.0000713588\n",
      "Epoch [13101 / 20000] average reconstruction error: 0.0008564415 , kl(*beta): 7.4129385376 (0.0074129385), reconstruction loss: 0.0001151476\n",
      "Epoch [13201 / 20000] average reconstruction error: 0.0008043404 , kl(*beta): 7.3925881577 (0.0073925882), reconstruction loss: 0.0000650815\n",
      "Epoch [13301 / 20000] average reconstruction error: 0.0008174314 , kl(*beta): 7.3014477539 (0.0073014478), reconstruction loss: 0.0000872866\n",
      "Epoch [13401 / 20000] average reconstruction error: 0.0008994105 , kl(*beta): 7.9056223106 (0.0079056223), reconstruction loss: 0.0001088482\n",
      "Epoch [13501 / 20000] average reconstruction error: 0.0008669391 , kl(*beta): 7.8858921623 (0.0078858922), reconstruction loss: 0.0000783499\n",
      "Epoch [13601 / 20000] average reconstruction error: 0.0008261731 , kl(*beta): 7.4748260307 (0.0074748260), reconstruction loss: 0.0000786905\n",
      "Epoch [13701 / 20000] average reconstruction error: 0.0008853106 , kl(*beta): 7.7361434937 (0.0077361435), reconstruction loss: 0.0001116962\n",
      "Epoch [13801 / 20000] average reconstruction error: 0.0008079920 , kl(*beta): 7.5464441299 (0.0075464441), reconstruction loss: 0.0000533475\n",
      "Epoch [13901 / 20000] average reconstruction error: 0.0008808610 , kl(*beta): 7.7098368835 (0.0077098369), reconstruction loss: 0.0001098773\n",
      "Epoch [14001 / 20000] average reconstruction error: 0.0008824995 , kl(*beta): 7.5498199844 (0.0075498200), reconstruction loss: 0.0001275174\n",
      "Epoch [14101 / 20000] average reconstruction error: 0.0008228831 , kl(*beta): 7.6989318275 (0.0076989318), reconstruction loss: 0.0000529899\n",
      "Epoch [14201 / 20000] average reconstruction error: 0.0008892843 , kl(*beta): 7.8164026833 (0.0078164027), reconstruction loss: 0.0001076440\n",
      "Epoch [14301 / 20000] average reconstruction error: 0.0008558342 , kl(*beta): 7.7157784081 (0.0077157784), reconstruction loss: 0.0000842564\n",
      "Epoch [14401 / 20000] average reconstruction error: 0.0009200428 , kl(*beta): 7.6811963272 (0.0076811963), reconstruction loss: 0.0001519231\n",
      "Epoch [14501 / 20000] average reconstruction error: 0.0008048861 , kl(*beta): 7.5375659752 (0.0075375660), reconstruction loss: 0.0000511295\n",
      "Epoch [14601 / 20000] average reconstruction error: 0.0007773463 , kl(*beta): 7.3518388748 (0.0073518389), reconstruction loss: 0.0000421624\n",
      "Epoch [14701 / 20000] average reconstruction error: 0.0008856003 , kl(*beta): 7.5266813850 (0.0075266814), reconstruction loss: 0.0001329322\n",
      "Epoch [14801 / 20000] average reconstruction error: 0.0008170478 , kl(*beta): 7.2589673805 (0.0072589674), reconstruction loss: 0.0000911510\n",
      "Epoch [14901 / 20000] average reconstruction error: 0.0008104606 , kl(*beta): 7.3341065598 (0.0073341066), reconstruction loss: 0.0000770499\n",
      "Epoch [15001 / 20000] average reconstruction error: 0.0008584671 , kl(*beta): 7.1791219521 (0.0071791220), reconstruction loss: 0.0001405549\n",
      "Epoch [15101 / 20000] average reconstruction error: 0.0007756812 , kl(*beta): 7.4352506256 (0.0074352506), reconstruction loss: 0.0000321561\n",
      "Epoch [15201 / 20000] average reconstruction error: 0.0008872231 , kl(*beta): 7.7866243553 (0.0077866244), reconstruction loss: 0.0001085607\n",
      "Epoch [15301 / 20000] average reconstruction error: 0.0008333806 , kl(*beta): 7.7322656059 (0.0077322656), reconstruction loss: 0.0000601540\n",
      "Epoch [15401 / 20000] average reconstruction error: 0.0008261187 , kl(*beta): 7.9122177696 (0.0079122178), reconstruction loss: 0.0000348968\n",
      "Epoch [15501 / 20000] average reconstruction error: 0.0008977823 , kl(*beta): 7.6081803513 (0.0076081804), reconstruction loss: 0.0001369642\n",
      "Epoch [15601 / 20000] average reconstruction error: 0.0007795226 , kl(*beta): 7.6144713402 (0.0076144713), reconstruction loss: 0.0000180754\n",
      "Epoch [15701 / 20000] average reconstruction error: 0.0008267602 , kl(*beta): 7.4490582466 (0.0074490582), reconstruction loss: 0.0000818543\n",
      "Epoch [15801 / 20000] average reconstruction error: 0.0008092458 , kl(*beta): 7.4312422752 (0.0074312423), reconstruction loss: 0.0000661215\n",
      "Epoch [15901 / 20000] average reconstruction error: 0.0013526654 , kl(*beta): 7.4988218307 (0.0074988218), reconstruction loss: 0.0006027831\n",
      "Epoch [16001 / 20000] average reconstruction error: 0.0008247096 , kl(*beta): 7.7015036392 (0.0077015036), reconstruction loss: 0.0000545592\n",
      "Epoch [16101 / 20000] average reconstruction error: 0.0008163248 , kl(*beta): 7.2619589806 (0.0072619590), reconstruction loss: 0.0000901289\n",
      "Epoch [16201 / 20000] average reconstruction error: 0.0015300244 , kl(*beta): 7.8470716286 (0.0078470716), reconstruction loss: 0.0007453172\n",
      "Epoch [16301 / 20000] average reconstruction error: 0.0008256437 , kl(*beta): 7.2785444450 (0.0072785444), reconstruction loss: 0.0000977892\n",
      "Epoch [16401 / 20000] average reconstruction error: 0.0014981029 , kl(*beta): 7.9420876694 (0.0079420877), reconstruction loss: 0.0007038941\n",
      "Epoch [16501 / 20000] average reconstruction error: 0.0008250019 , kl(*beta): 7.7074294090 (0.0077074294), reconstruction loss: 0.0000542589\n",
      "Epoch [16601 / 20000] average reconstruction error: 0.0007952084 , kl(*beta): 7.5981111145 (0.0075981111), reconstruction loss: 0.0000353973\n",
      "Epoch [16701 / 20000] average reconstruction error: 0.0010771526 , kl(*beta): 7.7008053589 (0.0077008054), reconstruction loss: 0.0003070720\n",
      "Epoch [16801 / 20000] average reconstruction error: 0.0009540567 , kl(*beta): 7.5393975830 (0.0075393976), reconstruction loss: 0.0002001169\n",
      "Epoch [16901 / 20000] average reconstruction error: 0.0007401246 , kl(*beta): 7.1715256882 (0.0071715257), reconstruction loss: 0.0000229720\n",
      "Epoch [17001 / 20000] average reconstruction error: 0.0008406895 , kl(*beta): 7.5575127602 (0.0075575128), reconstruction loss: 0.0000849382\n",
      "Epoch [17101 / 20000] average reconstruction error: 0.0008144294 , kl(*beta): 7.6871838570 (0.0076871839), reconstruction loss: 0.0000457110\n",
      "Epoch [17201 / 20000] average reconstruction error: 0.0011684279 , kl(*beta): 7.7259875870 (0.0077259876), reconstruction loss: 0.0003958291\n",
      "Epoch [17301 / 20000] average reconstruction error: 0.0011210150 , kl(*beta): 7.7907815552 (0.0077907816), reconstruction loss: 0.0003419367\n",
      "Epoch [17401 / 20000] average reconstruction error: 0.0008369275 , kl(*beta): 7.8282012367 (0.0078282012), reconstruction loss: 0.0000541073\n",
      "Epoch [17501 / 20000] average reconstruction error: 0.0009024960 , kl(*beta): 7.8994056892 (0.0078994057), reconstruction loss: 0.0001125554\n",
      "Epoch [17601 / 20000] average reconstruction error: 0.0007610714 , kl(*beta): 7.2851272202 (0.0072851272), reconstruction loss: 0.0000325587\n",
      "Epoch [17701 / 20000] average reconstruction error: 0.0008565158 , kl(*beta): 7.4674922752 (0.0074674923), reconstruction loss: 0.0001097665\n",
      "Epoch [17801 / 20000] average reconstruction error: 0.0008288370 , kl(*beta): 7.9562881088 (0.0079562881), reconstruction loss: 0.0000332082\n",
      "Epoch [17901 / 20000] average reconstruction error: 0.0009283479 , kl(*beta): 7.5236125565 (0.0075236126), reconstruction loss: 0.0001759866\n",
      "Epoch [18001 / 20000] average reconstruction error: 0.0008199191 , kl(*beta): 7.7510655975 (0.0077510656), reconstruction loss: 0.0000448125\n",
      "Epoch [18101 / 20000] average reconstruction error: 0.0010259533 , kl(*beta): 7.4789136505 (0.0074789137), reconstruction loss: 0.0002780619\n",
      "Epoch [18201 / 20000] average reconstruction error: 0.0013434949 , kl(*beta): 7.3628213501 (0.0073628214), reconstruction loss: 0.0006072127\n",
      "Epoch [18301 / 20000] average reconstruction error: 0.0007692334 , kl(*beta): 7.3560840225 (0.0073560840), reconstruction loss: 0.0000336250\n",
      "Epoch [18401 / 20000] average reconstruction error: 0.0008319123 , kl(*beta): 7.2933306313 (0.0072933306), reconstruction loss: 0.0001025792\n",
      "Epoch [18501 / 20000] average reconstruction error: 0.0016906477 , kl(*beta): 7.9992070770 (0.0079992071), reconstruction loss: 0.0008907269\n",
      "Epoch [18601 / 20000] average reconstruction error: 0.0008180107 , kl(*beta): 7.8951086426 (0.0078951086), reconstruction loss: 0.0000284998\n",
      "Epoch [18701 / 20000] average reconstruction error: 0.0007990825 , kl(*beta): 7.5590344810 (0.0075590345), reconstruction loss: 0.0000431790\n",
      "Epoch [18801 / 20000] average reconstruction error: 0.0008936889 , kl(*beta): 7.5618811035 (0.0075618811), reconstruction loss: 0.0001375007\n",
      "Epoch [18901 / 20000] average reconstruction error: 0.0014863245 , kl(*beta): 7.7190679550 (0.0077190680), reconstruction loss: 0.0007144176\n",
      "Epoch [19001 / 20000] average reconstruction error: 0.0007996845 , kl(*beta): 7.4812272263 (0.0074812272), reconstruction loss: 0.0000515617\n",
      "Epoch [19101 / 20000] average reconstruction error: 0.0009423439 , kl(*beta): 7.8349389458 (0.0078349389), reconstruction loss: 0.0001588499\n",
      "Epoch [19201 / 20000] average reconstruction error: 0.0008293466 , kl(*beta): 7.8525932312 (0.0078525932), reconstruction loss: 0.0000440872\n",
      "Epoch [19301 / 20000] average reconstruction error: 0.0008556718 , kl(*beta): 7.6647438240 (0.0076647438), reconstruction loss: 0.0000891973\n",
      "Epoch [19401 / 20000] average reconstruction error: 0.0011296839 , kl(*beta): 7.5848110771 (0.0075848111), reconstruction loss: 0.0003712027\n",
      "Epoch [19501 / 20000] average reconstruction error: 0.0008450774 , kl(*beta): 7.6313156509 (0.0076313157), reconstruction loss: 0.0000819458\n",
      "Epoch [19601 / 20000] average reconstruction error: 0.0008121962 , kl(*beta): 7.5679036522 (0.0075679037), reconstruction loss: 0.0000554058\n",
      "Epoch [19701 / 20000] average reconstruction error: 0.0007771951 , kl(*beta): 7.5484791756 (0.0075484792), reconstruction loss: 0.0000223471\n",
      "Epoch [19801 / 20000] average reconstruction error: 0.0007734774 , kl(*beta): 7.5248465729 (0.0075248466), reconstruction loss: 0.0000209927\n",
      "Epoch [19901 / 20000] average reconstruction error: 0.0007889775 , kl(*beta): 7.5528424644 (0.0075528425), reconstruction loss: 0.0000336932\n"
     ]
    }
   ],
   "source": [
    "torch.set_printoptions(precision=10)\n",
    "p = 5\n",
    "eps = 1\n",
    "t_list = os.listdir(\"data/paper/AneuriskP\" + str(p) + \"eps0\" + str(eps) )[:100]\n",
    "dataset = tDataset(t_list, \"data/paper/AneuriskP\" + str(p) + \"eps0\" + str(eps) )\n",
    "data_loader = DataLoader(dataset, batch_size = batch_size, shuffle=True, collate_fn=my_collate)\n",
    "\n",
    "\n",
    "mult = mv.numberNodes(data_loader, batch_size)\n",
    "feature_size = 64\n",
    "latent_size = feature_size\n",
    "hidden_size_encoder = 512\n",
    "hidden_size_decoder = 256\n",
    "\n",
    "Grassencoder = mv.GRASSEncoder(input_size = 4, feature_size=feature_size, hidden_size=hidden_size_encoder)\n",
    "Grassencoder = Grassencoder.to(device)\n",
    "Grassdecoder = mv.GRASSDecoder(latent_size=latent_size, hidden_size=hidden_size_decoder, mult = mult)\n",
    "Grassdecoder = Grassdecoder.to(device)\n",
    "\n",
    "mv.setLevel(data_loader)\n",
    "\n",
    "##loop parameters\n",
    "epochs = 20000\n",
    "learning_rate = 1e-4\n",
    "params = list(Grassencoder.parameters()) + list(Grassdecoder.parameters()) \n",
    "opt = torch.optim.Adam(params, lr=learning_rate) \n",
    "total_paramse = sum(param.numel() for param in Grassencoder.parameters())\n",
    "total_paramsd = sum(param.numel() for param in Grassdecoder.parameters())\n",
    "print(\"total parameters encoder \", total_paramse)\n",
    "print(\"total parameters decoder\", total_paramsd)\n",
    "print(\"total parameters\", total_paramse + total_paramsd)\n",
    "\n",
    "Grassencoder.train()\n",
    "Grassdecoder.train()\n",
    "\n",
    "config = {\n",
    "\"learning_rate\": learning_rate,\n",
    "\"epochs\": epochs,\n",
    "\"batch_size\": batch_size,\n",
    "\"dataset\": t_list,\n",
    "\"number of trees\": len(data_loader)*batch_size,\n",
    "\"optim\": opt,\n",
    "\"latent_size\" : latent_size,\n",
    "\"params\":total_paramse + total_paramsd,\n",
    "\"prof\": p,\n",
    "}\n",
    "wandb.init(project=\"MIA\", entity=\"paufeldman\", config = config)\n",
    "\n",
    "train_model(epochs, data_loader, Grassencoder, Grassdecoder, opt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('py_torc')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8f3e717cd274da89498094fde320e6eab1bf0f52911d27cf47473187acb3fe8a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
