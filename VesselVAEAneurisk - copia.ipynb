{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "torch.manual_seed(125)\n",
    "import random\n",
    "random.seed(125)\n",
    "import torch_f as torch_f\n",
    "import modelovae as mv\n",
    "import meshSubplot as ms\n",
    "import wandb\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_gpu = True\n",
    "device = torch.device(\"cuda:0\" if use_gpu and torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encodeStructureFold(fold, root):\n",
    "    '''Folds the tree by depth, so that nodes at the same depth can go in to the \n",
    "    encoder at the same time, reducing computational cost'''\n",
    "    def encodeNode(node):\n",
    "        \n",
    "        if node is None:\n",
    "            return\n",
    "        \n",
    "        if node.isLeaf():\n",
    "            return fold.add('leafEncoder', node.radius)\n",
    "        else:\n",
    "            left = encodeNode(node.left)\n",
    "            right = encodeNode(node.right)\n",
    "            if left is not None and right is not None:\n",
    "                return fold.add('bifurcationEncoder', node.radius, right, left)\n",
    "            elif right is not None:\n",
    "                return fold.add('internalEncoder', node.radius, right)\n",
    "            elif left is not None:\n",
    "                return fold.add('internalEncoder', node.radius, left)\n",
    "        \n",
    "\n",
    "    encoding = encodeNode(root)\n",
    "    return fold.add('sampleEncoder', encoding)\n",
    "\n",
    "def encode_structure(root, Grassencoder):\n",
    "        \n",
    "    def encode_node(node, Grassencoder):\n",
    "          \n",
    "        if node is None:\n",
    "            return\n",
    "        if node.isLeaf():\n",
    "            return Grassencoder.leafEncoder(node.radius.reshape(-1,4))\n",
    "        else :\n",
    "            left = encode_node(node.left, Grassencoder)\n",
    "            right = encode_node(node.right, Grassencoder)\n",
    "            if left is not None and right is not None:\n",
    "                return Grassencoder.bifurcationEncoder(node.radius.reshape(-1,4), right, left)\n",
    "            if right is not None:\n",
    "                return Grassencoder.internalEncoder(node.radius.reshape(-1,4), right)\n",
    "            if left is not None:\n",
    "                return Grassencoder.internalEncoder(node.radius.reshape(-1,4), left)\n",
    "\n",
    "    encoding = encode_node(root, Grassencoder)\n",
    "    return Grassencoder.sampleEncoder(encoding)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def numerar_nodos(root, count):\n",
    "    if root is not None:\n",
    "        numerar_nodos(root.left, count)\n",
    "        root.data = len(count)\n",
    "        count.append(1)\n",
    "        numerar_nodos(root.right, count)\n",
    "        return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_collate(batch):\n",
    "    return batch\n",
    "\n",
    "\n",
    "class tDataset(Dataset):\n",
    "    def __init__(self, l, dir, transform=None):\n",
    "        self.names = l\n",
    "        self.transform = transform\n",
    "        self.data = [] #lista con las strings de todos los arboles\n",
    "        for file in self.names:\n",
    "            self.data.append(mv.read_tree(file, dir))\n",
    "        #\"data\" is a list of all serialized trees, \"trees\" is a list of the binary trees\n",
    "        self.trees = []\n",
    "        for tree in self.data:\n",
    "            deserial = mv.deserialize(tree)\n",
    "            c = []\n",
    "            numerar_nodos(deserial, c)\n",
    "            self.trees.append({deserial: len(c)})\n",
    "            \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.names)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        tree = self.trees[idx]\n",
    "        return tree\n",
    "\n",
    "batch_size = 4"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decodeStructureFoldGrass(fold, v, root):\n",
    "    ''' Decodes the tree in a depth first fashion, grouping nodes at the same depth\n",
    "    in order to reduce computational cost'''\n",
    "\n",
    "    def decodeNode(fold, v, node, flag):\n",
    "        multipl = np.round((node.maxlevel+1-node.level)/node.treelevel, decimals=2)\n",
    "        label = fold.add('nodeClassifier', v)\n",
    "      \n",
    "               \n",
    "        if node.childs() == 1 :\n",
    "            \n",
    "            right, radius = fold.add('internalDecoder', v).split(2)\n",
    "            \n",
    "            if node.right:\n",
    "                nodoSiguiente = node.right\n",
    "            else:\n",
    "                nodoSiguiente = node.left\n",
    "            \n",
    "            child_loss = decodeNode(fold, right, nodoSiguiente, flag = 1)\n",
    "            lossEstructura = fold.add('classifyLossEstimator', label, node)\n",
    "            lossAtributo = fold.add('calcularLossAtributo', node, radius)\n",
    "            \n",
    "           \n",
    "            losse = fold.add('vectorMult', multipl, lossEstructura)\n",
    "            #losse = lossEstructura\n",
    "            loss = fold.add('vectorAdder', losse, lossAtributo)\n",
    "            loss2 = fold.add('vectorAdder', loss, child_loss)\n",
    "\n",
    "            return loss2\n",
    "        elif node.childs() == 0 : \n",
    "\n",
    "            radius = fold.add('featureDecoder', v)\n",
    "            \n",
    "            lossEstructura = fold.add('classifyLossEstimator', label, node) \n",
    "            lossAtributo = fold.add('calcularLossAtributo', node, radius)\n",
    "\n",
    "            losse = fold.add('vectorMult', multipl, lossEstructura)\n",
    "            #losse = lossEstructura\n",
    "            loss =  fold.add('vectorAdder', losse, lossAtributo)   \n",
    "\n",
    "            return loss\n",
    "            \n",
    "        \n",
    "        elif node.childs() == 2 :\n",
    "\n",
    "            left, right, radius = fold.add('bifurcationDecoder', v).split(3)\n",
    "            nodoSiguienteRight = node.right\n",
    "            nodoSiguienteLeft = node.left\n",
    "\n",
    "            if nodoSiguienteRight is not None:\n",
    "                right_loss = decodeNode(fold, right, nodoSiguienteRight, flag = 1)\n",
    "             \n",
    "            if nodoSiguienteLeft is not None:\n",
    "                left_loss  = decodeNode(fold, left, nodoSiguienteLeft, flag = 1)\n",
    "\n",
    "          \n",
    "            \n",
    "            lossEstructura = fold.add('classifyLossEstimator', label, node)\n",
    "            lossAtributo   = fold.add('calcularLossAtributo', node, radius)\n",
    "            losse = fold.add('vectorMult', multipl, lossEstructura)\n",
    "            #losse = lossEstructura\n",
    "            loss = fold.add('vectorAdder', losse, lossAtributo)\n",
    "            loss2 = fold.add('vectorAdder', loss, right_loss)\n",
    "            loss3 = fold.add('vectorAdder', loss2, left_loss)\n",
    "            return loss3\n",
    "            \n",
    "    v1 = fold.add('sampleDecoder', v)\n",
    "    dec = decodeNode (fold, v1, root, flag = 0)\n",
    "    return dec\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SaveBestModel:\n",
    "    \"\"\"\n",
    "    Class to save the best model while training. If the current epoch's \n",
    "    validation loss is less than the previous least less, then save the\n",
    "    model state.\n",
    "    \"\"\"\n",
    "    def __init__(self, best_valid_loss=float('inf')):\n",
    "        self.best_valid_loss = best_valid_loss\n",
    "        \n",
    "    def __call__(\n",
    "        self, current_valid_loss, \n",
    "        epoch, encoder, decoder, optimizer\n",
    "    ):  \n",
    "        if epoch > 50:\n",
    "            if current_valid_loss < self.best_valid_loss:\n",
    "                self.best_valid_loss = current_valid_loss\n",
    "                #'classifier_state_dict': classifier.state_dict(),\n",
    "                torch.save({\n",
    "                    'epoch': epoch+1,\n",
    "                    'encoder_state_dict': encoder.state_dict(),\n",
    "                    'decoder_state_dict': decoder.state_dict(),\n",
    "                    'loss' : self.best_valid_loss,\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    }, 'output/AneuriskP15eps02-best1.pth')\n",
    "\n",
    "class SaveLastModel:\n",
    "    \"\"\"\n",
    "    Class to save the model while training. \n",
    "    \"\"\"  \n",
    "    def __call__( self,  epoch, encoder, decoder, optimizer):\n",
    "        torch.save({\n",
    "            'epoch': epoch+1,\n",
    "            'encoder_state_dict': encoder.state_dict(),\n",
    "            'decoder_state_dict': decoder.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            }, 'ablation/outputP15eps02-last1.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def escalon_beta (e, corte):\n",
    "    l = np.linspace(e,e,corte)\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_Level(tree, n_nodes):\n",
    "    max_level = 0  \n",
    "    for x in range(0, n_nodes):\n",
    "        level = mv.getLevel(tree, x)\n",
    "        if level > max_level:\n",
    "            max_level = level\n",
    "        if (level):\n",
    "            node = mv.searchNode(tree, x)\n",
    "            node.level = mv.getLevel(tree, x)\n",
    "        else:\n",
    "            print(x, \"is not present in tree\")\n",
    "    tree_level = []\n",
    "    tree.getTreeLevel(tree, tree_level)\n",
    "    tree_level = [max_level - nodelevel for nodelevel in tree_level]\n",
    "    tree.setTreeLevel(tree, sum(tree_level))\n",
    "    tree.setMaxLevel(tree, max_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(epochs, data_loader, Grassencoder, Grassdecoder, opt):\n",
    " \n",
    "    save_last_model = SaveLastModel()\n",
    "    save_best_model = SaveBestModel()\n",
    "    train_loss_avg = []\n",
    "    betas = escalon_beta(.001, 400000)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "    \n",
    "        beta = betas[epoch]\n",
    "        train_loss_avg.append(0)\n",
    "\n",
    "        epochTotalLoss = 0\n",
    "        epochReconLoss = 0\n",
    "        epochKLDivLoss = 0\n",
    "        epochKLDivLossBeta = 0\n",
    "\n",
    "        for batch_idx, batch in enumerate(data_loader):            \n",
    "            \n",
    "            enc_fold = torch_f.Fold(device)\n",
    "            \n",
    "            enc_fold_nodes = []     \n",
    "            n_nodes = []\n",
    "            for tree in batch: #example es un arbolito\n",
    "                example = list(tree.keys())[0]\n",
    "                n = tree[example]#[0]\n",
    "                n_nodes.append(n)\n",
    "                enc_fold_nodes.append(encodeStructureFold(enc_fold, example))\n",
    "            \n",
    "            enc_fold_nodes = enc_fold.apply(Grassencoder, [enc_fold_nodes])\n",
    "            \n",
    "            enc_fold_nodes = torch.split(enc_fold_nodes[0], 1, 0)\n",
    "            \n",
    "            dec_fold = torch_f.Fold(device)\n",
    "            dec_fold_nodes = []\n",
    "            kld_fold_nodes = []\n",
    "\n",
    "            for tree, fnode in zip(batch, enc_fold_nodes):\n",
    "                example = list(tree.keys())[0]\n",
    "                root_code, kl_div = torch.chunk(fnode, 2, 1)\n",
    "                dec_fold_nodes.append(decodeStructureFoldGrass(dec_fold, root_code, example))\n",
    "                kld_fold_nodes.append(kl_div)\n",
    "                \n",
    "            total_loss = dec_fold.apply(Grassdecoder, [dec_fold_nodes, kld_fold_nodes])\n",
    "            n_nodes = torch.tensor(n_nodes, device = device)\n",
    "            recon_loss = torch.div(total_loss[0], n_nodes)\n",
    "            recon_loss = recon_loss.sum() / len(batch)               # avg. reconstruction loss per example\n",
    "            \n",
    "            kldiv_loss = []\n",
    "            for element in kld_fold_nodes:\n",
    "                l = torch.sum(element)\n",
    "                kldiv_loss.append(l)\n",
    "           \n",
    "            kldiv_loss = sum(kldiv_loss) / len(batch)\n",
    "           \n",
    "            total_loss = recon_loss +  beta*kldiv_loss/10\n",
    "           \n",
    "            opt.zero_grad()\n",
    "            total_loss.backward()\n",
    "            opt.step()\n",
    "            train_loss_avg[-1] += (total_loss.item())\n",
    "            epochTotalLoss += total_loss.item()\n",
    "            epochReconLoss += recon_loss.item()\n",
    "            epochKLDivLoss += kldiv_loss.item()\n",
    "            epochKLDivLossBeta += beta*kldiv_loss.item()\n",
    "\n",
    "        epochTotalLoss /= len(data_loader)\n",
    "        epochReconLoss /= len(data_loader)\n",
    "        epochKLDivLoss /= len(data_loader)\n",
    "        epochKLDivLossBeta  /= len(data_loader)\n",
    "        \n",
    "        \n",
    "        save_best_model(total_loss, epoch, Grassencoder, Grassdecoder, opt)\n",
    "        if epoch % 10 == 0: \n",
    "            wandb.log({'epoch': epoch+1, 'loss': epochTotalLoss, 'kl_div': epochKLDivLoss, 'kl_div (*beta)': epochKLDivLossBeta, 'recon_loss': epochReconLoss, 'beta': beta})\n",
    "        if epoch % 100 == 0:   \n",
    "            save_last_model(epoch, Grassencoder, Grassdecoder, opt)\n",
    "        if epoch % 100 == 0:\n",
    "            print('Epoch [%d / %d] average reconstruction error: %.10f , kl(*beta): %.10f (%.10f), reconstruction loss: %.10f' % (epoch+1, epochs, epochTotalLoss, epochKLDivLoss, epochKLDivLossBeta, epochReconLoss))\n",
    "    return \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FOR LOOP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total parameters encoder  626560\n",
      "total parameters decoder 379911\n",
      "total parameters 1006471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mpaufeldman\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.6 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\User\\Documents\\MICCAI\\VesselVAEMIA\\wandb\\run-20240425_133745-zjpmbkc0</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/paufeldman/MIA/runs/zjpmbkc0' target=\"_blank\">daily-night-84</a></strong> to <a href='https://wandb.ai/paufeldman/MIA' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/paufeldman/MIA' target=\"_blank\">https://wandb.ai/paufeldman/MIA</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/paufeldman/MIA/runs/zjpmbkc0' target=\"_blank\">https://wandb.ai/paufeldman/MIA/runs/zjpmbkc0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1 / 20000] average reconstruction error: 0.1193334606 , kl(*beta): 0.0473284966 (0.0000473285), reconstruction loss: 0.1193287280\n",
      "Epoch [101 / 20000] average reconstruction error: 0.0184334410 , kl(*beta): 4.6291177225 (0.0046291177), reconstruction loss: 0.0179705292\n",
      "Epoch [201 / 20000] average reconstruction error: 0.0163336965 , kl(*beta): 3.8412607050 (0.0038412607), reconstruction loss: 0.0159495702\n",
      "Epoch [301 / 20000] average reconstruction error: 0.0148279740 , kl(*beta): 4.7673721313 (0.0047673721), reconstruction loss: 0.0143512368\n",
      "Epoch [401 / 20000] average reconstruction error: 0.0130028397 , kl(*beta): 5.8797511005 (0.0058797511), reconstruction loss: 0.0124148646\n",
      "Epoch [501 / 20000] average reconstruction error: 0.0121042639 , kl(*beta): 6.5839282417 (0.0065839282), reconstruction loss: 0.0114458711\n",
      "Epoch [601 / 20000] average reconstruction error: 0.0110939336 , kl(*beta): 7.4580786324 (0.0074580786), reconstruction loss: 0.0103481257\n",
      "Epoch [701 / 20000] average reconstruction error: 0.0109463050 , kl(*beta): 7.8416335297 (0.0078416335), reconstruction loss: 0.0101621416\n",
      "Epoch [801 / 20000] average reconstruction error: 0.0107570690 , kl(*beta): 7.8884003830 (0.0078884004), reconstruction loss: 0.0099682290\n",
      "Epoch [901 / 20000] average reconstruction error: 0.0093174634 , kl(*beta): 7.5535048294 (0.0075535048), reconstruction loss: 0.0085621128\n",
      "Epoch [1001 / 20000] average reconstruction error: 0.0081669402 , kl(*beta): 7.5547895241 (0.0075547895), reconstruction loss: 0.0074114612\n",
      "Epoch [1101 / 20000] average reconstruction error: 0.0088813373 , kl(*beta): 9.3388818932 (0.0093388819), reconstruction loss: 0.0079474490\n",
      "Epoch [1201 / 20000] average reconstruction error: 0.0074146193 , kl(*beta): 7.8237295914 (0.0078237296), reconstruction loss: 0.0066322463\n",
      "Epoch [1301 / 20000] average reconstruction error: 0.0062367493 , kl(*beta): 7.8675350952 (0.0078675351), reconstruction loss: 0.0054499958\n",
      "Epoch [1401 / 20000] average reconstruction error: 0.0061516142 , kl(*beta): 7.5381945801 (0.0075381946), reconstruction loss: 0.0053977947\n",
      "Epoch [1501 / 20000] average reconstruction error: 0.0050157285 , kl(*beta): 7.2309746742 (0.0072309747), reconstruction loss: 0.0042926310\n",
      "Epoch [1601 / 20000] average reconstruction error: 0.0045171593 , kl(*beta): 7.4960588455 (0.0074960588), reconstruction loss: 0.0037675534\n",
      "Epoch [1701 / 20000] average reconstruction error: 0.0048172620 , kl(*beta): 7.7459358597 (0.0077459359), reconstruction loss: 0.0040426683\n",
      "Epoch [1801 / 20000] average reconstruction error: 0.0040348961 , kl(*beta): 7.6182943153 (0.0076182943), reconstruction loss: 0.0032730666\n",
      "Epoch [1901 / 20000] average reconstruction error: 0.0043755782 , kl(*beta): 7.4607375526 (0.0074607376), reconstruction loss: 0.0036295043\n",
      "Epoch [2001 / 20000] average reconstruction error: 0.0037625975 , kl(*beta): 7.9578854179 (0.0079578854), reconstruction loss: 0.0029668089\n",
      "Epoch [2101 / 20000] average reconstruction error: 0.0032316193 , kl(*beta): 7.4277558708 (0.0074277559), reconstruction loss: 0.0024888436\n",
      "Epoch [2201 / 20000] average reconstruction error: 0.0034046084 , kl(*beta): 7.7860728455 (0.0077860728), reconstruction loss: 0.0026260011\n",
      "Epoch [2301 / 20000] average reconstruction error: 0.0033469722 , kl(*beta): 7.4791425705 (0.0074791426), reconstruction loss: 0.0025990579\n",
      "Epoch [2401 / 20000] average reconstruction error: 0.0045750003 , kl(*beta): 8.5746189880 (0.0085746190), reconstruction loss: 0.0037175384\n",
      "Epoch [2501 / 20000] average reconstruction error: 0.0028936049 , kl(*beta): 7.4681140327 (0.0074681140), reconstruction loss: 0.0021467934\n",
      "Epoch [2601 / 20000] average reconstruction error: 0.0025804469 , kl(*beta): 7.5938614655 (0.0075938615), reconstruction loss: 0.0018210607\n",
      "Epoch [2701 / 20000] average reconstruction error: 0.0043571621 , kl(*beta): 9.1351447487 (0.0091351447), reconstruction loss: 0.0034436476\n",
      "Epoch [2801 / 20000] average reconstruction error: 0.0022835758 , kl(*beta): 7.3371178627 (0.0073371179), reconstruction loss: 0.0015498639\n",
      "Epoch [2901 / 20000] average reconstruction error: 0.0022525352 , kl(*beta): 7.4039941788 (0.0074039942), reconstruction loss: 0.0015121357\n",
      "Epoch [3001 / 20000] average reconstruction error: 0.0022149114 , kl(*beta): 7.2715400314 (0.0072715400), reconstruction loss: 0.0014877573\n",
      "Epoch [3101 / 20000] average reconstruction error: 0.0023380966 , kl(*beta): 8.1577835083 (0.0081577835), reconstruction loss: 0.0015223181\n",
      "Epoch [3201 / 20000] average reconstruction error: 0.0029312038 , kl(*beta): 8.2120850754 (0.0082120851), reconstruction loss: 0.0021099952\n",
      "Epoch [3301 / 20000] average reconstruction error: 0.0022470802 , kl(*beta): 7.8595326424 (0.0078595326), reconstruction loss: 0.0014611269\n",
      "Epoch [3401 / 20000] average reconstruction error: 0.0019985130 , kl(*beta): 7.3603479004 (0.0073603479), reconstruction loss: 0.0012624782\n",
      "Epoch [3501 / 20000] average reconstruction error: 0.0019490316 , kl(*beta): 7.7413443375 (0.0077413443), reconstruction loss: 0.0011748971\n",
      "Epoch [3601 / 20000] average reconstruction error: 0.0044138720 , kl(*beta): 8.5694525337 (0.0085694525), reconstruction loss: 0.0035569267\n",
      "Epoch [3701 / 20000] average reconstruction error: 0.0021318778 , kl(*beta): 8.0672891617 (0.0080672892), reconstruction loss: 0.0013251488\n",
      "Epoch [3801 / 20000] average reconstruction error: 0.0015811426 , kl(*beta): 7.0630179787 (0.0070630180), reconstruction loss: 0.0008748408\n",
      "Epoch [3901 / 20000] average reconstruction error: 0.0023102311 , kl(*beta): 7.6693221092 (0.0076693221), reconstruction loss: 0.0015432989\n",
      "Epoch [4001 / 20000] average reconstruction error: 0.0023280563 , kl(*beta): 8.0237472725 (0.0080237473), reconstruction loss: 0.0015256816\n",
      "Epoch [4101 / 20000] average reconstruction error: 0.0015834848 , kl(*beta): 7.3450057411 (0.0073450057), reconstruction loss: 0.0008489841\n",
      "Epoch [4201 / 20000] average reconstruction error: 0.0019154604 , kl(*beta): 7.4242938042 (0.0074242938), reconstruction loss: 0.0011730309\n",
      "Epoch [4301 / 20000] average reconstruction error: 0.0032196536 , kl(*beta): 7.7371543121 (0.0077371543), reconstruction loss: 0.0024459381\n",
      "Epoch [4401 / 20000] average reconstruction error: 0.0016128915 , kl(*beta): 7.3332382584 (0.0073332383), reconstruction loss: 0.0008795676\n",
      "Epoch [4501 / 20000] average reconstruction error: 0.0016518487 , kl(*beta): 7.5650732231 (0.0075650732), reconstruction loss: 0.0008953414\n",
      "Epoch [4601 / 20000] average reconstruction error: 0.0016571752 , kl(*beta): 7.1456306458 (0.0071456306), reconstruction loss: 0.0009426120\n",
      "Epoch [4701 / 20000] average reconstruction error: 0.0019963743 , kl(*beta): 7.5563431740 (0.0075563432), reconstruction loss: 0.0012407399\n",
      "Epoch [4801 / 20000] average reconstruction error: 0.0027460747 , kl(*beta): 8.5951408386 (0.0085951408), reconstruction loss: 0.0018865605\n",
      "Epoch [4901 / 20000] average reconstruction error: 0.0028736535 , kl(*beta): 7.5757078171 (0.0075757078), reconstruction loss: 0.0021160827\n",
      "Epoch [5001 / 20000] average reconstruction error: 0.0015357918 , kl(*beta): 7.3667919540 (0.0073667920), reconstruction loss: 0.0007991126\n",
      "Epoch [5101 / 20000] average reconstruction error: 0.0016865770 , kl(*beta): 7.4033251953 (0.0074033252), reconstruction loss: 0.0009462444\n",
      "Epoch [5201 / 20000] average reconstruction error: 0.0036140293 , kl(*beta): 8.2740640068 (0.0082740640), reconstruction loss: 0.0027866228\n",
      "Epoch [5301 / 20000] average reconstruction error: 0.0012613522 , kl(*beta): 7.1150718689 (0.0071150719), reconstruction loss: 0.0005498450\n",
      "Epoch [5401 / 20000] average reconstruction error: 0.0013012256 , kl(*beta): 7.2496107101 (0.0072496107), reconstruction loss: 0.0005762645\n",
      "Epoch [5501 / 20000] average reconstruction error: 0.0035065471 , kl(*beta): 8.9247953796 (0.0089247954), reconstruction loss: 0.0026140675\n",
      "Epoch [5601 / 20000] average reconstruction error: 0.0016988688 , kl(*beta): 7.4205661583 (0.0074205662), reconstruction loss: 0.0009568122\n",
      "Epoch [5701 / 20000] average reconstruction error: 0.0014831474 , kl(*beta): 7.4790438843 (0.0074790439), reconstruction loss: 0.0007352430\n",
      "Epoch [5801 / 20000] average reconstruction error: 0.0014285401 , kl(*beta): 7.1938345528 (0.0071938346), reconstruction loss: 0.0007091566\n",
      "Epoch [5901 / 20000] average reconstruction error: 0.0012166576 , kl(*beta): 7.1166285133 (0.0071166285), reconstruction loss: 0.0005049947\n",
      "Epoch [6001 / 20000] average reconstruction error: 0.0013123178 , kl(*beta): 7.7716103745 (0.0077716104), reconstruction loss: 0.0005351567\n",
      "Epoch [6101 / 20000] average reconstruction error: 0.0014084791 , kl(*beta): 7.7130890274 (0.0077130890), reconstruction loss: 0.0006371702\n",
      "Epoch [6201 / 20000] average reconstruction error: 0.0041867694 , kl(*beta): 7.7095810699 (0.0077095811), reconstruction loss: 0.0034158113\n",
      "Epoch [6301 / 20000] average reconstruction error: 0.0015882538 , kl(*beta): 7.0016469383 (0.0070016469), reconstruction loss: 0.0008880891\n",
      "Epoch [6401 / 20000] average reconstruction error: 0.0018133208 , kl(*beta): 7.8253273773 (0.0078253274), reconstruction loss: 0.0010307880\n",
      "Epoch [6501 / 20000] average reconstruction error: 0.0012338675 , kl(*beta): 7.6185060883 (0.0076185061), reconstruction loss: 0.0004720168\n",
      "Epoch [6601 / 20000] average reconstruction error: 0.0013636359 , kl(*beta): 7.6373238182 (0.0076373238), reconstruction loss: 0.0005999035\n",
      "Epoch [6701 / 20000] average reconstruction error: 0.0017396407 , kl(*beta): 7.3793530083 (0.0073793530), reconstruction loss: 0.0010017053\n",
      "Epoch [6801 / 20000] average reconstruction error: 0.0011371663 , kl(*beta): 7.2641414452 (0.0072641414), reconstruction loss: 0.0004107521\n",
      "Epoch [6901 / 20000] average reconstruction error: 0.0015977224 , kl(*beta): 8.6436889648 (0.0086436890), reconstruction loss: 0.0007333535\n",
      "Epoch [7001 / 20000] average reconstruction error: 0.0012671072 , kl(*beta): 7.2840283394 (0.0072840283), reconstruction loss: 0.0005387043\n",
      "Epoch [7101 / 20000] average reconstruction error: 0.0012374058 , kl(*beta): 7.7183321953 (0.0077183322), reconstruction loss: 0.0004655725\n",
      "Epoch [7201 / 20000] average reconstruction error: 0.0012595429 , kl(*beta): 7.3979412651 (0.0073979413), reconstruction loss: 0.0005197487\n",
      "Epoch [7301 / 20000] average reconstruction error: 0.0012331167 , kl(*beta): 7.2292101479 (0.0072292101), reconstruction loss: 0.0005101957\n",
      "Epoch [7401 / 20000] average reconstruction error: 0.0020638345 , kl(*beta): 7.2152066612 (0.0072152067), reconstruction loss: 0.0013423138\n",
      "Epoch [7501 / 20000] average reconstruction error: 0.0011468842 , kl(*beta): 7.4279709053 (0.0074279709), reconstruction loss: 0.0004040871\n",
      "Epoch [7601 / 20000] average reconstruction error: 0.0010871891 , kl(*beta): 7.3223634529 (0.0073223635), reconstruction loss: 0.0003549527\n",
      "Epoch [7701 / 20000] average reconstruction error: 0.0012688995 , kl(*beta): 7.5299468422 (0.0075299468), reconstruction loss: 0.0005159048\n",
      "Epoch [7801 / 20000] average reconstruction error: 0.0013603179 , kl(*beta): 8.0325325012 (0.0080325325), reconstruction loss: 0.0005570646\n",
      "Epoch [7901 / 20000] average reconstruction error: 0.0011603642 , kl(*beta): 7.3009375572 (0.0073009376), reconstruction loss: 0.0004302704\n",
      "Epoch [8001 / 20000] average reconstruction error: 0.0014627792 , kl(*beta): 7.6204902458 (0.0076204902), reconstruction loss: 0.0007007301\n",
      "Epoch [8101 / 20000] average reconstruction error: 0.0009581694 , kl(*beta): 7.0363337708 (0.0070363338), reconstruction loss: 0.0002545360\n",
      "Epoch [8201 / 20000] average reconstruction error: 0.0010186778 , kl(*beta): 7.1309898567 (0.0071309899), reconstruction loss: 0.0003055787\n",
      "Epoch [8301 / 20000] average reconstruction error: 0.0011235701 , kl(*beta): 7.5125882339 (0.0075125882), reconstruction loss: 0.0003723113\n",
      "Epoch [8401 / 20000] average reconstruction error: 0.0017526508 , kl(*beta): 7.4145923805 (0.0074145924), reconstruction loss: 0.0010111915\n",
      "Epoch [8501 / 20000] average reconstruction error: 0.0013372953 , kl(*beta): 7.6583271408 (0.0076583271), reconstruction loss: 0.0005714625\n",
      "Epoch [8601 / 20000] average reconstruction error: 0.0012576769 , kl(*beta): 7.3848910522 (0.0073848911), reconstruction loss: 0.0005191877\n",
      "Epoch [8701 / 20000] average reconstruction error: 0.0016156987 , kl(*beta): 7.8828084946 (0.0078828085), reconstruction loss: 0.0008274178\n",
      "Epoch [8801 / 20000] average reconstruction error: 0.0011457595 , kl(*beta): 7.2787844276 (0.0072787844), reconstruction loss: 0.0004178810\n",
      "Epoch [8901 / 20000] average reconstruction error: 0.0012342159 , kl(*beta): 7.1429971886 (0.0071429972), reconstruction loss: 0.0005199162\n",
      "Epoch [9001 / 20000] average reconstruction error: 0.0011749932 , kl(*beta): 6.8555292702 (0.0068555293), reconstruction loss: 0.0004894402\n",
      "Epoch [9101 / 20000] average reconstruction error: 0.0010604914 , kl(*beta): 7.2437613678 (0.0072437614), reconstruction loss: 0.0003361152\n",
      "Epoch [9201 / 20000] average reconstruction error: 0.0009509080 , kl(*beta): 6.8175647545 (0.0068175648), reconstruction loss: 0.0002691514\n",
      "Epoch [9301 / 20000] average reconstruction error: 0.0015011490 , kl(*beta): 7.2960167885 (0.0072960168), reconstruction loss: 0.0007715473\n",
      "Epoch [9401 / 20000] average reconstruction error: 0.0015302392 , kl(*beta): 7.4224535179 (0.0074224535), reconstruction loss: 0.0007879938\n",
      "Epoch [9501 / 20000] average reconstruction error: 0.0010404879 , kl(*beta): 7.2946543121 (0.0072946543), reconstruction loss: 0.0003110224\n",
      "Epoch [9601 / 20000] average reconstruction error: 0.0012049602 , kl(*beta): 7.1694731140 (0.0071694731), reconstruction loss: 0.0004880129\n",
      "Epoch [9701 / 20000] average reconstruction error: 0.0011653001 , kl(*beta): 7.4940826988 (0.0074940827), reconstruction loss: 0.0004158918\n",
      "Epoch [9801 / 20000] average reconstruction error: 0.0012031164 , kl(*beta): 7.5149048996 (0.0075149049), reconstruction loss: 0.0004516259\n",
      "Epoch [9901 / 20000] average reconstruction error: 0.0009533933 , kl(*beta): 7.1760133553 (0.0071760134), reconstruction loss: 0.0002357919\n",
      "Epoch [10001 / 20000] average reconstruction error: 0.0009322057 , kl(*beta): 7.0899049377 (0.0070899049), reconstruction loss: 0.0002232151\n",
      "Epoch [10101 / 20000] average reconstruction error: 0.0008958512 , kl(*beta): 7.0386980247 (0.0070386980), reconstruction loss: 0.0001919814\n",
      "Epoch [10201 / 20000] average reconstruction error: 0.0011245308 , kl(*beta): 7.7145680428 (0.0077145680), reconstruction loss: 0.0003530739\n",
      "Epoch [10301 / 20000] average reconstruction error: 0.0021166513 , kl(*beta): 7.7469561577 (0.0077469562), reconstruction loss: 0.0013419557\n",
      "Epoch [10401 / 20000] average reconstruction error: 0.0011358920 , kl(*beta): 7.0127024841 (0.0070127025), reconstruction loss: 0.0004346217\n",
      "Epoch [10501 / 20000] average reconstruction error: 0.0010224790 , kl(*beta): 6.9953382874 (0.0069953383), reconstruction loss: 0.0003229451\n",
      "Epoch [10601 / 20000] average reconstruction error: 0.0016419023 , kl(*beta): 7.7723005104 (0.0077723005), reconstruction loss: 0.0008646723\n",
      "Epoch [10701 / 20000] average reconstruction error: 0.0020580971 , kl(*beta): 7.6421574020 (0.0076421574), reconstruction loss: 0.0012938814\n",
      "Epoch [10801 / 20000] average reconstruction error: 0.0012745331 , kl(*beta): 7.8556125450 (0.0078556125), reconstruction loss: 0.0004889718\n",
      "Epoch [10901 / 20000] average reconstruction error: 0.0009441404 , kl(*beta): 7.1142117500 (0.0071142118), reconstruction loss: 0.0002327192\n",
      "Epoch [11001 / 20000] average reconstruction error: 0.0010419728 , kl(*beta): 7.2425174332 (0.0072425174), reconstruction loss: 0.0003177210\n",
      "Epoch [11101 / 20000] average reconstruction error: 0.0012866162 , kl(*beta): 7.3989524078 (0.0073989524), reconstruction loss: 0.0005467209\n",
      "Epoch [11201 / 20000] average reconstruction error: 0.0013639282 , kl(*beta): 7.5470736885 (0.0075470737), reconstruction loss: 0.0006092207\n",
      "Epoch [11301 / 20000] average reconstruction error: 0.0010260278 , kl(*beta): 7.3899202538 (0.0073899203), reconstruction loss: 0.0002870358\n",
      "Epoch [11401 / 20000] average reconstruction error: 0.0009478101 , kl(*beta): 7.4994232941 (0.0074994233), reconstruction loss: 0.0001978677\n",
      "Epoch [11501 / 20000] average reconstruction error: 0.0008993181 , kl(*beta): 6.9573430824 (0.0069573431), reconstruction loss: 0.0002035838\n",
      "Epoch [11601 / 20000] average reconstruction error: 0.0013464063 , kl(*beta): 7.6822601700 (0.0076822602), reconstruction loss: 0.0005781802\n",
      "Epoch [11701 / 20000] average reconstruction error: 0.0009810850 , kl(*beta): 7.1493169785 (0.0071493170), reconstruction loss: 0.0002661533\n",
      "Epoch [11801 / 20000] average reconstruction error: 0.0012563514 , kl(*beta): 7.1900936317 (0.0071900936), reconstruction loss: 0.0005373420\n",
      "Epoch [11901 / 20000] average reconstruction error: 0.0008806283 , kl(*beta): 6.9370821190 (0.0069370821), reconstruction loss: 0.0001869200\n",
      "Epoch [12001 / 20000] average reconstruction error: 0.0023154095 , kl(*beta): 7.5070683861 (0.0075070684), reconstruction loss: 0.0015647027\n",
      "Epoch [12101 / 20000] average reconstruction error: 0.0009066629 , kl(*beta): 7.1828038597 (0.0071828039), reconstruction loss: 0.0001883825\n",
      "Epoch [12201 / 20000] average reconstruction error: 0.0009739365 , kl(*beta): 7.0027563667 (0.0070027564), reconstruction loss: 0.0002736609\n",
      "Epoch [12301 / 20000] average reconstruction error: 0.0009704421 , kl(*beta): 7.3791679192 (0.0073791679), reconstruction loss: 0.0002325253\n",
      "Epoch [12401 / 20000] average reconstruction error: 0.0019256623 , kl(*beta): 7.8385550117 (0.0078385550), reconstruction loss: 0.0011418068\n",
      "Epoch [12501 / 20000] average reconstruction error: 0.0012436115 , kl(*beta): 7.4376231384 (0.0074376231), reconstruction loss: 0.0004998492\n",
      "Epoch [12601 / 20000] average reconstruction error: 0.0009346094 , kl(*beta): 7.2016338539 (0.0072016339), reconstruction loss: 0.0002144459\n",
      "Epoch [12701 / 20000] average reconstruction error: 0.0010511610 , kl(*beta): 7.4128615570 (0.0074128616), reconstruction loss: 0.0003098748\n",
      "Epoch [12801 / 20000] average reconstruction error: 0.0018827625 , kl(*beta): 7.4731069183 (0.0074731069), reconstruction loss: 0.0011354517\n",
      "Epoch [12901 / 20000] average reconstruction error: 0.0011177580 , kl(*beta): 7.1179289627 (0.0071179290), reconstruction loss: 0.0004059651\n",
      "Epoch [13001 / 20000] average reconstruction error: 0.0012688521 , kl(*beta): 7.5470972252 (0.0075470972), reconstruction loss: 0.0005141423\n",
      "Epoch [13101 / 20000] average reconstruction error: 0.0010956269 , kl(*beta): 7.3236792946 (0.0073236793), reconstruction loss: 0.0003632590\n",
      "Epoch [13201 / 20000] average reconstruction error: 0.0010016106 , kl(*beta): 6.9221695137 (0.0069221695), reconstruction loss: 0.0003093936\n",
      "Epoch [13301 / 20000] average reconstruction error: 0.0014472542 , kl(*beta): 6.9918550682 (0.0069918551), reconstruction loss: 0.0007480687\n",
      "Epoch [13401 / 20000] average reconstruction error: 0.0010105883 , kl(*beta): 7.3850457191 (0.0073850457), reconstruction loss: 0.0002720837\n",
      "Epoch [13501 / 20000] average reconstruction error: 0.0011559919 , kl(*beta): 7.5301106644 (0.0075301107), reconstruction loss: 0.0004029808\n",
      "Epoch [13601 / 20000] average reconstruction error: 0.0009391510 , kl(*beta): 7.3486914444 (0.0073486914), reconstruction loss: 0.0002042818\n",
      "Epoch [13701 / 20000] average reconstruction error: 0.0009687418 , kl(*beta): 7.0762496758 (0.0070762497), reconstruction loss: 0.0002611168\n",
      "Epoch [13801 / 20000] average reconstruction error: 0.0012577487 , kl(*beta): 7.4751148605 (0.0074751149), reconstruction loss: 0.0005102372\n",
      "Epoch [13901 / 20000] average reconstruction error: 0.0008962535 , kl(*beta): 6.7603086281 (0.0067603086), reconstruction loss: 0.0002202226\n",
      "Epoch [14001 / 20000] average reconstruction error: 0.0010122083 , kl(*beta): 7.0138352203 (0.0070138352), reconstruction loss: 0.0003108247\n",
      "Epoch [14101 / 20000] average reconstruction error: 0.0009215303 , kl(*beta): 7.4746613121 (0.0074746613), reconstruction loss: 0.0001740641\n",
      "Epoch [14201 / 20000] average reconstruction error: 0.0012339773 , kl(*beta): 7.5401035500 (0.0075401035), reconstruction loss: 0.0004799669\n",
      "Epoch [14301 / 20000] average reconstruction error: 0.0017713341 , kl(*beta): 7.2909975815 (0.0072909976), reconstruction loss: 0.0010422343\n",
      "Epoch [14401 / 20000] average reconstruction error: 0.0011288864 , kl(*beta): 7.0540410233 (0.0070540410), reconstruction loss: 0.0004234822\n",
      "Epoch [14501 / 20000] average reconstruction error: 0.0008646588 , kl(*beta): 7.0202210426 (0.0070202210), reconstruction loss: 0.0001626367\n",
      "Epoch [14601 / 20000] average reconstruction error: 0.0008964509 , kl(*beta): 7.0169011879 (0.0070169012), reconstruction loss: 0.0001947608\n",
      "Epoch [14701 / 20000] average reconstruction error: 0.0022221529 , kl(*beta): 7.5056011200 (0.0075056011), reconstruction loss: 0.0014715927\n",
      "Epoch [14801 / 20000] average reconstruction error: 0.0014193052 , kl(*beta): 7.0898836517 (0.0070898837), reconstruction loss: 0.0007103168\n",
      "Epoch [14901 / 20000] average reconstruction error: 0.0014050090 , kl(*beta): 7.4189585114 (0.0074189585), reconstruction loss: 0.0006631131\n",
      "Epoch [15001 / 20000] average reconstruction error: 0.0014914574 , kl(*beta): 7.4201908302 (0.0074201908), reconstruction loss: 0.0007494382\n",
      "Epoch [15101 / 20000] average reconstruction error: 0.0012209626 , kl(*beta): 7.3787138748 (0.0073787139), reconstruction loss: 0.0004830912\n",
      "Epoch [15201 / 20000] average reconstruction error: 0.0009705753 , kl(*beta): 7.0230100250 (0.0070230100), reconstruction loss: 0.0002682742\n",
      "Epoch [15301 / 20000] average reconstruction error: 0.0014393328 , kl(*beta): 7.4491239738 (0.0074491240), reconstruction loss: 0.0006944204\n",
      "Epoch [15401 / 20000] average reconstruction error: 0.0010544862 , kl(*beta): 7.5586376953 (0.0075586377), reconstruction loss: 0.0002986224\n",
      "Epoch [15501 / 20000] average reconstruction error: 0.0010153805 , kl(*beta): 7.2553166771 (0.0072553167), reconstruction loss: 0.0002898488\n",
      "Epoch [15601 / 20000] average reconstruction error: 0.0021626780 , kl(*beta): 8.1210812569 (0.0081210813), reconstruction loss: 0.0013505698\n",
      "Epoch [15701 / 20000] average reconstruction error: 0.0010371863 , kl(*beta): 7.5611037827 (0.0075611038), reconstruction loss: 0.0002810759\n",
      "Epoch [15801 / 20000] average reconstruction error: 0.0009281449 , kl(*beta): 7.4193352509 (0.0074193353), reconstruction loss: 0.0001862114\n",
      "Epoch [15901 / 20000] average reconstruction error: 0.0010011434 , kl(*beta): 7.4592512131 (0.0074592512), reconstruction loss: 0.0002552182\n",
      "Epoch [16001 / 20000] average reconstruction error: 0.0022732707 , kl(*beta): 8.2767066193 (0.0082767066), reconstruction loss: 0.0014456000\n",
      "Epoch [16101 / 20000] average reconstruction error: 0.0012173973 , kl(*beta): 7.2581028748 (0.0072581029), reconstruction loss: 0.0004915869\n",
      "Epoch [16201 / 20000] average reconstruction error: 0.0010339330 , kl(*beta): 7.2901714706 (0.0072901715), reconstruction loss: 0.0003049159\n",
      "Epoch [16301 / 20000] average reconstruction error: 0.0010893102 , kl(*beta): 7.8206727219 (0.0078206727), reconstruction loss: 0.0003072429\n",
      "Epoch [16401 / 20000] average reconstruction error: 0.0012151780 , kl(*beta): 7.0655085945 (0.0070655086), reconstruction loss: 0.0005086271\n",
      "Epoch [16501 / 20000] average reconstruction error: 0.0009691620 , kl(*beta): 7.2081051254 (0.0072081051), reconstruction loss: 0.0002483514\n",
      "Epoch [16601 / 20000] average reconstruction error: 0.0010102444 , kl(*beta): 7.4183690453 (0.0074183690), reconstruction loss: 0.0002684074\n",
      "Epoch [16701 / 20000] average reconstruction error: 0.0010038224 , kl(*beta): 7.2399219131 (0.0072399219), reconstruction loss: 0.0002798302\n",
      "Epoch [16801 / 20000] average reconstruction error: 0.0009533480 , kl(*beta): 7.2019116020 (0.0072019116), reconstruction loss: 0.0002331568\n",
      "Epoch [16901 / 20000] average reconstruction error: 0.0051461119 , kl(*beta): 7.7539731789 (0.0077539732), reconstruction loss: 0.0043707145\n",
      "Epoch [17001 / 20000] average reconstruction error: 0.0009472818 , kl(*beta): 7.3772899246 (0.0073772899), reconstruction loss: 0.0002095527\n",
      "Epoch [17101 / 20000] average reconstruction error: 0.0016912191 , kl(*beta): 7.3251047325 (0.0073251047), reconstruction loss: 0.0009587085\n",
      "Epoch [17201 / 20000] average reconstruction error: 0.0028831845 , kl(*beta): 7.7791457558 (0.0077791458), reconstruction loss: 0.0021052698\n",
      "Epoch [17301 / 20000] average reconstruction error: 0.0017706513 , kl(*beta): 7.5524953651 (0.0075524954), reconstruction loss: 0.0010154017\n",
      "Epoch [17401 / 20000] average reconstruction error: 0.0010557364 , kl(*beta): 7.2460880089 (0.0072460880), reconstruction loss: 0.0003311275\n",
      "Epoch [17501 / 20000] average reconstruction error: 0.0009783294 , kl(*beta): 7.1056445694 (0.0071056446), reconstruction loss: 0.0002677649\n",
      "Epoch [17601 / 20000] average reconstruction error: 0.0010096715 , kl(*beta): 7.4257375717 (0.0074257376), reconstruction loss: 0.0002670977\n",
      "Epoch [17701 / 20000] average reconstruction error: 0.0012942363 , kl(*beta): 7.2351503754 (0.0072351504), reconstruction loss: 0.0005707212\n",
      "Epoch [17801 / 20000] average reconstruction error: 0.0010231152 , kl(*beta): 7.2590868568 (0.0072590869), reconstruction loss: 0.0002972065\n",
      "Epoch [17901 / 20000] average reconstruction error: 0.0009401112 , kl(*beta): 6.9075914574 (0.0069075915), reconstruction loss: 0.0002493520\n",
      "Epoch [18001 / 20000] average reconstruction error: 0.0017788190 , kl(*beta): 7.3901765060 (0.0073901765), reconstruction loss: 0.0010398013\n",
      "Epoch [18101 / 20000] average reconstruction error: 0.0011847052 , kl(*beta): 7.2908952141 (0.0072908952), reconstruction loss: 0.0004556157\n",
      "Epoch [18201 / 20000] average reconstruction error: 0.0010919704 , kl(*beta): 7.1257997322 (0.0071257997), reconstruction loss: 0.0003793904\n",
      "Epoch [18301 / 20000] average reconstruction error: 0.0010601128 , kl(*beta): 7.3211315918 (0.0073211316), reconstruction loss: 0.0003279996\n",
      "Epoch [18401 / 20000] average reconstruction error: 0.0013623169 , kl(*beta): 7.5029637718 (0.0075029638), reconstruction loss: 0.0006120205\n",
      "Epoch [18501 / 20000] average reconstruction error: 0.0009167560 , kl(*beta): 7.5712034035 (0.0075712034), reconstruction loss: 0.0001596356\n",
      "Epoch [18601 / 20000] average reconstruction error: 0.0009816112 , kl(*beta): 7.4066643524 (0.0074066644), reconstruction loss: 0.0002409448\n",
      "Epoch [18701 / 20000] average reconstruction error: 0.0014214253 , kl(*beta): 7.7794698524 (0.0077794699), reconstruction loss: 0.0006434783\n",
      "Epoch [18801 / 20000] average reconstruction error: 0.0009518088 , kl(*beta): 7.2600164223 (0.0072600164), reconstruction loss: 0.0002258071\n",
      "Epoch [18901 / 20000] average reconstruction error: 0.0011277675 , kl(*beta): 7.6688211632 (0.0076688212), reconstruction loss: 0.0003608853\n",
      "Epoch [19001 / 20000] average reconstruction error: 0.0009531396 , kl(*beta): 7.5313562012 (0.0075313562), reconstruction loss: 0.0002000039\n",
      "Epoch [19101 / 20000] average reconstruction error: 0.0013070822 , kl(*beta): 7.8197006989 (0.0078197007), reconstruction loss: 0.0005251121\n",
      "Epoch [19201 / 20000] average reconstruction error: 0.0009162531 , kl(*beta): 7.1170123863 (0.0071170124), reconstruction loss: 0.0002045519\n",
      "Epoch [19301 / 20000] average reconstruction error: 0.0013724211 , kl(*beta): 7.6165025902 (0.0076165026), reconstruction loss: 0.0006107708\n",
      "Epoch [19401 / 20000] average reconstruction error: 0.0014643381 , kl(*beta): 7.7995769882 (0.0077995770), reconstruction loss: 0.0006843803\n",
      "Epoch [19501 / 20000] average reconstruction error: 0.0009643908 , kl(*beta): 7.4490873146 (0.0074490873), reconstruction loss: 0.0002194821\n",
      "Epoch [19601 / 20000] average reconstruction error: 0.0009592971 , kl(*beta): 7.1857687950 (0.0071857688), reconstruction loss: 0.0002407201\n",
      "Epoch [19701 / 20000] average reconstruction error: 0.0012042298 , kl(*beta): 7.5925873375 (0.0075925873), reconstruction loss: 0.0004449710\n",
      "Epoch [19801 / 20000] average reconstruction error: 0.0010148402 , kl(*beta): 7.3956939507 (0.0073956940), reconstruction loss: 0.0002752708\n",
      "Epoch [19901 / 20000] average reconstruction error: 0.0010589999 , kl(*beta): 7.2912843895 (0.0072912844), reconstruction loss: 0.0003298714\n"
     ]
    }
   ],
   "source": [
    "torch.set_printoptions(precision=10)\n",
    "p = 15\n",
    "eps = 2\n",
    "t_list = os.listdir(\"data/paper/AneuriskP\" + str(p) + \"eps0\" + str(eps) )[:100]\n",
    "dataset = tDataset(t_list, \"data/paper/AneuriskP\" + str(p) + \"eps0\" + str(eps) )\n",
    "data_loader = DataLoader(dataset, batch_size = batch_size, shuffle=True, collate_fn=my_collate)\n",
    "\n",
    "\n",
    "mult = mv.numberNodes(data_loader, batch_size)\n",
    "feature_size = 64\n",
    "latent_size = feature_size\n",
    "hidden_size_encoder = 512\n",
    "hidden_size_decoder = 256\n",
    "\n",
    "Grassencoder = mv.GRASSEncoder(input_size = 4, feature_size=feature_size, hidden_size=hidden_size_encoder)\n",
    "Grassencoder = Grassencoder.to(device)\n",
    "Grassdecoder = mv.GRASSDecoder(latent_size=latent_size, hidden_size=hidden_size_decoder, mult = mult)\n",
    "Grassdecoder = Grassdecoder.to(device)\n",
    "\n",
    "mv.setLevel(data_loader)\n",
    "\n",
    "##loop parameters\n",
    "epochs = 20000\n",
    "learning_rate = 1e-4\n",
    "params = list(Grassencoder.parameters()) + list(Grassdecoder.parameters()) \n",
    "opt = torch.optim.Adam(params, lr=learning_rate) \n",
    "total_paramse = sum(param.numel() for param in Grassencoder.parameters())\n",
    "total_paramsd = sum(param.numel() for param in Grassdecoder.parameters())\n",
    "print(\"total parameters encoder \", total_paramse)\n",
    "print(\"total parameters decoder\", total_paramsd)\n",
    "print(\"total parameters\", total_paramse + total_paramsd)\n",
    "\n",
    "Grassencoder.train()\n",
    "Grassdecoder.train()\n",
    "\n",
    "config = {\n",
    "\"learning_rate\": learning_rate,\n",
    "\"epochs\": epochs,\n",
    "\"batch_size\": batch_size,\n",
    "\"dataset\": t_list,\n",
    "\"number of trees\": len(data_loader)*batch_size,\n",
    "\"optim\": opt,\n",
    "\"latent_size\" : latent_size,\n",
    "\"params\":total_paramse + total_paramsd,\n",
    "\"prof\": p,\n",
    "}\n",
    "wandb.init(project=\"MIA\", entity=\"paufeldman\", config = config)\n",
    "\n",
    "train_model(epochs, data_loader, Grassencoder, Grassdecoder, opt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('py_torc')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8f3e717cd274da89498094fde320e6eab1bf0f52911d27cf47473187acb3fe8a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
