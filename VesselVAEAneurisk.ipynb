{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "torch.manual_seed(125)\n",
    "import random\n",
    "random.seed(125)\n",
    "import torch_f as torch_f\n",
    "import modelovae as mv\n",
    "import meshSubplot as ms\n",
    "import wandb\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_gpu = True\n",
    "device = torch.device(\"cuda:0\" if use_gpu and torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encodeStructureFold(fold, root):\n",
    "    '''Folds the tree by depth, so that nodes at the same depth can go in to the \n",
    "    encoder at the same time, reducing computational cost'''\n",
    "    def encodeNode(node):\n",
    "        \n",
    "        if node is None:\n",
    "            return\n",
    "        \n",
    "        if node.isLeaf():\n",
    "            return fold.add('leafEncoder', node.radius)\n",
    "        else:\n",
    "            left = encodeNode(node.left)\n",
    "            right = encodeNode(node.right)\n",
    "            if left is not None and right is not None:\n",
    "                return fold.add('bifurcationEncoder', node.radius, right, left)\n",
    "            elif right is not None:\n",
    "                return fold.add('internalEncoder', node.radius, right)\n",
    "            elif left is not None:\n",
    "                return fold.add('internalEncoder', node.radius, left)\n",
    "        \n",
    "\n",
    "    encoding = encodeNode(root)\n",
    "    return fold.add('sampleEncoder', encoding)\n",
    "\n",
    "def encode_structure(root, Grassencoder):\n",
    "        \n",
    "    def encode_node(node, Grassencoder):\n",
    "          \n",
    "        if node is None:\n",
    "            return\n",
    "        if node.isLeaf():\n",
    "            return Grassencoder.leafEncoder(node.radius.reshape(-1,4))\n",
    "        else :\n",
    "            left = encode_node(node.left, Grassencoder)\n",
    "            right = encode_node(node.right, Grassencoder)\n",
    "            if left is not None and right is not None:\n",
    "                return Grassencoder.bifurcationEncoder(node.radius.reshape(-1,4), right, left)\n",
    "            if right is not None:\n",
    "                return Grassencoder.internalEncoder(node.radius.reshape(-1,4), right)\n",
    "            if left is not None:\n",
    "                return Grassencoder.internalEncoder(node.radius.reshape(-1,4), left)\n",
    "\n",
    "    encoding = encode_node(root, Grassencoder)\n",
    "    return Grassencoder.sampleEncoder(encoding)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def numerar_nodos(root, count):\n",
    "    if root is not None:\n",
    "        numerar_nodos(root.left, count)\n",
    "        root.data = len(count)\n",
    "        count.append(1)\n",
    "        numerar_nodos(root.right, count)\n",
    "        return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_collate(batch):\n",
    "    return batch\n",
    "\n",
    "\n",
    "class tDataset(Dataset):\n",
    "    def __init__(self, l, dir, transform=None):\n",
    "        self.names = l\n",
    "        self.transform = transform\n",
    "        self.data = [] #lista con las strings de todos los arboles\n",
    "        for file in self.names:\n",
    "            self.data.append(mv.read_tree(file, dir))\n",
    "        #\"data\" is a list of all serialized trees, \"trees\" is a list of the binary trees\n",
    "        self.trees = []\n",
    "        for tree in self.data:\n",
    "            deserial = mv.deserialize(tree)\n",
    "            c = []\n",
    "            numerar_nodos(deserial, c)\n",
    "            self.trees.append({deserial: len(c)})\n",
    "            \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.names)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        tree = self.trees[idx]\n",
    "        return tree\n",
    "\n",
    "batch_size = 4"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decodeStructureFoldGrass(fold, v, root):\n",
    "    ''' Decodes the tree in a depth first fashion, grouping nodes at the same depth\n",
    "    in order to reduce computational cost'''\n",
    "\n",
    "    def decodeNode(fold, v, node, flag):\n",
    "        #multipl = np.round((node.maxlevel+1-node.level)/node.treelevel, decimals=2)\n",
    "        label = fold.add('nodeClassifier', v)\n",
    "      \n",
    "               \n",
    "        if node.childs() == 1 :\n",
    "            \n",
    "            right, radius = fold.add('internalDecoder', v).split(2)\n",
    "            \n",
    "            if node.right:\n",
    "                nodoSiguiente = node.right\n",
    "            else:\n",
    "                nodoSiguiente = node.left\n",
    "            \n",
    "            child_loss = decodeNode(fold, right, nodoSiguiente, flag = 1)\n",
    "            lossEstructura = fold.add('classifyLossEstimator', label, node)\n",
    "            lossAtributo = fold.add('calcularLossAtributo', node, radius)\n",
    "            \n",
    "           \n",
    "            #losse = fold.add('vectorMult', multipl, lossEstructura)\n",
    "            losse = lossEstructura\n",
    "            loss = fold.add('vectorAdder', losse, lossAtributo)\n",
    "            loss2 = fold.add('vectorAdder', loss, child_loss)\n",
    "\n",
    "            return loss2\n",
    "        elif node.childs() == 0 : \n",
    "\n",
    "            radius = fold.add('featureDecoder', v)\n",
    "            \n",
    "            lossEstructura = fold.add('classifyLossEstimator', label, node) \n",
    "            lossAtributo = fold.add('calcularLossAtributo', node, radius)\n",
    "    \n",
    "            #losse = fold.add('vectorMult', multipl, lossEstructura)\n",
    "            losse = lossEstructura\n",
    "            loss =  fold.add('vectorAdder', losse, lossAtributo)   \n",
    "\n",
    "            return loss\n",
    "            \n",
    "        \n",
    "        elif node.childs() == 2 :\n",
    "\n",
    "            left, right, radius = fold.add('bifurcationDecoder', v).split(3)\n",
    "            nodoSiguienteRight = node.right\n",
    "            nodoSiguienteLeft = node.left\n",
    "\n",
    "            if nodoSiguienteRight is not None:\n",
    "                right_loss = decodeNode(fold, right, nodoSiguienteRight, flag = 1)\n",
    "             \n",
    "            if nodoSiguienteLeft is not None:\n",
    "                left_loss  = decodeNode(fold, left, nodoSiguienteLeft, flag = 1)\n",
    "\n",
    "          \n",
    "            \n",
    "            lossEstructura = fold.add('classifyLossEstimator', label, node)\n",
    "            lossAtributo   = fold.add('calcularLossAtributo', node, radius)\n",
    "            #losse = fold.add('vectorMult', multipl, lossEstructura)\n",
    "            losse = lossEstructura\n",
    "            loss = fold.add('vectorAdder', losse, lossAtributo)\n",
    "            loss2 = fold.add('vectorAdder', loss, right_loss)\n",
    "            loss3 = fold.add('vectorAdder', loss2, left_loss)\n",
    "            return loss3\n",
    "            \n",
    "    v1 = fold.add('sampleDecoder', v)\n",
    "    dec = decodeNode (fold, v1, root, flag = 0)\n",
    "    return dec\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SaveBestModel:\n",
    "    \"\"\"\n",
    "    Class to save the best model while training. If the current epoch's \n",
    "    validation loss is less than the previous least less, then save the\n",
    "    model state.\n",
    "    \"\"\"\n",
    "    def __init__(self, best_valid_loss=float('inf')):\n",
    "        self.best_valid_loss = best_valid_loss\n",
    "        \n",
    "    def __call__(\n",
    "        self, current_valid_loss, \n",
    "        epoch, encoder, decoder, optimizer\n",
    "    ):  \n",
    "        if epoch > 50:\n",
    "            if current_valid_loss < self.best_valid_loss:\n",
    "                self.best_valid_loss = current_valid_loss\n",
    "                #'classifier_state_dict': classifier.state_dict(),\n",
    "                torch.save({\n",
    "                    'epoch': epoch+1,\n",
    "                    'encoder_state_dict': encoder.state_dict(),\n",
    "                    'decoder_state_dict': decoder.state_dict(),\n",
    "                    'loss' : self.best_valid_loss,\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    }, 'ablation/IntraP15eps01-best.pth')\n",
    "\n",
    "class SaveLastModel:\n",
    "    \"\"\"\n",
    "    Class to save the model while training. \n",
    "    \"\"\"  \n",
    "    def __call__( self,  epoch, encoder, decoder, optimizer):\n",
    "        torch.save({\n",
    "            'epoch': epoch+1,\n",
    "            'encoder_state_dict': encoder.state_dict(),\n",
    "            'decoder_state_dict': decoder.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            }, 'ablation/IntraP15eps01-last.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def escalon_beta (e, corte):\n",
    "    l = np.linspace(e,e,corte)\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_Level(tree, n_nodes):\n",
    "    max_level = 0  \n",
    "    for x in range(0, n_nodes):\n",
    "        level = mv.getLevel(tree, x)\n",
    "        if level > max_level:\n",
    "            max_level = level\n",
    "        if (level):\n",
    "            node = mv.searchNode(tree, x)\n",
    "            node.level = mv.getLevel(tree, x)\n",
    "        else:\n",
    "            print(x, \"is not present in tree\")\n",
    "    tree_level = []\n",
    "    tree.getTreeLevel(tree, tree_level)\n",
    "    tree_level = [max_level - nodelevel for nodelevel in tree_level]\n",
    "    tree.setTreeLevel(tree, sum(tree_level))\n",
    "    tree.setMaxLevel(tree, max_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(epochs, data_loader, Grassencoder, Grassdecoder, opt):\n",
    " \n",
    "    save_last_model = SaveLastModel()\n",
    "    save_best_model = SaveBestModel()\n",
    "    train_loss_avg = []\n",
    "    betas = escalon_beta(.001, 400000)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "    \n",
    "        beta = betas[epoch]\n",
    "        train_loss_avg.append(0)\n",
    "\n",
    "        epochTotalLoss = 0\n",
    "        epochReconLoss = 0\n",
    "        epochKLDivLoss = 0\n",
    "        epochKLDivLossBeta = 0\n",
    "\n",
    "        for batch_idx, batch in enumerate(data_loader):            \n",
    "            \n",
    "            enc_fold = torch_f.Fold(device)\n",
    "            \n",
    "            enc_fold_nodes = []     \n",
    "            n_nodes = []\n",
    "            for tree in batch: #example es un arbolito\n",
    "                example = list(tree.keys())[0]\n",
    "                n = tree[example]#[0]\n",
    "                n_nodes.append(n)\n",
    "                enc_fold_nodes.append(encodeStructureFold(enc_fold, example))\n",
    "            \n",
    "            enc_fold_nodes = enc_fold.apply(Grassencoder, [enc_fold_nodes])\n",
    "            \n",
    "            enc_fold_nodes = torch.split(enc_fold_nodes[0], 1, 0)\n",
    "            \n",
    "            dec_fold = torch_f.Fold(device)\n",
    "            dec_fold_nodes = []\n",
    "            kld_fold_nodes = []\n",
    "\n",
    "            for tree, fnode in zip(batch, enc_fold_nodes):\n",
    "                example = list(tree.keys())[0]\n",
    "                root_code, kl_div = torch.chunk(fnode, 2, 1)\n",
    "                dec_fold_nodes.append(decodeStructureFoldGrass(dec_fold, root_code, example))\n",
    "                kld_fold_nodes.append(kl_div)\n",
    "                \n",
    "            total_loss = dec_fold.apply(Grassdecoder, [dec_fold_nodes, kld_fold_nodes])\n",
    "            n_nodes = torch.tensor(n_nodes, device = device)\n",
    "            recon_loss = torch.div(total_loss[0], n_nodes)\n",
    "            recon_loss = recon_loss.sum() / len(batch)               # avg. reconstruction loss per example\n",
    "            \n",
    "            kldiv_loss = []\n",
    "            for element in kld_fold_nodes:\n",
    "                l = torch.sum(element)\n",
    "                kldiv_loss.append(l)\n",
    "           \n",
    "            kldiv_loss = sum(kldiv_loss) / len(batch)\n",
    "           \n",
    "            total_loss = recon_loss +  beta*kldiv_loss/10\n",
    "           \n",
    "            opt.zero_grad()\n",
    "            total_loss.backward()\n",
    "            opt.step()\n",
    "            train_loss_avg[-1] += (total_loss.item())\n",
    "            epochTotalLoss += total_loss.item()\n",
    "            epochReconLoss += recon_loss.item()\n",
    "            epochKLDivLoss += kldiv_loss.item()\n",
    "            epochKLDivLossBeta += beta*kldiv_loss.item()\n",
    "\n",
    "        epochTotalLoss /= len(data_loader)\n",
    "        epochReconLoss /= len(data_loader)\n",
    "        epochKLDivLoss /= len(data_loader)\n",
    "        epochKLDivLossBeta  /= len(data_loader)\n",
    "        \n",
    "        \n",
    "        save_best_model(total_loss, epoch, Grassencoder, Grassdecoder, opt)\n",
    "        if epoch % 10 == 0: \n",
    "            wandb.log({'epoch': epoch+1, 'loss': epochTotalLoss, 'kl_div': epochKLDivLoss, 'kl_div (*beta)': epochKLDivLossBeta, 'recon_loss': epochReconLoss, 'beta': beta})\n",
    "        if epoch % 100 == 0:   \n",
    "            save_last_model(epoch, Grassencoder, Grassdecoder, opt)\n",
    "        if epoch % 100 == 0:\n",
    "            print('Epoch [%d / %d] average reconstruction error: %.10f , kl(*beta): %.10f (%.10f), reconstruction loss: %.10f' % (epoch+1, epochs, epochTotalLoss, epochKLDivLoss, epochKLDivLossBeta, epochReconLoss))\n",
    "    return \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FOR LOOP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total parameters encoder  626560\n",
      "total parameters decoder 379911\n",
      "total parameters 1006471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mpaufeldman\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.6 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\User\\Documents\\MICCAI\\VesselVAEMIA\\wandb\\run-20240422_090020-lirnd574</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/paufeldman/MIA/runs/lirnd574' target=\"_blank\">still-salad-82</a></strong> to <a href='https://wandb.ai/paufeldman/MIA' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/paufeldman/MIA' target=\"_blank\">https://wandb.ai/paufeldman/MIA</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/paufeldman/MIA/runs/lirnd574' target=\"_blank\">https://wandb.ai/paufeldman/MIA/runs/lirnd574</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1 / 20000] average reconstruction error: 0.1549149275 , kl(*beta): 0.0762657556 (0.0000762658), reconstruction loss: 0.1549072987\n",
      "Epoch [101 / 20000] average reconstruction error: 0.0564641863 , kl(*beta): 9.4217435837 (0.0094217436), reconstruction loss: 0.0555220126\n",
      "Epoch [201 / 20000] average reconstruction error: 0.0443855344 , kl(*beta): 13.1489133835 (0.0131489134), reconstruction loss: 0.0430706429\n",
      "Epoch [301 / 20000] average reconstruction error: 0.0391188500 , kl(*beta): 17.3959865189 (0.0173959865), reconstruction loss: 0.0373792513\n",
      "Epoch [401 / 20000] average reconstruction error: 0.0314095104 , kl(*beta): 20.3844422150 (0.0203844422), reconstruction loss: 0.0293710662\n",
      "Epoch [501 / 20000] average reconstruction error: 0.0260086403 , kl(*beta): 21.7398106384 (0.0217398106), reconstruction loss: 0.0238346588\n",
      "Epoch [601 / 20000] average reconstruction error: 0.0222258460 , kl(*beta): 21.4896871948 (0.0214896872), reconstruction loss: 0.0200768774\n",
      "Epoch [701 / 20000] average reconstruction error: 0.0217355653 , kl(*beta): 20.4750151825 (0.0204750152), reconstruction loss: 0.0196880638\n",
      "Epoch [801 / 20000] average reconstruction error: 0.0157934910 , kl(*beta): 20.0920780945 (0.0200920781), reconstruction loss: 0.0137842831\n",
      "Epoch [901 / 20000] average reconstruction error: 0.0192408773 , kl(*beta): 20.3208597565 (0.0203208598), reconstruction loss: 0.0172087912\n",
      "Epoch [1001 / 20000] average reconstruction error: 0.0111084656 , kl(*beta): 18.3129566574 (0.0183129567), reconstruction loss: 0.0092771697\n",
      "Epoch [1101 / 20000] average reconstruction error: 0.0235877839 , kl(*beta): 21.0099404907 (0.0210099405), reconstruction loss: 0.0214867897\n",
      "Epoch [1201 / 20000] average reconstruction error: 0.0096114202 , kl(*beta): 18.8852801514 (0.0188852802), reconstruction loss: 0.0077228921\n",
      "Epoch [1301 / 20000] average reconstruction error: 0.0132869315 , kl(*beta): 18.3997265625 (0.0183997266), reconstruction loss: 0.0114469588\n",
      "Epoch [1401 / 20000] average reconstruction error: 0.0071732704 , kl(*beta): 17.1062813187 (0.0171062813), reconstruction loss: 0.0054626422\n",
      "Epoch [1501 / 20000] average reconstruction error: 0.0070773223 , kl(*beta): 16.8199219513 (0.0168199220), reconstruction loss: 0.0053953300\n",
      "Epoch [1601 / 20000] average reconstruction error: 0.0065895246 , kl(*beta): 15.8669346619 (0.0158669347), reconstruction loss: 0.0050028311\n",
      "Epoch [1701 / 20000] average reconstruction error: 0.0143131859 , kl(*beta): 16.2008153534 (0.0162008154), reconstruction loss: 0.0126931043\n",
      "Epoch [1801 / 20000] average reconstruction error: 0.0053436444 , kl(*beta): 14.9130937195 (0.0149130937), reconstruction loss: 0.0038523349\n",
      "Epoch [1901 / 20000] average reconstruction error: 0.0048071667 , kl(*beta): 14.8739665985 (0.0148739666), reconstruction loss: 0.0033197699\n",
      "Epoch [2001 / 20000] average reconstruction error: 0.0045789054 , kl(*beta): 14.7051705933 (0.0147051706), reconstruction loss: 0.0031083882\n",
      "Epoch [2101 / 20000] average reconstruction error: 0.0044561588 , kl(*beta): 14.1324214172 (0.0141324214), reconstruction loss: 0.0030429166\n",
      "Epoch [2201 / 20000] average reconstruction error: 0.0045292466 , kl(*beta): 13.5175277328 (0.0135175277), reconstruction loss: 0.0031774937\n",
      "Epoch [2301 / 20000] average reconstruction error: 0.0044096902 , kl(*beta): 14.2203038406 (0.0142203038), reconstruction loss: 0.0029876597\n",
      "Epoch [2401 / 20000] average reconstruction error: 0.0147300651 , kl(*beta): 16.4229743958 (0.0164229744), reconstruction loss: 0.0130877674\n",
      "Epoch [2501 / 20000] average reconstruction error: 0.0044139347 , kl(*beta): 14.9235638809 (0.0149235639), reconstruction loss: 0.0029215783\n",
      "Epoch [2601 / 20000] average reconstruction error: 0.0033531617 , kl(*beta): 13.0531207657 (0.0130531208), reconstruction loss: 0.0020478495\n",
      "Epoch [2701 / 20000] average reconstruction error: 0.0041041679 , kl(*beta): 15.6252214432 (0.0156252214), reconstruction loss: 0.0025416457\n",
      "Epoch [2801 / 20000] average reconstruction error: 0.0033672360 , kl(*beta): 13.4500853729 (0.0134500854), reconstruction loss: 0.0020222274\n",
      "Epoch [2901 / 20000] average reconstruction error: 0.0099168847 , kl(*beta): 15.6080013275 (0.0156080013), reconstruction loss: 0.0083560845\n",
      "Epoch [3001 / 20000] average reconstruction error: 0.0120505263 , kl(*beta): 16.2541559219 (0.0162541559), reconstruction loss: 0.0104251105\n",
      "Epoch [3101 / 20000] average reconstruction error: 0.0025807314 , kl(*beta): 12.5490489578 (0.0125490490), reconstruction loss: 0.0013258264\n",
      "Epoch [3201 / 20000] average reconstruction error: 0.0025193371 , kl(*beta): 12.3543489456 (0.0123543489), reconstruction loss: 0.0012839022\n",
      "Epoch [3301 / 20000] average reconstruction error: 0.0065241888 , kl(*beta): 12.7011076736 (0.0127011077), reconstruction loss: 0.0052540781\n",
      "Epoch [3401 / 20000] average reconstruction error: 0.0037183085 , kl(*beta): 15.3094653702 (0.0153094654), reconstruction loss: 0.0021873618\n",
      "Epoch [3501 / 20000] average reconstruction error: 0.0021873849 , kl(*beta): 12.1790143204 (0.0121790143), reconstruction loss: 0.0009694834\n",
      "Epoch [3601 / 20000] average reconstruction error: 0.0026425750 , kl(*beta): 12.8348925018 (0.0128348925), reconstruction loss: 0.0013590856\n",
      "Epoch [3701 / 20000] average reconstruction error: 0.0037867659 , kl(*beta): 14.1492969131 (0.0141492969), reconstruction loss: 0.0023718360\n",
      "Epoch [3801 / 20000] average reconstruction error: 0.0081946265 , kl(*beta): 12.2679588699 (0.0122679589), reconstruction loss: 0.0069678306\n",
      "Epoch [3901 / 20000] average reconstruction error: 0.0021863808 , kl(*beta): 11.5808872986 (0.0115808873), reconstruction loss: 0.0010282920\n",
      "Epoch [4001 / 20000] average reconstruction error: 0.0022712675 , kl(*beta): 13.0501856613 (0.0130501857), reconstruction loss: 0.0009662488\n",
      "Epoch [4101 / 20000] average reconstruction error: 0.0087992765 , kl(*beta): 14.2190216064 (0.0142190216), reconstruction loss: 0.0073773743\n",
      "Epoch [4201 / 20000] average reconstruction error: 0.0019041307 , kl(*beta): 11.8168704605 (0.0118168705), reconstruction loss: 0.0007224436\n",
      "Epoch [4301 / 20000] average reconstruction error: 0.0018869771 , kl(*beta): 11.4030448914 (0.0114030449), reconstruction loss: 0.0007466725\n",
      "Epoch [4401 / 20000] average reconstruction error: 0.0018231257 , kl(*beta): 11.4674725342 (0.0114674725), reconstruction loss: 0.0006763783\n",
      "Epoch [4501 / 20000] average reconstruction error: 0.0020348178 , kl(*beta): 12.0863626480 (0.0120863626), reconstruction loss: 0.0008261814\n",
      "Epoch [4601 / 20000] average reconstruction error: 0.0017185151 , kl(*beta): 10.9565213394 (0.0109565213), reconstruction loss: 0.0006228629\n",
      "Epoch [4701 / 20000] average reconstruction error: 0.0019738123 , kl(*beta): 12.8596814728 (0.0128596815), reconstruction loss: 0.0006878440\n",
      "Epoch [4801 / 20000] average reconstruction error: 0.0017375967 , kl(*beta): 11.8158124924 (0.0118158125), reconstruction loss: 0.0005560154\n",
      "Epoch [4901 / 20000] average reconstruction error: 0.0016476492 , kl(*beta): 11.2124627304 (0.0112124627), reconstruction loss: 0.0005264029\n",
      "Epoch [5001 / 20000] average reconstruction error: 0.0035123412 , kl(*beta): 13.3562586212 (0.0133562586), reconstruction loss: 0.0021767152\n",
      "Epoch [5101 / 20000] average reconstruction error: 0.0030030696 , kl(*beta): 13.6968616867 (0.0136968617), reconstruction loss: 0.0016333833\n",
      "Epoch [5201 / 20000] average reconstruction error: 0.0021017858 , kl(*beta): 13.8846112061 (0.0138846112), reconstruction loss: 0.0007133246\n",
      "Epoch [5301 / 20000] average reconstruction error: 0.0017397188 , kl(*beta): 11.4000114822 (0.0114000115), reconstruction loss: 0.0005997176\n",
      "Epoch [5401 / 20000] average reconstruction error: 0.0023488726 , kl(*beta): 13.2960219955 (0.0132960220), reconstruction loss: 0.0010192703\n",
      "Epoch [5501 / 20000] average reconstruction error: 0.0050664990 , kl(*beta): 16.6178155136 (0.0166178155), reconstruction loss: 0.0034047174\n",
      "Epoch [5601 / 20000] average reconstruction error: 0.0019735009 , kl(*beta): 12.0188342285 (0.0120188342), reconstruction loss: 0.0007716174\n",
      "Epoch [5701 / 20000] average reconstruction error: 0.0022769994 , kl(*beta): 13.5043907547 (0.0135043908), reconstruction loss: 0.0009265603\n",
      "Epoch [5801 / 20000] average reconstruction error: 0.0017106660 , kl(*beta): 11.4790744400 (0.0114790744), reconstruction loss: 0.0005627585\n",
      "Epoch [5901 / 20000] average reconstruction error: 0.0027849077 , kl(*beta): 12.2584518051 (0.0122584518), reconstruction loss: 0.0015590624\n",
      "Epoch [6001 / 20000] average reconstruction error: 0.0015414032 , kl(*beta): 11.1023601913 (0.0111023602), reconstruction loss: 0.0004311671\n",
      "Epoch [6101 / 20000] average reconstruction error: 0.0082304670 , kl(*beta): 13.4024294662 (0.0134024295), reconstruction loss: 0.0068902240\n",
      "Epoch [6201 / 20000] average reconstruction error: 0.0015965815 , kl(*beta): 11.6722977066 (0.0116722977), reconstruction loss: 0.0004293517\n",
      "Epoch [6301 / 20000] average reconstruction error: 0.0016221343 , kl(*beta): 12.1367441559 (0.0121367442), reconstruction loss: 0.0004084598\n",
      "Epoch [6401 / 20000] average reconstruction error: 0.0058650450 , kl(*beta): 14.1586720657 (0.0141586721), reconstruction loss: 0.0044491777\n",
      "Epoch [6501 / 20000] average reconstruction error: 0.0030444844 , kl(*beta): 13.3317619324 (0.0133317619), reconstruction loss: 0.0017113081\n",
      "Epoch [6601 / 20000] average reconstruction error: 0.0062345884 , kl(*beta): 12.6471463394 (0.0126471463), reconstruction loss: 0.0049698737\n",
      "Epoch [6701 / 20000] average reconstruction error: 0.0022057378 , kl(*beta): 12.2893585205 (0.0122893585), reconstruction loss: 0.0009768018\n",
      "Epoch [6801 / 20000] average reconstruction error: 0.0022551209 , kl(*beta): 12.7234432983 (0.0127234433), reconstruction loss: 0.0009827765\n",
      "Epoch [6901 / 20000] average reconstruction error: 0.0058760451 , kl(*beta): 14.7041357040 (0.0147041357), reconstruction loss: 0.0044056315\n",
      "Epoch [7001 / 20000] average reconstruction error: 0.0018851042 , kl(*beta): 12.4257101822 (0.0124257102), reconstruction loss: 0.0006425331\n",
      "Epoch [7101 / 20000] average reconstruction error: 0.0037014501 , kl(*beta): 14.5373898315 (0.0145373898), reconstruction loss: 0.0022477111\n",
      "Epoch [7201 / 20000] average reconstruction error: 0.0019906607 , kl(*beta): 12.3355913925 (0.0123355914), reconstruction loss: 0.0007571015\n",
      "Epoch [7301 / 20000] average reconstruction error: 0.0030779518 , kl(*beta): 14.3234956360 (0.0143234956), reconstruction loss: 0.0016456022\n",
      "Epoch [7401 / 20000] average reconstruction error: 0.0015482121 , kl(*beta): 11.8299549103 (0.0118299549), reconstruction loss: 0.0003652166\n",
      "Epoch [7501 / 20000] average reconstruction error: 0.0019151359 , kl(*beta): 13.9318927765 (0.0139318928), reconstruction loss: 0.0005219465\n",
      "Epoch [7601 / 20000] average reconstruction error: 0.0016414984 , kl(*beta): 12.6027468109 (0.0126027468), reconstruction loss: 0.0003812236\n",
      "Epoch [7701 / 20000] average reconstruction error: 0.0033892080 , kl(*beta): 15.3667272949 (0.0153667273), reconstruction loss: 0.0018525352\n",
      "Epoch [7801 / 20000] average reconstruction error: 0.0017959761 , kl(*beta): 11.0181364059 (0.0110181364), reconstruction loss: 0.0006941623\n",
      "Epoch [7901 / 20000] average reconstruction error: 0.0048204544 , kl(*beta): 13.7839831161 (0.0137839831), reconstruction loss: 0.0034420561\n",
      "Epoch [8001 / 20000] average reconstruction error: 0.0026312269 , kl(*beta): 12.0844338989 (0.0120844339), reconstruction loss: 0.0014227834\n",
      "Epoch [8101 / 20000] average reconstruction error: 0.0026928360 , kl(*beta): 12.3547807693 (0.0123547808), reconstruction loss: 0.0014573578\n",
      "Epoch [8201 / 20000] average reconstruction error: 0.0014701769 , kl(*beta): 11.5034237671 (0.0115034238), reconstruction loss: 0.0003198345\n",
      "Epoch [8301 / 20000] average reconstruction error: 0.0042520836 , kl(*beta): 12.9512378693 (0.0129512379), reconstruction loss: 0.0029569597\n",
      "Epoch [8401 / 20000] average reconstruction error: 0.0157207928 , kl(*beta): 13.3935024643 (0.0133935025), reconstruction loss: 0.0143814426\n",
      "Epoch [8501 / 20000] average reconstruction error: 0.0018083869 , kl(*beta): 11.3890562057 (0.0113890562), reconstruction loss: 0.0006694812\n",
      "Epoch [8601 / 20000] average reconstruction error: 0.0017856779 , kl(*beta): 12.0078439713 (0.0120078440), reconstruction loss: 0.0005848934\n",
      "Epoch [8701 / 20000] average reconstruction error: 0.0033741607 , kl(*beta): 15.8758058548 (0.0158758059), reconstruction loss: 0.0017865800\n",
      "Epoch [8801 / 20000] average reconstruction error: 0.0015659437 , kl(*beta): 11.7966094589 (0.0117966095), reconstruction loss: 0.0003862827\n",
      "Epoch [8901 / 20000] average reconstruction error: 0.0019116638 , kl(*beta): 12.3307017517 (0.0123307018), reconstruction loss: 0.0006785935\n",
      "Epoch [9001 / 20000] average reconstruction error: 0.0017095686 , kl(*beta): 13.1422814941 (0.0131422815), reconstruction loss: 0.0003953404\n",
      "Epoch [9101 / 20000] average reconstruction error: 0.0015204219 , kl(*beta): 11.2645012283 (0.0112645012), reconstruction loss: 0.0003939717\n",
      "Epoch [9201 / 20000] average reconstruction error: 0.0017639486 , kl(*beta): 12.4049500275 (0.0124049500), reconstruction loss: 0.0005234535\n",
      "Epoch [9301 / 20000] average reconstruction error: 0.0016485136 , kl(*beta): 12.4632986069 (0.0124632986), reconstruction loss: 0.0004021836\n",
      "Epoch [9401 / 20000] average reconstruction error: 0.0013201853 , kl(*beta): 10.8182666397 (0.0108182666), reconstruction loss: 0.0002383586\n",
      "Epoch [9501 / 20000] average reconstruction error: 0.0024162106 , kl(*beta): 12.2167665482 (0.0122167665), reconstruction loss: 0.0011945338\n",
      "Epoch [9601 / 20000] average reconstruction error: 0.0016447787 , kl(*beta): 12.4860228729 (0.0124860229), reconstruction loss: 0.0003961763\n",
      "Epoch [9701 / 20000] average reconstruction error: 0.0059951907 , kl(*beta): 13.2949794769 (0.0132949795), reconstruction loss: 0.0046656926\n",
      "Epoch [9801 / 20000] average reconstruction error: 0.0019605914 , kl(*beta): 13.1330460739 (0.0131330461), reconstruction loss: 0.0006472867\n",
      "Epoch [9901 / 20000] average reconstruction error: 0.0037734028 , kl(*beta): 12.8320450592 (0.0128320451), reconstruction loss: 0.0024901983\n",
      "Epoch [10001 / 20000] average reconstruction error: 0.0025406062 , kl(*beta): 12.9708753586 (0.0129708754), reconstruction loss: 0.0012435186\n",
      "Epoch [10101 / 20000] average reconstruction error: 0.0016145780 , kl(*beta): 12.6421981812 (0.0126421982), reconstruction loss: 0.0003503582\n",
      "Epoch [10201 / 20000] average reconstruction error: 0.0015237054 , kl(*beta): 11.4546379852 (0.0114546380), reconstruction loss: 0.0003782415\n",
      "Epoch [10301 / 20000] average reconstruction error: 0.0012598967 , kl(*beta): 11.0288045502 (0.0110288046), reconstruction loss: 0.0001570162\n",
      "Epoch [10401 / 20000] average reconstruction error: 0.0015205021 , kl(*beta): 10.8952964401 (0.0108952964), reconstruction loss: 0.0004309724\n",
      "Epoch [10501 / 20000] average reconstruction error: 0.0020220968 , kl(*beta): 11.3451431274 (0.0113451431), reconstruction loss: 0.0008875824\n",
      "Epoch [10601 / 20000] average reconstruction error: 0.0017054462 , kl(*beta): 11.7442258072 (0.0117442258), reconstruction loss: 0.0005310236\n",
      "Epoch [10701 / 20000] average reconstruction error: 0.0016868655 , kl(*beta): 12.9807286835 (0.0129807287), reconstruction loss: 0.0003887926\n",
      "Epoch [10801 / 20000] average reconstruction error: 0.0016344839 , kl(*beta): 12.6056006622 (0.0126056007), reconstruction loss: 0.0003739237\n",
      "Epoch [10901 / 20000] average reconstruction error: 0.0015636562 , kl(*beta): 11.6696010208 (0.0116696010), reconstruction loss: 0.0003966960\n",
      "Epoch [11001 / 20000] average reconstruction error: 0.0036480638 , kl(*beta): 13.2478865051 (0.0132478865), reconstruction loss: 0.0023232751\n",
      "Epoch [11101 / 20000] average reconstruction error: 0.0014998735 , kl(*beta): 10.6445753098 (0.0106445753), reconstruction loss: 0.0004354159\n",
      "Epoch [11201 / 20000] average reconstruction error: 0.0013086739 , kl(*beta): 10.7149477768 (0.0107149478), reconstruction loss: 0.0002371790\n",
      "Epoch [11301 / 20000] average reconstruction error: 0.0017788115 , kl(*beta): 11.6315883255 (0.0116315883), reconstruction loss: 0.0006156526\n",
      "Epoch [11401 / 20000] average reconstruction error: 0.0031658331 , kl(*beta): 11.7576360703 (0.0117576361), reconstruction loss: 0.0019900694\n",
      "Epoch [11501 / 20000] average reconstruction error: 0.0016292720 , kl(*beta): 11.6123381042 (0.0116123381), reconstruction loss: 0.0004680381\n",
      "Epoch [11601 / 20000] average reconstruction error: 0.0022343829 , kl(*beta): 11.8016603470 (0.0118016603), reconstruction loss: 0.0010542168\n",
      "Epoch [11701 / 20000] average reconstruction error: 0.0016577259 , kl(*beta): 12.1213859558 (0.0121213860), reconstruction loss: 0.0004455872\n",
      "Epoch [11801 / 20000] average reconstruction error: 0.0014615779 , kl(*beta): 11.4070971680 (0.0114070972), reconstruction loss: 0.0003208682\n",
      "Epoch [11901 / 20000] average reconstruction error: 0.0025666979 , kl(*beta): 13.1154789734 (0.0131154790), reconstruction loss: 0.0012551499\n",
      "Epoch [12001 / 20000] average reconstruction error: 0.0013280265 , kl(*beta): 11.1537779999 (0.0111537780), reconstruction loss: 0.0002126486\n",
      "Epoch [12101 / 20000] average reconstruction error: 0.0072406194 , kl(*beta): 12.8399254608 (0.0128399255), reconstruction loss: 0.0059566267\n",
      "Epoch [12201 / 20000] average reconstruction error: 0.0017821321 , kl(*beta): 12.4192989349 (0.0124192989), reconstruction loss: 0.0005402022\n",
      "Epoch [12301 / 20000] average reconstruction error: 0.0013548050 , kl(*beta): 10.6996939850 (0.0106996940), reconstruction loss: 0.0002848355\n",
      "Epoch [12401 / 20000] average reconstruction error: 0.0055528490 , kl(*beta): 14.3192549515 (0.0143192550), reconstruction loss: 0.0041209234\n",
      "Epoch [12501 / 20000] average reconstruction error: 0.0018302923 , kl(*beta): 13.3159221649 (0.0133159222), reconstruction loss: 0.0004987000\n",
      "Epoch [12601 / 20000] average reconstruction error: 0.0014280686 , kl(*beta): 11.7458993530 (0.0117458994), reconstruction loss: 0.0002534786\n",
      "Epoch [12701 / 20000] average reconstruction error: 0.0015180247 , kl(*beta): 12.7975931549 (0.0127975932), reconstruction loss: 0.0002382653\n",
      "Epoch [12801 / 20000] average reconstruction error: 0.0015753583 , kl(*beta): 11.8465188980 (0.0118465189), reconstruction loss: 0.0003907064\n",
      "Epoch [12901 / 20000] average reconstruction error: 0.0013280834 , kl(*beta): 11.6785290909 (0.0116785291), reconstruction loss: 0.0001602304\n",
      "Epoch [13001 / 20000] average reconstruction error: 0.0015523161 , kl(*beta): 12.1760343933 (0.0121760344), reconstruction loss: 0.0003347126\n",
      "Epoch [13101 / 20000] average reconstruction error: 0.0019637920 , kl(*beta): 12.7402827835 (0.0127402828), reconstruction loss: 0.0006897636\n",
      "Epoch [13201 / 20000] average reconstruction error: 0.0032584052 , kl(*beta): 12.3037935257 (0.0123037935), reconstruction loss: 0.0020280258\n",
      "Epoch [13301 / 20000] average reconstruction error: 0.0013498219 , kl(*beta): 11.2505535889 (0.0112505536), reconstruction loss: 0.0002247665\n",
      "Epoch [13401 / 20000] average reconstruction error: 0.0013307932 , kl(*beta): 11.6633598709 (0.0116633599), reconstruction loss: 0.0001644572\n",
      "Epoch [13501 / 20000] average reconstruction error: 0.0014766984 , kl(*beta): 11.5790747833 (0.0115790748), reconstruction loss: 0.0003187908\n",
      "Epoch [13601 / 20000] average reconstruction error: 0.0012889610 , kl(*beta): 10.8426123810 (0.0108426124), reconstruction loss: 0.0002046996\n",
      "Epoch [13701 / 20000] average reconstruction error: 0.0013818173 , kl(*beta): 11.8122400665 (0.0118122401), reconstruction loss: 0.0002005932\n",
      "Epoch [13801 / 20000] average reconstruction error: 0.0016523823 , kl(*beta): 12.6418092728 (0.0126418093), reconstruction loss: 0.0003882013\n",
      "Epoch [13901 / 20000] average reconstruction error: 0.0028568155 , kl(*beta): 12.8382506943 (0.0128382507), reconstruction loss: 0.0015729904\n",
      "Epoch [14001 / 20000] average reconstruction error: 0.0020186760 , kl(*beta): 11.9764537048 (0.0119764537), reconstruction loss: 0.0008210305\n",
      "Epoch [14101 / 20000] average reconstruction error: 0.0014182563 , kl(*beta): 11.6674208069 (0.0116674208), reconstruction loss: 0.0002515141\n",
      "Epoch [14201 / 20000] average reconstruction error: 0.0013190713 , kl(*beta): 11.7813531494 (0.0117813531), reconstruction loss: 0.0001409359\n",
      "Epoch [14301 / 20000] average reconstruction error: 0.0029643136 , kl(*beta): 11.1813955307 (0.0111813955), reconstruction loss: 0.0018461739\n",
      "Epoch [14401 / 20000] average reconstruction error: 0.0015183337 , kl(*beta): 13.4283071136 (0.0134283071), reconstruction loss: 0.0001755029\n",
      "Epoch [14501 / 20000] average reconstruction error: 0.0014467499 , kl(*beta): 11.8221158218 (0.0118221158), reconstruction loss: 0.0002645382\n",
      "Epoch [14601 / 20000] average reconstruction error: 0.0013251013 , kl(*beta): 11.5537282181 (0.0115537282), reconstruction loss: 0.0001697284\n",
      "Epoch [14701 / 20000] average reconstruction error: 0.0023243298 , kl(*beta): 12.8420103836 (0.0128420104), reconstruction loss: 0.0010401287\n",
      "Epoch [14801 / 20000] average reconstruction error: 0.0023263019 , kl(*beta): 11.9367449570 (0.0119367450), reconstruction loss: 0.0011326273\n",
      "Epoch [14901 / 20000] average reconstruction error: 0.0014288996 , kl(*beta): 12.6554911041 (0.0126554911), reconstruction loss: 0.0001633503\n",
      "Epoch [15001 / 20000] average reconstruction error: 0.0013634457 , kl(*beta): 11.5126575470 (0.0115126575), reconstruction loss: 0.0002121798\n",
      "Epoch [15101 / 20000] average reconstruction error: 0.0024056318 , kl(*beta): 13.1868796921 (0.0131868797), reconstruction loss: 0.0010869437\n",
      "Epoch [15201 / 20000] average reconstruction error: 0.0015581479 , kl(*beta): 11.3702139664 (0.0113702140), reconstruction loss: 0.0004211264\n",
      "Epoch [15301 / 20000] average reconstruction error: 0.0014996271 , kl(*beta): 12.9060882568 (0.0129060883), reconstruction loss: 0.0002090182\n",
      "Epoch [15401 / 20000] average reconstruction error: 0.0016903566 , kl(*beta): 12.3594757462 (0.0123594757), reconstruction loss: 0.0004544090\n",
      "Epoch [15501 / 20000] average reconstruction error: 0.0029648974 , kl(*beta): 13.0428205109 (0.0130428205), reconstruction loss: 0.0016606153\n",
      "Epoch [15601 / 20000] average reconstruction error: 0.0025773330 , kl(*beta): 12.8626742172 (0.0128626742), reconstruction loss: 0.0012910655\n",
      "Epoch [15701 / 20000] average reconstruction error: 0.0012395984 , kl(*beta): 10.8667964935 (0.0108667965), reconstruction loss: 0.0001529187\n",
      "Epoch [15801 / 20000] average reconstruction error: 0.0012092961 , kl(*beta): 10.8543698502 (0.0108543699), reconstruction loss: 0.0001238590\n",
      "Epoch [15901 / 20000] average reconstruction error: 0.0012909714 , kl(*beta): 10.2483575821 (0.0102483576), reconstruction loss: 0.0002661356\n",
      "Epoch [16001 / 20000] average reconstruction error: 0.0027497477 , kl(*beta): 13.5657414246 (0.0135657414), reconstruction loss: 0.0013931734\n",
      "Epoch [16101 / 20000] average reconstruction error: 0.0022112658 , kl(*beta): 11.6619701004 (0.0116619701), reconstruction loss: 0.0010450687\n",
      "Epoch [16201 / 20000] average reconstruction error: 0.0038549293 , kl(*beta): 11.8284370804 (0.0118284371), reconstruction loss: 0.0026720855\n",
      "Epoch [16301 / 20000] average reconstruction error: 0.0013704515 , kl(*beta): 11.5404877472 (0.0115404877), reconstruction loss: 0.0002164026\n",
      "Epoch [16401 / 20000] average reconstruction error: 0.0012690625 , kl(*beta): 11.2151646805 (0.0112151647), reconstruction loss: 0.0001475459\n",
      "Epoch [16501 / 20000] average reconstruction error: 0.0014658566 , kl(*beta): 12.2349326324 (0.0122349326), reconstruction loss: 0.0002423633\n",
      "Epoch [16601 / 20000] average reconstruction error: 0.0016320839 , kl(*beta): 11.6667989349 (0.0116667989), reconstruction loss: 0.0004654039\n",
      "Epoch [16701 / 20000] average reconstruction error: 0.0016512374 , kl(*beta): 13.3754874420 (0.0133754874), reconstruction loss: 0.0003136885\n",
      "Epoch [16801 / 20000] average reconstruction error: 0.0013044530 , kl(*beta): 11.4439074707 (0.0114439075), reconstruction loss: 0.0001600622\n",
      "Epoch [16901 / 20000] average reconstruction error: 0.0018003600 , kl(*beta): 12.0870277405 (0.0120870277), reconstruction loss: 0.0005916571\n",
      "Epoch [17001 / 20000] average reconstruction error: 0.0012705257 , kl(*beta): 11.2720193863 (0.0112720194), reconstruction loss: 0.0001433237\n",
      "Epoch [17101 / 20000] average reconstruction error: 0.0019798388 , kl(*beta): 12.7905392838 (0.0127905393), reconstruction loss: 0.0007007848\n",
      "Epoch [17201 / 20000] average reconstruction error: 0.0021591405 , kl(*beta): 13.5133452225 (0.0135133452), reconstruction loss: 0.0008078059\n",
      "Epoch [17301 / 20000] average reconstruction error: 0.0014686098 , kl(*beta): 12.3443764114 (0.0123443764), reconstruction loss: 0.0002341721\n",
      "Epoch [17401 / 20000] average reconstruction error: 0.0017013064 , kl(*beta): 12.8345040894 (0.0128345041), reconstruction loss: 0.0004178559\n",
      "Epoch [17501 / 20000] average reconstruction error: 0.0021428510 , kl(*beta): 12.7773427200 (0.0127773427), reconstruction loss: 0.0008651166\n",
      "Epoch [17601 / 20000] average reconstruction error: 0.0020204342 , kl(*beta): 12.6939805603 (0.0126939806), reconstruction loss: 0.0007510360\n",
      "Epoch [17701 / 20000] average reconstruction error: 0.0026464554 , kl(*beta): 13.6765155029 (0.0136765155), reconstruction loss: 0.0012788037\n",
      "Epoch [17801 / 20000] average reconstruction error: 0.0012357455 , kl(*beta): 11.2462470627 (0.0112462471), reconstruction loss: 0.0001111207\n",
      "Epoch [17901 / 20000] average reconstruction error: 0.0027136519 , kl(*beta): 11.8274657059 (0.0118274657), reconstruction loss: 0.0015309053\n",
      "Epoch [18001 / 20000] average reconstruction error: 0.0012156988 , kl(*beta): 10.9782778931 (0.0109782779), reconstruction loss: 0.0001178710\n",
      "Epoch [18101 / 20000] average reconstruction error: 0.0016473625 , kl(*beta): 12.5448808289 (0.0125448808), reconstruction loss: 0.0003928743\n",
      "Epoch [18201 / 20000] average reconstruction error: 0.0019423893 , kl(*beta): 12.4206497955 (0.0124206498), reconstruction loss: 0.0007003243\n",
      "Epoch [18301 / 20000] average reconstruction error: 0.0015007562 , kl(*beta): 11.5242271042 (0.0115242271), reconstruction loss: 0.0003483334\n",
      "Epoch [18401 / 20000] average reconstruction error: 0.0015440984 , kl(*beta): 12.0058407593 (0.0120058408), reconstruction loss: 0.0003435143\n",
      "Epoch [18501 / 20000] average reconstruction error: 0.0013283734 , kl(*beta): 12.2247274780 (0.0122247275), reconstruction loss: 0.0001059006\n",
      "Epoch [18601 / 20000] average reconstruction error: 0.0013960297 , kl(*beta): 11.4656998825 (0.0114656999), reconstruction loss: 0.0002494596\n",
      "Epoch [18701 / 20000] average reconstruction error: 0.0015435925 , kl(*beta): 13.1153768158 (0.0131153768), reconstruction loss: 0.0002320547\n",
      "Epoch [18801 / 20000] average reconstruction error: 0.0014257446 , kl(*beta): 12.0157542801 (0.0120157543), reconstruction loss: 0.0002241691\n",
      "Epoch [18901 / 20000] average reconstruction error: 0.0014210814 , kl(*beta): 11.9703524399 (0.0119703524), reconstruction loss: 0.0002240461\n",
      "Epoch [19001 / 20000] average reconstruction error: 0.0013019611 , kl(*beta): 11.4647799301 (0.0114647799), reconstruction loss: 0.0001554830\n",
      "Epoch [19101 / 20000] average reconstruction error: 0.0018657885 , kl(*beta): 13.6495801544 (0.0136495802), reconstruction loss: 0.0005008304\n",
      "Epoch [19201 / 20000] average reconstruction error: 0.0013945721 , kl(*beta): 11.7545055008 (0.0117545055), reconstruction loss: 0.0002191215\n",
      "Epoch [19301 / 20000] average reconstruction error: 0.0012071799 , kl(*beta): 10.7342512894 (0.0107342513), reconstruction loss: 0.0001337546\n",
      "Epoch [19401 / 20000] average reconstruction error: 0.0023970134 , kl(*beta): 13.6150151443 (0.0136150151), reconstruction loss: 0.0010355118\n",
      "Epoch [19501 / 20000] average reconstruction error: 0.0034709707 , kl(*beta): 12.7235364532 (0.0127235365), reconstruction loss: 0.0021986170\n",
      "Epoch [19601 / 20000] average reconstruction error: 0.0013908038 , kl(*beta): 11.5965997314 (0.0115965997), reconstruction loss: 0.0002311437\n",
      "Epoch [19701 / 20000] average reconstruction error: 0.0013156602 , kl(*beta): 12.2892955017 (0.0122892955), reconstruction loss: 0.0000867306\n",
      "Epoch [19801 / 20000] average reconstruction error: 0.0013894510 , kl(*beta): 11.5355958176 (0.0115355958), reconstruction loss: 0.0002358914\n",
      "Epoch [19901 / 20000] average reconstruction error: 0.0014479304 , kl(*beta): 11.9054423904 (0.0119054424), reconstruction loss: 0.0002573861\n"
     ]
    }
   ],
   "source": [
    "torch.set_printoptions(precision=10)\n",
    "p = 15\n",
    "eps = 1\n",
    "t_list = os.listdir(\"data/paper/IntraP\" + str(p) + \"eps0\" + str(eps) )[:100]\n",
    "dataset = tDataset(t_list, \"data/paper/IntraP\" + str(p) + \"eps0\" + str(eps) )\n",
    "data_loader = DataLoader(dataset, batch_size = batch_size, shuffle=True, collate_fn=my_collate)\n",
    "\n",
    "\n",
    "mult = mv.numberNodes(data_loader, batch_size)\n",
    "feature_size = 64\n",
    "latent_size = feature_size\n",
    "hidden_size_encoder = 512\n",
    "hidden_size_decoder = 256\n",
    "\n",
    "Grassencoder = mv.GRASSEncoder(input_size = 4, feature_size=feature_size, hidden_size=hidden_size_encoder)\n",
    "Grassencoder = Grassencoder.to(device)\n",
    "Grassdecoder = mv.GRASSDecoder(latent_size=latent_size, hidden_size=hidden_size_decoder, mult = mult)\n",
    "Grassdecoder = Grassdecoder.to(device)\n",
    "\n",
    "mv.setLevel(data_loader)\n",
    "\n",
    "##loop parameters\n",
    "epochs = 20000\n",
    "learning_rate = 1e-4\n",
    "params = list(Grassencoder.parameters()) + list(Grassdecoder.parameters()) \n",
    "opt = torch.optim.Adam(params, lr=learning_rate) \n",
    "total_paramse = sum(param.numel() for param in Grassencoder.parameters())\n",
    "total_paramsd = sum(param.numel() for param in Grassdecoder.parameters())\n",
    "print(\"total parameters encoder \", total_paramse)\n",
    "print(\"total parameters decoder\", total_paramsd)\n",
    "print(\"total parameters\", total_paramse + total_paramsd)\n",
    "\n",
    "Grassencoder.train()\n",
    "Grassdecoder.train()\n",
    "\n",
    "config = {\n",
    "\"learning_rate\": learning_rate,\n",
    "\"epochs\": epochs,\n",
    "\"batch_size\": batch_size,\n",
    "\"dataset\": t_list,\n",
    "\"number of trees\": len(data_loader)*batch_size,\n",
    "\"optim\": opt,\n",
    "\"latent_size\" : latent_size,\n",
    "\"params\":total_paramse + total_paramsd,\n",
    "\"prof\": p,\n",
    "}\n",
    "wandb.init(project=\"MIA\", entity=\"paufeldman\", config = config)\n",
    "\n",
    "train_model(epochs, data_loader, Grassencoder, Grassdecoder, opt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('py_torc')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8f3e717cd274da89498094fde320e6eab1bf0f52911d27cf47473187acb3fe8a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
