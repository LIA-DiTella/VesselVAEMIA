{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "torch.manual_seed(125)\n",
    "import random\n",
    "random.seed(125)\n",
    "import torch_f as torch_f\n",
    "import modelovae as mv\n",
    "import meshSubplot as ms\n",
    "import wandb\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_gpu = True\n",
    "device = torch.device(\"cuda:0\" if use_gpu and torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encodeStructureFold(fold, root):\n",
    "    '''Folds the tree by depth, so that nodes at the same depth can go in to the \n",
    "    encoder at the same time, reducing computational cost'''\n",
    "    def encodeNode(node):\n",
    "        \n",
    "        if node is None:\n",
    "            return\n",
    "        \n",
    "        if node.isLeaf():\n",
    "            return fold.add('leafEncoder', node.radius)\n",
    "        else:\n",
    "            left = encodeNode(node.left)\n",
    "            right = encodeNode(node.right)\n",
    "            if left is not None and right is not None:\n",
    "                return fold.add('bifurcationEncoder', node.radius, right, left)\n",
    "            elif right is not None:\n",
    "                return fold.add('internalEncoder', node.radius, right)\n",
    "            elif left is not None:\n",
    "                return fold.add('internalEncoder', node.radius, left)\n",
    "        \n",
    "\n",
    "    encoding = encodeNode(root)\n",
    "    return fold.add('sampleEncoder', encoding)\n",
    "\n",
    "def encode_structure(root, Grassencoder):\n",
    "        \n",
    "    def encode_node(node, Grassencoder):\n",
    "          \n",
    "        if node is None:\n",
    "            return\n",
    "        if node.isLeaf():\n",
    "            return Grassencoder.leafEncoder(node.radius.reshape(-1,4))\n",
    "        else :\n",
    "            left = encode_node(node.left, Grassencoder)\n",
    "            right = encode_node(node.right, Grassencoder)\n",
    "            if left is not None and right is not None:\n",
    "                return Grassencoder.bifurcationEncoder(node.radius.reshape(-1,4), right, left)\n",
    "            if right is not None:\n",
    "                return Grassencoder.internalEncoder(node.radius.reshape(-1,4), right)\n",
    "            if left is not None:\n",
    "                return Grassencoder.internalEncoder(node.radius.reshape(-1,4), left)\n",
    "\n",
    "    encoding = encode_node(root, Grassencoder)\n",
    "    return Grassencoder.sampleEncoder(encoding)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def numerar_nodos(root, count):\n",
    "    if root is not None:\n",
    "        numerar_nodos(root.left, count)\n",
    "        root.data = len(count)\n",
    "        count.append(1)\n",
    "        numerar_nodos(root.right, count)\n",
    "        return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_collate(batch):\n",
    "    return batch\n",
    "\n",
    "\n",
    "class tDataset(Dataset):\n",
    "    def __init__(self, l, dir, transform=None):\n",
    "        self.names = l\n",
    "        self.transform = transform\n",
    "        self.data = [] #lista con las strings de todos los arboles\n",
    "        for file in self.names:\n",
    "            self.data.append(mv.read_tree(file, dir))\n",
    "        #\"data\" is a list of all serialized trees, \"trees\" is a list of the binary trees\n",
    "        self.trees = []\n",
    "        for tree in self.data:\n",
    "            deserial = mv.deserialize(tree)\n",
    "            c = []\n",
    "            numerar_nodos(deserial, c)\n",
    "            self.trees.append({deserial: len(c)})\n",
    "            \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.names)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        tree = self.trees[idx]\n",
    "        return tree\n",
    "\n",
    "batch_size = 4"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decodeStructureFoldGrass(fold, v, root):\n",
    "    ''' Decodes the tree in a depth first fashion, grouping nodes at the same depth\n",
    "    in order to reduce computational cost'''\n",
    "\n",
    "    def decodeNode(fold, v, node, flag):\n",
    "        multipl = np.round((node.maxlevel+1-node.level)/node.treelevel, decimals=2)\n",
    "        label = fold.add('nodeClassifier', v)\n",
    "      \n",
    "               \n",
    "        if node.childs() == 1 :\n",
    "            \n",
    "            right, radius = fold.add('internalDecoder', v).split(2)\n",
    "            \n",
    "            if node.right:\n",
    "                nodoSiguiente = node.right\n",
    "            else:\n",
    "                nodoSiguiente = node.left\n",
    "            \n",
    "            child_loss = decodeNode(fold, right, nodoSiguiente, flag = 1)\n",
    "            lossEstructura = fold.add('classifyLossEstimator', label, node)\n",
    "            lossAtributo = fold.add('calcularLossAtributo', node, radius)\n",
    "            \n",
    "           \n",
    "            losse = fold.add('vectorMult', multipl, lossEstructura)\n",
    "            loss = fold.add('vectorAdder', losse, lossAtributo)\n",
    "            loss2 = fold.add('vectorAdder', loss, child_loss)\n",
    "\n",
    "            return loss2\n",
    "        elif node.childs() == 0 : \n",
    "\n",
    "            radius = fold.add('featureDecoder', v)\n",
    "            \n",
    "            lossEstructura = fold.add('classifyLossEstimator', label, node) \n",
    "            lossAtributo = fold.add('calcularLossAtributo', node, radius)\n",
    "    \n",
    "            losse = fold.add('vectorMult', multipl, lossEstructura)\n",
    "            loss =  fold.add('vectorAdder', losse, lossAtributo)   \n",
    "\n",
    "            return loss\n",
    "            \n",
    "        \n",
    "        elif node.childs() == 2 :\n",
    "\n",
    "            left, right, radius = fold.add('bifurcationDecoder', v).split(3)\n",
    "            nodoSiguienteRight = node.right\n",
    "            nodoSiguienteLeft = node.left\n",
    "\n",
    "            if nodoSiguienteRight is not None:\n",
    "                right_loss = decodeNode(fold, right, nodoSiguienteRight, flag = 1)\n",
    "             \n",
    "            if nodoSiguienteLeft is not None:\n",
    "                left_loss  = decodeNode(fold, left, nodoSiguienteLeft, flag = 1)\n",
    "\n",
    "          \n",
    "            \n",
    "            lossEstructura = fold.add('classifyLossEstimator', label, node)\n",
    "            lossAtributo   = fold.add('calcularLossAtributo', node, radius)\n",
    "            losse = fold.add('vectorMult', multipl, lossEstructura)\n",
    "            loss = fold.add('vectorAdder', losse, lossAtributo)\n",
    "            loss2 = fold.add('vectorAdder', loss, right_loss)\n",
    "            loss3 = fold.add('vectorAdder', loss2, left_loss)\n",
    "            return loss3\n",
    "            \n",
    "    v1 = fold.add('sampleDecoder', v)\n",
    "    dec = decodeNode (fold, v1, root, flag = 0)\n",
    "    return dec\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SaveBestModel:\n",
    "    \"\"\"\n",
    "    Class to save the best model while training. If the current epoch's \n",
    "    validation loss is less than the previous least less, then save the\n",
    "    model state.\n",
    "    \"\"\"\n",
    "    def __init__(self, best_valid_loss=float('inf')):\n",
    "        self.best_valid_loss = best_valid_loss\n",
    "        \n",
    "    def __call__(\n",
    "        self, current_valid_loss, \n",
    "        epoch, encoder, decoder, optimizer\n",
    "    ):  \n",
    "        if epoch > 50:\n",
    "            if current_valid_loss < self.best_valid_loss:\n",
    "                self.best_valid_loss = current_valid_loss\n",
    "                #'classifier_state_dict': classifier.state_dict(),\n",
    "                torch.save({\n",
    "                    'epoch': epoch+1,\n",
    "                    'encoder_state_dict': encoder.state_dict(),\n",
    "                    'decoder_state_dict': decoder.state_dict(),\n",
    "                    'loss' : self.best_valid_loss,\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    }, 'output/IntraP5eps01-best.pth')\n",
    "\n",
    "class SaveLastModel:\n",
    "    \"\"\"\n",
    "    Class to save the model while training. \n",
    "    \"\"\"  \n",
    "    def __call__( self,  epoch, encoder, decoder, optimizer):\n",
    "        torch.save({\n",
    "            'epoch': epoch+1,\n",
    "            'encoder_state_dict': encoder.state_dict(),\n",
    "            'decoder_state_dict': decoder.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            }, 'output/IntraP5eps01-last.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def escalon_beta (e, corte):\n",
    "    l = np.linspace(e,e,corte)\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_Level(tree, n_nodes):\n",
    "    max_level = 0  \n",
    "    for x in range(0, n_nodes):\n",
    "        level = mv.getLevel(tree, x)\n",
    "        if level > max_level:\n",
    "            max_level = level\n",
    "        if (level):\n",
    "            node = mv.searchNode(tree, x)\n",
    "            node.level = mv.getLevel(tree, x)\n",
    "        else:\n",
    "            print(x, \"is not present in tree\")\n",
    "    tree_level = []\n",
    "    tree.getTreeLevel(tree, tree_level)\n",
    "    tree_level = [max_level - nodelevel for nodelevel in tree_level]\n",
    "    tree.setTreeLevel(tree, sum(tree_level))\n",
    "    tree.setMaxLevel(tree, max_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(epochs, data_loader, Grassencoder, Grassdecoder, opt):\n",
    " \n",
    "    save_last_model = SaveLastModel()\n",
    "    save_best_model = SaveBestModel()\n",
    "    train_loss_avg = []\n",
    "    betas = escalon_beta(.001, 400000)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "    \n",
    "        beta = betas[epoch]\n",
    "        train_loss_avg.append(0)\n",
    "\n",
    "        epochTotalLoss = 0\n",
    "        epochReconLoss = 0\n",
    "        epochKLDivLoss = 0\n",
    "        epochKLDivLossBeta = 0\n",
    "\n",
    "        for batch_idx, batch in enumerate(data_loader):            \n",
    "            \n",
    "            enc_fold = torch_f.Fold(device)\n",
    "            \n",
    "            enc_fold_nodes = []     \n",
    "            n_nodes = []\n",
    "            for tree in batch: #example es un arbolito\n",
    "                example = list(tree.keys())[0]\n",
    "                n = tree[example]#[0]\n",
    "                n_nodes.append(n)\n",
    "                enc_fold_nodes.append(encodeStructureFold(enc_fold, example))\n",
    "            \n",
    "            enc_fold_nodes = enc_fold.apply(Grassencoder, [enc_fold_nodes])\n",
    "            \n",
    "            enc_fold_nodes = torch.split(enc_fold_nodes[0], 1, 0)\n",
    "            \n",
    "            dec_fold = torch_f.Fold(device)\n",
    "            dec_fold_nodes = []\n",
    "            kld_fold_nodes = []\n",
    "\n",
    "            for tree, fnode in zip(batch, enc_fold_nodes):\n",
    "                example = list(tree.keys())[0]\n",
    "                root_code, kl_div = torch.chunk(fnode, 2, 1)\n",
    "                dec_fold_nodes.append(decodeStructureFoldGrass(dec_fold, root_code, example))\n",
    "                kld_fold_nodes.append(kl_div)\n",
    "                \n",
    "            total_loss = dec_fold.apply(Grassdecoder, [dec_fold_nodes, kld_fold_nodes])\n",
    "            n_nodes = torch.tensor(n_nodes, device = device)\n",
    "            recon_loss = torch.div(total_loss[0], n_nodes)\n",
    "            recon_loss = recon_loss.sum() / len(batch)               # avg. reconstruction loss per example\n",
    "            \n",
    "            kldiv_loss = []\n",
    "            for element in kld_fold_nodes:\n",
    "                l = torch.sum(element)\n",
    "                kldiv_loss.append(l)\n",
    "           \n",
    "            kldiv_loss = sum(kldiv_loss) / len(batch)\n",
    "           \n",
    "            total_loss = recon_loss +  beta*kldiv_loss/10\n",
    "           \n",
    "            opt.zero_grad()\n",
    "            total_loss.backward()\n",
    "            opt.step()\n",
    "            train_loss_avg[-1] += (total_loss.item())\n",
    "            epochTotalLoss += total_loss.item()\n",
    "            epochReconLoss += recon_loss.item()\n",
    "            epochKLDivLoss += kldiv_loss.item()\n",
    "            epochKLDivLossBeta += beta*kldiv_loss.item()\n",
    "\n",
    "        epochTotalLoss /= len(data_loader)\n",
    "        epochReconLoss /= len(data_loader)\n",
    "        epochKLDivLoss /= len(data_loader)\n",
    "        epochKLDivLossBeta  /= len(data_loader)\n",
    "        \n",
    "        \n",
    "        save_best_model(total_loss, epoch, Grassencoder, Grassdecoder, opt)\n",
    "        if epoch % 10 == 0: \n",
    "            wandb.log({'epoch': epoch+1, 'loss': epochTotalLoss, 'kl_div': epochKLDivLoss, 'kl_div (*beta)': epochKLDivLossBeta, 'recon_loss': epochReconLoss, 'beta': beta})\n",
    "        if epoch % 100 == 0:   \n",
    "            save_last_model(epoch, Grassencoder, Grassdecoder, opt)\n",
    "        if epoch % 100 == 0:\n",
    "            print('Epoch [%d / %d] average reconstruction error: %.10f , kl(*beta): %.10f (%.10f), reconstruction loss: %.10f' % (epoch+1, epochs, epochTotalLoss, epochKLDivLoss, epochKLDivLossBeta, epochReconLoss))\n",
    "    return \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FOR LOOP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total parameters encoder  626560\n",
      "total parameters decoder 379911\n",
      "total parameters 1006471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mpaufeldman\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\User\\Documents\\vesselvaeashish\\VesselVAE\\wandb\\run-20240208_104724-uatv0ew4</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/paufeldman/MIA/runs/uatv0ew4' target=\"_blank\">restful-bird-39</a></strong> to <a href='https://wandb.ai/paufeldman/MIA' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/paufeldman/MIA' target=\"_blank\">https://wandb.ai/paufeldman/MIA</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/paufeldman/MIA/runs/uatv0ew4' target=\"_blank\">https://wandb.ai/paufeldman/MIA/runs/uatv0ew4</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1 / 20000] average reconstruction error: 0.1270289689 , kl(*beta): 0.0816377684 (0.0000816378), reconstruction loss: 0.1270208049\n",
      "Epoch [101 / 20000] average reconstruction error: 0.0204502714 , kl(*beta): 11.5204441071 (0.0115204441), reconstruction loss: 0.0192982270\n",
      "Epoch [201 / 20000] average reconstruction error: 0.0135736323 , kl(*beta): 14.4290743637 (0.0144290744), reconstruction loss: 0.0121307248\n",
      "Epoch [301 / 20000] average reconstruction error: 0.0090397443 , kl(*beta): 15.0502492142 (0.0150502492), reconstruction loss: 0.0075347193\n",
      "Epoch [401 / 20000] average reconstruction error: 0.0055488473 , kl(*beta): 13.4049786377 (0.0134049786), reconstruction loss: 0.0042083493\n",
      "Epoch [501 / 20000] average reconstruction error: 0.0039470470 , kl(*beta): 12.2685623550 (0.0122685624), reconstruction loss: 0.0027201907\n",
      "Epoch [601 / 20000] average reconstruction error: 0.0029561374 , kl(*beta): 11.9064958572 (0.0119064959), reconstruction loss: 0.0017654877\n",
      "Epoch [701 / 20000] average reconstruction error: 0.0025730675 , kl(*beta): 11.4538505173 (0.0114538505), reconstruction loss: 0.0014276824\n",
      "Epoch [801 / 20000] average reconstruction error: 0.0022759026 , kl(*beta): 11.1721430969 (0.0111721431), reconstruction loss: 0.0011586882\n",
      "Epoch [901 / 20000] average reconstruction error: 0.0020330866 , kl(*beta): 11.1876970291 (0.0111876970), reconstruction loss: 0.0009143169\n",
      "Epoch [1001 / 20000] average reconstruction error: 0.0018754644 , kl(*beta): 10.7890412140 (0.0107890412), reconstruction loss: 0.0007965602\n",
      "Epoch [1101 / 20000] average reconstruction error: 0.0018883964 , kl(*beta): 10.8666617966 (0.0108666618), reconstruction loss: 0.0008017302\n",
      "Epoch [1201 / 20000] average reconstruction error: 0.0020247848 , kl(*beta): 10.5643764496 (0.0105643764), reconstruction loss: 0.0009683471\n",
      "Epoch [1301 / 20000] average reconstruction error: 0.0016107887 , kl(*beta): 10.2144694138 (0.0102144694), reconstruction loss: 0.0005893417\n",
      "Epoch [1401 / 20000] average reconstruction error: 0.0017636385 , kl(*beta): 10.0417672348 (0.0100417672), reconstruction loss: 0.0007594617\n",
      "Epoch [1501 / 20000] average reconstruction error: 0.0016278682 , kl(*beta): 10.2137322235 (0.0102137322), reconstruction loss: 0.0006064949\n",
      "Epoch [1601 / 20000] average reconstruction error: 0.0013820926 , kl(*beta): 9.5398311996 (0.0095398312), reconstruction loss: 0.0004281095\n",
      "Epoch [1701 / 20000] average reconstruction error: 0.0014610537 , kl(*beta): 10.1283398438 (0.0101283398), reconstruction loss: 0.0004482196\n",
      "Epoch [1801 / 20000] average reconstruction error: 0.0016513892 , kl(*beta): 9.8695114136 (0.0098695114), reconstruction loss: 0.0006644380\n",
      "Epoch [1901 / 20000] average reconstruction error: 0.0014916358 , kl(*beta): 9.6118507385 (0.0096118507), reconstruction loss: 0.0005304506\n",
      "Epoch [2001 / 20000] average reconstruction error: 0.0014090358 , kl(*beta): 9.8492160416 (0.0098492160), reconstruction loss: 0.0004241141\n",
      "Epoch [2101 / 20000] average reconstruction error: 0.0016367655 , kl(*beta): 11.1786654282 (0.0111786654), reconstruction loss: 0.0005188989\n",
      "Epoch [2201 / 20000] average reconstruction error: 0.0013034685 , kl(*beta): 9.1743592072 (0.0091743592), reconstruction loss: 0.0003860326\n",
      "Epoch [2301 / 20000] average reconstruction error: 0.0012332736 , kl(*beta): 9.1377583694 (0.0091377584), reconstruction loss: 0.0003194977\n",
      "Epoch [2401 / 20000] average reconstruction error: 0.0012232855 , kl(*beta): 8.9970276260 (0.0089970276), reconstruction loss: 0.0003235826\n",
      "Epoch [2501 / 20000] average reconstruction error: 0.0013584033 , kl(*beta): 9.5498548126 (0.0095498548), reconstruction loss: 0.0004034178\n",
      "Epoch [2601 / 20000] average reconstruction error: 0.0012461458 , kl(*beta): 9.2890028763 (0.0092890029), reconstruction loss: 0.0003172454\n",
      "Epoch [2701 / 20000] average reconstruction error: 0.0010941390 , kl(*beta): 8.8273401642 (0.0088273402), reconstruction loss: 0.0002114050\n",
      "Epoch [2801 / 20000] average reconstruction error: 0.0011681590 , kl(*beta): 8.8168346024 (0.0088168346), reconstruction loss: 0.0002864754\n",
      "Epoch [2901 / 20000] average reconstruction error: 0.0012745623 , kl(*beta): 10.0726248550 (0.0100726249), reconstruction loss: 0.0002672997\n",
      "Epoch [3001 / 20000] average reconstruction error: 0.0010972337 , kl(*beta): 8.5984252739 (0.0085984253), reconstruction loss: 0.0002373911\n",
      "Epoch [3101 / 20000] average reconstruction error: 0.0012139819 , kl(*beta): 9.4168455887 (0.0094168456), reconstruction loss: 0.0002722973\n",
      "Epoch [3201 / 20000] average reconstruction error: 0.0011256733 , kl(*beta): 8.9215886688 (0.0089215887), reconstruction loss: 0.0002335144\n",
      "Epoch [3301 / 20000] average reconstruction error: 0.0011184506 , kl(*beta): 8.6927938461 (0.0086927938), reconstruction loss: 0.0002491712\n",
      "Epoch [3401 / 20000] average reconstruction error: 0.0014700268 , kl(*beta): 9.5182797623 (0.0095182798), reconstruction loss: 0.0005181988\n",
      "Epoch [3501 / 20000] average reconstruction error: 0.0011654689 , kl(*beta): 9.4764357376 (0.0094764357), reconstruction loss: 0.0002178253\n",
      "Epoch [3601 / 20000] average reconstruction error: 0.0010335402 , kl(*beta): 8.6289079857 (0.0086289080), reconstruction loss: 0.0001706493\n",
      "Epoch [3701 / 20000] average reconstruction error: 0.0011698893 , kl(*beta): 9.2295439911 (0.0092295440), reconstruction loss: 0.0002469349\n",
      "Epoch [3801 / 20000] average reconstruction error: 0.0010288763 , kl(*beta): 8.8345703125 (0.0088345703), reconstruction loss: 0.0001454192\n",
      "Epoch [3901 / 20000] average reconstruction error: 0.0015961261 , kl(*beta): 9.2985954285 (0.0092985954), reconstruction loss: 0.0006662664\n",
      "Epoch [4001 / 20000] average reconstruction error: 0.0011438209 , kl(*beta): 8.9328728104 (0.0089328728), reconstruction loss: 0.0002505336\n",
      "Epoch [4101 / 20000] average reconstruction error: 0.0009590790 , kl(*beta): 8.4031855583 (0.0084031856), reconstruction loss: 0.0001187604\n",
      "Epoch [4201 / 20000] average reconstruction error: 0.0009850087 , kl(*beta): 8.5017107773 (0.0085017108), reconstruction loss: 0.0001348375\n",
      "Epoch [4301 / 20000] average reconstruction error: 0.0010955048 , kl(*beta): 9.2010125351 (0.0092010125), reconstruction loss: 0.0001754035\n",
      "Epoch [4401 / 20000] average reconstruction error: 0.0022317068 , kl(*beta): 9.2010358047 (0.0092010358), reconstruction loss: 0.0013116032\n",
      "Epoch [4501 / 20000] average reconstruction error: 0.0013180718 , kl(*beta): 8.7449995041 (0.0087449995), reconstruction loss: 0.0004435718\n",
      "Epoch [4601 / 20000] average reconstruction error: 0.0009586379 , kl(*beta): 8.5457494736 (0.0085457495), reconstruction loss: 0.0001040629\n",
      "Epoch [4701 / 20000] average reconstruction error: 0.0009754541 , kl(*beta): 8.3726104355 (0.0083726104), reconstruction loss: 0.0001381930\n",
      "Epoch [4801 / 20000] average reconstruction error: 0.0010097298 , kl(*beta): 8.7513577271 (0.0087513577), reconstruction loss: 0.0001345940\n",
      "Epoch [4901 / 20000] average reconstruction error: 0.0011514757 , kl(*beta): 9.1132633209 (0.0091132633), reconstruction loss: 0.0002401494\n",
      "Epoch [5001 / 20000] average reconstruction error: 0.0010896765 , kl(*beta): 9.1538557816 (0.0091538558), reconstruction loss: 0.0001742908\n",
      "Epoch [5101 / 20000] average reconstruction error: 0.0009477513 , kl(*beta): 8.5377052498 (0.0085377052), reconstruction loss: 0.0000939807\n",
      "Epoch [5201 / 20000] average reconstruction error: 0.0009709726 , kl(*beta): 8.5712910461 (0.0085712910), reconstruction loss: 0.0001138435\n",
      "Epoch [5301 / 20000] average reconstruction error: 0.0009766422 , kl(*beta): 8.1215244102 (0.0081215244), reconstruction loss: 0.0001644898\n",
      "Epoch [5401 / 20000] average reconstruction error: 0.0021639811 , kl(*beta): 9.0312716293 (0.0090312716), reconstruction loss: 0.0012608538\n",
      "Epoch [5501 / 20000] average reconstruction error: 0.0011605498 , kl(*beta): 8.5485874176 (0.0085485874), reconstruction loss: 0.0003056911\n",
      "Epoch [5601 / 20000] average reconstruction error: 0.0010718352 , kl(*beta): 8.7860935593 (0.0087860936), reconstruction loss: 0.0001932257\n",
      "Epoch [5701 / 20000] average reconstruction error: 0.0013269933 , kl(*beta): 9.3769892120 (0.0093769892), reconstruction loss: 0.0003892943\n",
      "Epoch [5801 / 20000] average reconstruction error: 0.0016486255 , kl(*beta): 9.1983200455 (0.0091983200), reconstruction loss: 0.0007287934\n",
      "Epoch [5901 / 20000] average reconstruction error: 0.0009199142 , kl(*beta): 8.5076197243 (0.0085076197), reconstruction loss: 0.0000691522\n",
      "Epoch [6001 / 20000] average reconstruction error: 0.0009501053 , kl(*beta): 8.6607809067 (0.0086607809), reconstruction loss: 0.0000840272\n",
      "Epoch [6101 / 20000] average reconstruction error: 0.0010026540 , kl(*beta): 8.8577128220 (0.0088577128), reconstruction loss: 0.0001168826\n",
      "Epoch [6201 / 20000] average reconstruction error: 0.0009583895 , kl(*beta): 8.7202798080 (0.0087202798), reconstruction loss: 0.0000863614\n",
      "Epoch [6301 / 20000] average reconstruction error: 0.0011734015 , kl(*beta): 9.1615233994 (0.0091615234), reconstruction loss: 0.0002572491\n",
      "Epoch [6401 / 20000] average reconstruction error: 0.0009386895 , kl(*beta): 8.7241382980 (0.0087241383), reconstruction loss: 0.0000662756\n",
      "Epoch [6501 / 20000] average reconstruction error: 0.0011815981 , kl(*beta): 9.3795258331 (0.0093795258), reconstruction loss: 0.0002436455\n",
      "Epoch [6601 / 20000] average reconstruction error: 0.0009491538 , kl(*beta): 8.2242370605 (0.0082242371), reconstruction loss: 0.0001267301\n",
      "Epoch [6701 / 20000] average reconstruction error: 0.0013828040 , kl(*beta): 9.1454411697 (0.0091454412), reconstruction loss: 0.0004682598\n",
      "Epoch [6801 / 20000] average reconstruction error: 0.0009788093 , kl(*beta): 8.6396614456 (0.0086396614), reconstruction loss: 0.0001148431\n",
      "Epoch [6901 / 20000] average reconstruction error: 0.0008908186 , kl(*beta): 8.1192062569 (0.0081192063), reconstruction loss: 0.0000788980\n",
      "Epoch [7001 / 20000] average reconstruction error: 0.0009286126 , kl(*beta): 8.1185933113 (0.0081185933), reconstruction loss: 0.0001167532\n",
      "Epoch [7101 / 20000] average reconstruction error: 0.0011560130 , kl(*beta): 8.7544501114 (0.0087544501), reconstruction loss: 0.0002805680\n",
      "Epoch [7201 / 20000] average reconstruction error: 0.0009469521 , kl(*beta): 8.6566880035 (0.0086566880), reconstruction loss: 0.0000812833\n",
      "Epoch [7301 / 20000] average reconstruction error: 0.0010467091 , kl(*beta): 8.7361864471 (0.0087361864), reconstruction loss: 0.0001730904\n",
      "Epoch [7401 / 20000] average reconstruction error: 0.0009116351 , kl(*beta): 8.6245064163 (0.0086245064), reconstruction loss: 0.0000491844\n",
      "Epoch [7501 / 20000] average reconstruction error: 0.0013049260 , kl(*beta): 8.4739595985 (0.0084739596), reconstruction loss: 0.0004575300\n",
      "Epoch [7601 / 20000] average reconstruction error: 0.0022069719 , kl(*beta): 9.7914511108 (0.0097914511), reconstruction loss: 0.0012278267\n",
      "Epoch [7701 / 20000] average reconstruction error: 0.0015465623 , kl(*beta): 8.4119339180 (0.0084119339), reconstruction loss: 0.0007053688\n",
      "Epoch [7801 / 20000] average reconstruction error: 0.0008902804 , kl(*beta): 8.2896083260 (0.0082896083), reconstruction loss: 0.0000613195\n",
      "Epoch [7901 / 20000] average reconstruction error: 0.0010416221 , kl(*beta): 9.0079836655 (0.0090079837), reconstruction loss: 0.0001408236\n",
      "Epoch [8001 / 20000] average reconstruction error: 0.0009483146 , kl(*beta): 8.7001570129 (0.0087001570), reconstruction loss: 0.0000782988\n",
      "Epoch [8101 / 20000] average reconstruction error: 0.0012510562 , kl(*beta): 10.0337723923 (0.0100337724), reconstruction loss: 0.0002476788\n",
      "Epoch [8201 / 20000] average reconstruction error: 0.0009248925 , kl(*beta): 8.2709786987 (0.0082709787), reconstruction loss: 0.0000977946\n",
      "Epoch [8301 / 20000] average reconstruction error: 0.0009038480 , kl(*beta): 8.2001950264 (0.0082001950), reconstruction loss: 0.0000838285\n",
      "Epoch [8401 / 20000] average reconstruction error: 0.0010338326 , kl(*beta): 9.5820483398 (0.0095820483), reconstruction loss: 0.0000756277\n",
      "Epoch [8501 / 20000] average reconstruction error: 0.0016541495 , kl(*beta): 8.5971752739 (0.0085971753), reconstruction loss: 0.0007944319\n",
      "Epoch [8601 / 20000] average reconstruction error: 0.0015352938 , kl(*beta): 9.5917717743 (0.0095917718), reconstruction loss: 0.0005761166\n",
      "Epoch [8701 / 20000] average reconstruction error: 0.0009760863 , kl(*beta): 8.8589282608 (0.0088589283), reconstruction loss: 0.0000901934\n",
      "Epoch [8801 / 20000] average reconstruction error: 0.0009068489 , kl(*beta): 8.1953570938 (0.0081953571), reconstruction loss: 0.0000873131\n",
      "Epoch [8901 / 20000] average reconstruction error: 0.0010019942 , kl(*beta): 9.0377005005 (0.0090377005), reconstruction loss: 0.0000982241\n",
      "Epoch [9001 / 20000] average reconstruction error: 0.0015197924 , kl(*beta): 8.2933579254 (0.0082933579), reconstruction loss: 0.0006904565\n",
      "Epoch [9101 / 20000] average reconstruction error: 0.0010191476 , kl(*beta): 8.8956128311 (0.0088956128), reconstruction loss: 0.0001295862\n",
      "Epoch [9201 / 20000] average reconstruction error: 0.0009329159 , kl(*beta): 8.6993330383 (0.0086993330), reconstruction loss: 0.0000629826\n",
      "Epoch [9301 / 20000] average reconstruction error: 0.0011550142 , kl(*beta): 9.2936098480 (0.0092936098), reconstruction loss: 0.0002256531\n",
      "Epoch [9401 / 20000] average reconstruction error: 0.0009400805 , kl(*beta): 7.8540659332 (0.0078540659), reconstruction loss: 0.0001546739\n",
      "Epoch [9501 / 20000] average reconstruction error: 0.0008974067 , kl(*beta): 8.3663724327 (0.0083663724), reconstruction loss: 0.0000607694\n",
      "Epoch [9601 / 20000] average reconstruction error: 0.0013213333 , kl(*beta): 9.1914538574 (0.0091914539), reconstruction loss: 0.0004021878\n",
      "Epoch [9701 / 20000] average reconstruction error: 0.0009095156 , kl(*beta): 8.3726587486 (0.0083726587), reconstruction loss: 0.0000722496\n",
      "Epoch [9801 / 20000] average reconstruction error: 0.0009094245 , kl(*beta): 8.6349307060 (0.0086349307), reconstruction loss: 0.0000459314\n",
      "Epoch [9901 / 20000] average reconstruction error: 0.0009033613 , kl(*beta): 8.6297521210 (0.0086297521), reconstruction loss: 0.0000403861\n",
      "Epoch [10001 / 20000] average reconstruction error: 0.0009313200 , kl(*beta): 8.6181398773 (0.0086181399), reconstruction loss: 0.0000695060\n",
      "Epoch [10101 / 20000] average reconstruction error: 0.0014899856 , kl(*beta): 8.7093848801 (0.0087093849), reconstruction loss: 0.0006190470\n",
      "Epoch [10201 / 20000] average reconstruction error: 0.0008938734 , kl(*beta): 8.5624296951 (0.0085624297), reconstruction loss: 0.0000376304\n",
      "Epoch [10301 / 20000] average reconstruction error: 0.0010822091 , kl(*beta): 8.7403379059 (0.0087403379), reconstruction loss: 0.0002081752\n",
      "Epoch [10401 / 20000] average reconstruction error: 0.0009478931 , kl(*beta): 8.2955116081 (0.0082955116), reconstruction loss: 0.0001183419\n",
      "Epoch [10501 / 20000] average reconstruction error: 0.0008904738 , kl(*beta): 8.2764072609 (0.0082764073), reconstruction loss: 0.0000628330\n",
      "Epoch [10601 / 20000] average reconstruction error: 0.0011845672 , kl(*beta): 9.2965252686 (0.0092965253), reconstruction loss: 0.0002549147\n",
      "Epoch [10701 / 20000] average reconstruction error: 0.0009970064 , kl(*beta): 8.5822411919 (0.0085822412), reconstruction loss: 0.0001387822\n",
      "Epoch [10801 / 20000] average reconstruction error: 0.0010751118 , kl(*beta): 9.2480865479 (0.0092480865), reconstruction loss: 0.0001503031\n",
      "Epoch [10901 / 20000] average reconstruction error: 0.0010254359 , kl(*beta): 8.8546986008 (0.0088546986), reconstruction loss: 0.0001399660\n",
      "Epoch [11001 / 20000] average reconstruction error: 0.0009436927 , kl(*beta): 8.1325287819 (0.0081325288), reconstruction loss: 0.0001304398\n",
      "Epoch [11101 / 20000] average reconstruction error: 0.0012354306 , kl(*beta): 8.3259177017 (0.0083259177), reconstruction loss: 0.0004028387\n",
      "Epoch [11201 / 20000] average reconstruction error: 0.0010344215 , kl(*beta): 9.2672411728 (0.0092672412), reconstruction loss: 0.0001076973\n",
      "Epoch [11301 / 20000] average reconstruction error: 0.0008885616 , kl(*beta): 8.3524703979 (0.0083524704), reconstruction loss: 0.0000533145\n",
      "Epoch [11401 / 20000] average reconstruction error: 0.0008777384 , kl(*beta): 8.1050896263 (0.0081050896), reconstruction loss: 0.0000672294\n",
      "Epoch [11501 / 20000] average reconstruction error: 0.0009638883 , kl(*beta): 8.8965806580 (0.0088965807), reconstruction loss: 0.0000742301\n",
      "Epoch [11601 / 20000] average reconstruction error: 0.0010465031 , kl(*beta): 8.5267412376 (0.0085267412), reconstruction loss: 0.0001938289\n",
      "Epoch [11701 / 20000] average reconstruction error: 0.0009198209 , kl(*beta): 8.4347645760 (0.0084347646), reconstruction loss: 0.0000763444\n",
      "Epoch [11801 / 20000] average reconstruction error: 0.0009894768 , kl(*beta): 8.0923513794 (0.0080923514), reconstruction loss: 0.0001802416\n",
      "Epoch [11901 / 20000] average reconstruction error: 0.0008469957 , kl(*beta): 7.8717526817 (0.0078717527), reconstruction loss: 0.0000598204\n",
      "Epoch [12001 / 20000] average reconstruction error: 0.0011381374 , kl(*beta): 8.9393535233 (0.0089393535), reconstruction loss: 0.0002442020\n",
      "Epoch [12101 / 20000] average reconstruction error: 0.0008610075 , kl(*beta): 8.2748016930 (0.0082748017), reconstruction loss: 0.0000335273\n",
      "Epoch [12201 / 20000] average reconstruction error: 0.0010734454 , kl(*beta): 8.6191631699 (0.0086191632), reconstruction loss: 0.0002115290\n",
      "Epoch [12301 / 20000] average reconstruction error: 0.0012488870 , kl(*beta): 9.5964424133 (0.0095964424), reconstruction loss: 0.0002892426\n",
      "Epoch [12401 / 20000] average reconstruction error: 0.0009478475 , kl(*beta): 9.0081716919 (0.0090081717), reconstruction loss: 0.0000470303\n",
      "Epoch [12501 / 20000] average reconstruction error: 0.0011257930 , kl(*beta): 8.7400407410 (0.0087400407), reconstruction loss: 0.0002517889\n",
      "Epoch [12601 / 20000] average reconstruction error: 0.0008286369 , kl(*beta): 7.9402336311 (0.0079402336), reconstruction loss: 0.0000346135\n",
      "Epoch [12701 / 20000] average reconstruction error: 0.0009042883 , kl(*beta): 8.1175646210 (0.0081175646), reconstruction loss: 0.0000925318\n",
      "Epoch [12801 / 20000] average reconstruction error: 0.0009978506 , kl(*beta): 9.5743143082 (0.0095743143), reconstruction loss: 0.0000404191\n",
      "Epoch [12901 / 20000] average reconstruction error: 0.0011122659 , kl(*beta): 9.2027665329 (0.0092027665), reconstruction loss: 0.0001919892\n",
      "Epoch [13001 / 20000] average reconstruction error: 0.0009031264 , kl(*beta): 8.5004803467 (0.0085004803), reconstruction loss: 0.0000530783\n",
      "Epoch [13101 / 20000] average reconstruction error: 0.0009079863 , kl(*beta): 7.9052646065 (0.0079052646), reconstruction loss: 0.0001174598\n",
      "Epoch [13201 / 20000] average reconstruction error: 0.0008766117 , kl(*beta): 8.4544232559 (0.0084544233), reconstruction loss: 0.0000311693\n",
      "Epoch [13301 / 20000] average reconstruction error: 0.0010413081 , kl(*beta): 8.4746729660 (0.0084746730), reconstruction loss: 0.0001938408\n",
      "Epoch [13401 / 20000] average reconstruction error: 0.0009239037 , kl(*beta): 8.9568972778 (0.0089568973), reconstruction loss: 0.0000282139\n",
      "Epoch [13501 / 20000] average reconstruction error: 0.0009726651 , kl(*beta): 8.4630129051 (0.0084630129), reconstruction loss: 0.0001263637\n",
      "Epoch [13601 / 20000] average reconstruction error: 0.0015011377 , kl(*beta): 8.6907738876 (0.0086907739), reconstruction loss: 0.0006320603\n",
      "Epoch [13701 / 20000] average reconstruction error: 0.0008321301 , kl(*beta): 7.8930859756 (0.0078930860), reconstruction loss: 0.0000428215\n",
      "Epoch [13801 / 20000] average reconstruction error: 0.0014211760 , kl(*beta): 9.2268726349 (0.0092268726), reconstruction loss: 0.0004984886\n",
      "Epoch [13901 / 20000] average reconstruction error: 0.0009807833 , kl(*beta): 8.0713841057 (0.0080713841), reconstruction loss: 0.0001736449\n",
      "Epoch [14001 / 20000] average reconstruction error: 0.0009374046 , kl(*beta): 8.0639008141 (0.0080639008), reconstruction loss: 0.0001310145\n",
      "Epoch [14101 / 20000] average reconstruction error: 0.0011176624 , kl(*beta): 8.3942242241 (0.0083942242), reconstruction loss: 0.0002782399\n",
      "Epoch [14201 / 20000] average reconstruction error: 0.0010241420 , kl(*beta): 8.5874413300 (0.0085874413), reconstruction loss: 0.0001653978\n",
      "Epoch [14301 / 20000] average reconstruction error: 0.0008697691 , kl(*beta): 8.2885331345 (0.0082885331), reconstruction loss: 0.0000409157\n",
      "Epoch [14401 / 20000] average reconstruction error: 0.0009144786 , kl(*beta): 8.2748249817 (0.0082748250), reconstruction loss: 0.0000869961\n",
      "Epoch [14501 / 20000] average reconstruction error: 0.0008513049 , kl(*beta): 8.1332033730 (0.0081332034), reconstruction loss: 0.0000379845\n",
      "Epoch [14601 / 20000] average reconstruction error: 0.0010637286 , kl(*beta): 8.8450255203 (0.0088450255), reconstruction loss: 0.0001792260\n",
      "Epoch [14701 / 20000] average reconstruction error: 0.0009526176 , kl(*beta): 8.2998970795 (0.0082998971), reconstruction loss: 0.0001226279\n",
      "Epoch [14801 / 20000] average reconstruction error: 0.0008623094 , kl(*beta): 7.8224982643 (0.0078224983), reconstruction loss: 0.0000800595\n",
      "Epoch [14901 / 20000] average reconstruction error: 0.0015612968 , kl(*beta): 8.9765006638 (0.0089765007), reconstruction loss: 0.0006636467\n",
      "Epoch [15001 / 20000] average reconstruction error: 0.0010607619 , kl(*beta): 9.3249010468 (0.0093249010), reconstruction loss: 0.0001282718\n",
      "Epoch [15101 / 20000] average reconstruction error: 0.0009066904 , kl(*beta): 8.4792160797 (0.0084792161), reconstruction loss: 0.0000587688\n",
      "Epoch [15201 / 20000] average reconstruction error: 0.0010818531 , kl(*beta): 8.7978995895 (0.0087978996), reconstruction loss: 0.0002020631\n",
      "Epoch [15301 / 20000] average reconstruction error: 0.0008519281 , kl(*beta): 8.2300725174 (0.0082300725), reconstruction loss: 0.0000289208\n",
      "Epoch [15401 / 20000] average reconstruction error: 0.0009324078 , kl(*beta): 8.5707168198 (0.0085707168), reconstruction loss: 0.0000753361\n",
      "Epoch [15501 / 20000] average reconstruction error: 0.0008662680 , kl(*beta): 8.2896721840 (0.0082896722), reconstruction loss: 0.0000373007\n",
      "Epoch [15601 / 20000] average reconstruction error: 0.0008975771 , kl(*beta): 8.5611941910 (0.0085611942), reconstruction loss: 0.0000414577\n",
      "Epoch [15701 / 20000] average reconstruction error: 0.0008148945 , kl(*beta): 7.8956009865 (0.0078956010), reconstruction loss: 0.0000253344\n",
      "Epoch [15801 / 20000] average reconstruction error: 0.0011354441 , kl(*beta): 8.7223434448 (0.0087223434), reconstruction loss: 0.0002632097\n",
      "Epoch [15901 / 20000] average reconstruction error: 0.0008336298 , kl(*beta): 7.9393585968 (0.0079393586), reconstruction loss: 0.0000396938\n",
      "Epoch [16001 / 20000] average reconstruction error: 0.0009309895 , kl(*beta): 9.0185469055 (0.0090185469), reconstruction loss: 0.0000291348\n",
      "Epoch [16101 / 20000] average reconstruction error: 0.0009397685 , kl(*beta): 8.6700787544 (0.0086700788), reconstruction loss: 0.0000727606\n",
      "Epoch [16201 / 20000] average reconstruction error: 0.0008908425 , kl(*beta): 8.5760304642 (0.0085760305), reconstruction loss: 0.0000332394\n",
      "Epoch [16301 / 20000] average reconstruction error: 0.0009049273 , kl(*beta): 8.5439238548 (0.0085439239), reconstruction loss: 0.0000505349\n",
      "Epoch [16401 / 20000] average reconstruction error: 0.0009059875 , kl(*beta): 8.7642448235 (0.0087642448), reconstruction loss: 0.0000295630\n",
      "Epoch [16501 / 20000] average reconstruction error: 0.0009858210 , kl(*beta): 8.4554197502 (0.0084554198), reconstruction loss: 0.0001402789\n",
      "Epoch [16601 / 20000] average reconstruction error: 0.0009454028 , kl(*beta): 8.6318259048 (0.0086318259), reconstruction loss: 0.0000822202\n",
      "Epoch [16701 / 20000] average reconstruction error: 0.0009127185 , kl(*beta): 8.7513468552 (0.0087513469), reconstruction loss: 0.0000375838\n",
      "Epoch [16801 / 20000] average reconstruction error: 0.0009848486 , kl(*beta): 9.2163715363 (0.0092163715), reconstruction loss: 0.0000632113\n",
      "Epoch [16901 / 20000] average reconstruction error: 0.0009830687 , kl(*beta): 8.7267684937 (0.0087267685), reconstruction loss: 0.0001103918\n",
      "Epoch [17001 / 20000] average reconstruction error: 0.0008820891 , kl(*beta): 8.5798274994 (0.0085798275), reconstruction loss: 0.0000241063\n",
      "Epoch [17101 / 20000] average reconstruction error: 0.0009221428 , kl(*beta): 8.9036816788 (0.0089036817), reconstruction loss: 0.0000317745\n",
      "Epoch [17201 / 20000] average reconstruction error: 0.0011119298 , kl(*beta): 8.6275283813 (0.0086275284), reconstruction loss: 0.0002491769\n",
      "Epoch [17301 / 20000] average reconstruction error: 0.0009132744 , kl(*beta): 8.4628522873 (0.0084628523), reconstruction loss: 0.0000669891\n",
      "Epoch [17401 / 20000] average reconstruction error: 0.0009679875 , kl(*beta): 8.7737639618 (0.0087737640), reconstruction loss: 0.0000906110\n",
      "Epoch [17501 / 20000] average reconstruction error: 0.0008913031 , kl(*beta): 8.0657069778 (0.0080657070), reconstruction loss: 0.0000847323\n",
      "Epoch [17601 / 20000] average reconstruction error: 0.0016092824 , kl(*beta): 8.1075256729 (0.0081075257), reconstruction loss: 0.0007985299\n",
      "Epoch [17701 / 20000] average reconstruction error: 0.0008808638 , kl(*beta): 8.5169233322 (0.0085169233), reconstruction loss: 0.0000291714\n",
      "Epoch [17801 / 20000] average reconstruction error: 0.0008571960 , kl(*beta): 8.3313463020 (0.0083313463), reconstruction loss: 0.0000240613\n",
      "Epoch [17901 / 20000] average reconstruction error: 0.0010840623 , kl(*beta): 8.4294157791 (0.0084294158), reconstruction loss: 0.0002411207\n",
      "Epoch [18001 / 20000] average reconstruction error: 0.0008696887 , kl(*beta): 8.3615121460 (0.0083615121), reconstruction loss: 0.0000335374\n",
      "Epoch [18101 / 20000] average reconstruction error: 0.0008975303 , kl(*beta): 7.8235904312 (0.0078235904), reconstruction loss: 0.0001151712\n",
      "Epoch [18201 / 20000] average reconstruction error: 0.0008243713 , kl(*beta): 8.0599369431 (0.0080599369), reconstruction loss: 0.0000183776\n",
      "Epoch [18301 / 20000] average reconstruction error: 0.0014900586 , kl(*beta): 8.9147951508 (0.0089147952), reconstruction loss: 0.0005985790\n",
      "Epoch [18401 / 20000] average reconstruction error: 0.0008384428 , kl(*beta): 8.0239174080 (0.0080239174), reconstruction loss: 0.0000360510\n",
      "Epoch [18501 / 20000] average reconstruction error: 0.0011120740 , kl(*beta): 8.3001518631 (0.0083001519), reconstruction loss: 0.0002820588\n",
      "Epoch [18601 / 20000] average reconstruction error: 0.0012110530 , kl(*beta): 8.4743521118 (0.0084743521), reconstruction loss: 0.0003636177\n",
      "Epoch [18701 / 20000] average reconstruction error: 0.0008409344 , kl(*beta): 8.0424216270 (0.0080424216), reconstruction loss: 0.0000366922\n",
      "Epoch [18801 / 20000] average reconstruction error: 0.0009244191 , kl(*beta): 8.7201446152 (0.0087201446), reconstruction loss: 0.0000524046\n",
      "Epoch [18901 / 20000] average reconstruction error: 0.0008868215 , kl(*beta): 8.3056520271 (0.0083056520), reconstruction loss: 0.0000562562\n",
      "Epoch [19001 / 20000] average reconstruction error: 0.0008030881 , kl(*beta): 7.7970605278 (0.0077970605), reconstruction loss: 0.0000233820\n",
      "Epoch [19101 / 20000] average reconstruction error: 0.0008141518 , kl(*beta): 7.8558077812 (0.0078558078), reconstruction loss: 0.0000285709\n",
      "Epoch [19201 / 20000] average reconstruction error: 0.0013374884 , kl(*beta): 8.5485496140 (0.0085485496), reconstruction loss: 0.0004826334\n",
      "Epoch [19301 / 20000] average reconstruction error: 0.0016569080 , kl(*beta): 8.0776015663 (0.0080776016), reconstruction loss: 0.0008491479\n",
      "Epoch [19401 / 20000] average reconstruction error: 0.0008265108 , kl(*beta): 8.0395111465 (0.0080395111), reconstruction loss: 0.0000225597\n",
      "Epoch [19501 / 20000] average reconstruction error: 0.0008359643 , kl(*beta): 8.1847357750 (0.0081847358), reconstruction loss: 0.0000174906\n",
      "Epoch [19601 / 20000] average reconstruction error: 0.0013425267 , kl(*beta): 8.8552499771 (0.0088552500), reconstruction loss: 0.0004570017\n",
      "Epoch [19701 / 20000] average reconstruction error: 0.0011335974 , kl(*beta): 8.4215208054 (0.0084215208), reconstruction loss: 0.0002914453\n",
      "Epoch [19801 / 20000] average reconstruction error: 0.0017064027 , kl(*beta): 8.6144741058 (0.0086144741), reconstruction loss: 0.0008449553\n",
      "Epoch [19901 / 20000] average reconstruction error: 0.0013967518 , kl(*beta): 8.2761406898 (0.0082761407), reconstruction loss: 0.0005691377\n"
     ]
    }
   ],
   "source": [
    "torch.set_printoptions(precision=10)\n",
    "p = 5\n",
    "eps = 1\n",
    "t_list = os.listdir(\"data/paper/IntraP\" + str(p) + \"eps0\" + str(eps) )[:100]\n",
    "dataset = tDataset(t_list, \"data/paper/IntraP\" + str(p) + \"eps0\" + str(eps) )\n",
    "data_loader = DataLoader(dataset, batch_size = batch_size, shuffle=True, collate_fn=my_collate)\n",
    "\n",
    "\n",
    "mult = mv.numberNodes(data_loader, batch_size)\n",
    "feature_size = 64\n",
    "latent_size = feature_size\n",
    "hidden_size_encoder = 512\n",
    "hidden_size_decoder = 256\n",
    "\n",
    "Grassencoder = mv.GRASSEncoder(input_size = 4, feature_size=feature_size, hidden_size=hidden_size_encoder)\n",
    "Grassencoder = Grassencoder.to(device)\n",
    "Grassdecoder = mv.GRASSDecoder(latent_size=latent_size, hidden_size=hidden_size_decoder, mult = mult)\n",
    "Grassdecoder = Grassdecoder.to(device)\n",
    "\n",
    "mv.setLevel(data_loader)\n",
    "\n",
    "##loop parameters\n",
    "epochs = 20000\n",
    "learning_rate = 1e-4\n",
    "params = list(Grassencoder.parameters()) + list(Grassdecoder.parameters()) \n",
    "opt = torch.optim.Adam(params, lr=learning_rate) \n",
    "total_paramse = sum(param.numel() for param in Grassencoder.parameters())\n",
    "total_paramsd = sum(param.numel() for param in Grassdecoder.parameters())\n",
    "print(\"total parameters encoder \", total_paramse)\n",
    "print(\"total parameters decoder\", total_paramsd)\n",
    "print(\"total parameters\", total_paramse + total_paramsd)\n",
    "\n",
    "Grassencoder.train()\n",
    "Grassdecoder.train()\n",
    "\n",
    "config = {\n",
    "\"learning_rate\": learning_rate,\n",
    "\"epochs\": epochs,\n",
    "\"batch_size\": batch_size,\n",
    "\"dataset\": t_list,\n",
    "\"number of trees\": len(data_loader)*batch_size,\n",
    "\"optim\": opt,\n",
    "\"latent_size\" : latent_size,\n",
    "\"params\":total_paramse + total_paramsd,\n",
    "\"prof\": p,\n",
    "}\n",
    "wandb.init(project=\"MIA\", entity=\"paufeldman\", config = config)\n",
    "\n",
    "train_model(epochs, data_loader, Grassencoder, Grassdecoder, opt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('py_torc')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8f3e717cd274da89498094fde320e6eab1bf0f52911d27cf47473187acb3fe8a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
