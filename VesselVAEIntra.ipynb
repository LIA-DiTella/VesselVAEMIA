{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "torch.manual_seed(125)\n",
    "import random\n",
    "random.seed(125)\n",
    "import torch_f as torch_f\n",
    "import modelovae as mv\n",
    "import meshSubplot as ms\n",
    "import wandb\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_gpu = True\n",
    "device = torch.device(\"cuda:0\" if use_gpu and torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encodeStructureFold(fold, root):\n",
    "    '''Folds the tree by depth, so that nodes at the same depth can go in to the \n",
    "    encoder at the same time, reducing computational cost'''\n",
    "    def encodeNode(node):\n",
    "        \n",
    "        if node is None:\n",
    "            return\n",
    "        \n",
    "        if node.isLeaf():\n",
    "            return fold.add('leafEncoder', node.radius)\n",
    "        else:\n",
    "            left = encodeNode(node.left)\n",
    "            right = encodeNode(node.right)\n",
    "            if left is not None and right is not None:\n",
    "                return fold.add('bifurcationEncoder', node.radius, right, left)\n",
    "            elif right is not None:\n",
    "                return fold.add('internalEncoder', node.radius, right)\n",
    "            elif left is not None:\n",
    "                return fold.add('internalEncoder', node.radius, left)\n",
    "        \n",
    "\n",
    "    encoding = encodeNode(root)\n",
    "    return fold.add('sampleEncoder', encoding)\n",
    "\n",
    "def encode_structure(root, Grassencoder):\n",
    "        \n",
    "    def encode_node(node, Grassencoder):\n",
    "          \n",
    "        if node is None:\n",
    "            return\n",
    "        if node.isLeaf():\n",
    "            return Grassencoder.leafEncoder(node.radius.reshape(-1,4))\n",
    "        else :\n",
    "            left = encode_node(node.left, Grassencoder)\n",
    "            right = encode_node(node.right, Grassencoder)\n",
    "            if left is not None and right is not None:\n",
    "                return Grassencoder.bifurcationEncoder(node.radius.reshape(-1,4), right, left)\n",
    "            if right is not None:\n",
    "                return Grassencoder.internalEncoder(node.radius.reshape(-1,4), right)\n",
    "            if left is not None:\n",
    "                return Grassencoder.internalEncoder(node.radius.reshape(-1,4), left)\n",
    "\n",
    "    encoding = encode_node(root, Grassencoder)\n",
    "    return Grassencoder.sampleEncoder(encoding)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def numerar_nodos(root, count):\n",
    "    if root is not None:\n",
    "        numerar_nodos(root.left, count)\n",
    "        root.data = len(count)\n",
    "        count.append(1)\n",
    "        numerar_nodos(root.right, count)\n",
    "        return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_collate(batch):\n",
    "    return batch\n",
    "\n",
    "\n",
    "class tDataset(Dataset):\n",
    "    def __init__(self, l, dir, transform=None):\n",
    "        self.names = l\n",
    "        self.transform = transform\n",
    "        self.data = [] #lista con las strings de todos los arboles\n",
    "        for file in self.names:\n",
    "            self.data.append(mv.read_tree(file, dir))\n",
    "        #\"data\" is a list of all serialized trees, \"trees\" is a list of the binary trees\n",
    "        self.trees = []\n",
    "        for tree in self.data:\n",
    "            deserial = mv.deserialize(tree)\n",
    "            c = []\n",
    "            numerar_nodos(deserial, c)\n",
    "            self.trees.append({deserial: len(c)})\n",
    "            \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.names)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        tree = self.trees[idx]\n",
    "        return tree\n",
    "\n",
    "batch_size = 4"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decodeStructureFoldGrass(fold, v, root):\n",
    "    ''' Decodes the tree in a depth first fashion, grouping nodes at the same depth\n",
    "    in order to reduce computational cost'''\n",
    "\n",
    "    def decodeNode(fold, v, node, flag):\n",
    "        #multipl = np.round((node.maxlevel+1-node.level)/node.treelevel, decimals=2)\n",
    "        label = fold.add('nodeClassifier', v)\n",
    "      \n",
    "               \n",
    "        if node.childs() == 1 :\n",
    "            \n",
    "            right, radius = fold.add('internalDecoder', v).split(2)\n",
    "            \n",
    "            if node.right:\n",
    "                nodoSiguiente = node.right\n",
    "            else:\n",
    "                nodoSiguiente = node.left\n",
    "            \n",
    "            child_loss = decodeNode(fold, right, nodoSiguiente, flag = 1)\n",
    "            lossEstructura = fold.add('classifyLossEstimator', label, node)\n",
    "            lossAtributo = fold.add('calcularLossAtributo', node, radius)\n",
    "            \n",
    "           \n",
    "            #losse = fold.add('vectorMult', multipl, lossEstructura)\n",
    "            losse = lossEstructura\n",
    "            loss = fold.add('vectorAdder', losse, lossAtributo)\n",
    "            loss2 = fold.add('vectorAdder', loss, child_loss)\n",
    "\n",
    "            return loss2\n",
    "        elif node.childs() == 0 : \n",
    "\n",
    "            radius = fold.add('featureDecoder', v)\n",
    "            \n",
    "            lossEstructura = fold.add('classifyLossEstimator', label, node) \n",
    "            lossAtributo = fold.add('calcularLossAtributo', node, radius)\n",
    "    \n",
    "            #losse = fold.add('vectorMult', multipl, lossEstructura)\n",
    "            losse = lossEstructura\n",
    "            loss =  fold.add('vectorAdder', losse, lossAtributo)   \n",
    "\n",
    "            return loss\n",
    "            \n",
    "        \n",
    "        elif node.childs() == 2 :\n",
    "\n",
    "            left, right, radius = fold.add('bifurcationDecoder', v).split(3)\n",
    "            nodoSiguienteRight = node.right\n",
    "            nodoSiguienteLeft = node.left\n",
    "\n",
    "            if nodoSiguienteRight is not None:\n",
    "                right_loss = decodeNode(fold, right, nodoSiguienteRight, flag = 1)\n",
    "             \n",
    "            if nodoSiguienteLeft is not None:\n",
    "                left_loss  = decodeNode(fold, left, nodoSiguienteLeft, flag = 1)\n",
    "\n",
    "          \n",
    "            \n",
    "            lossEstructura = fold.add('classifyLossEstimator', label, node)\n",
    "            lossAtributo   = fold.add('calcularLossAtributo', node, radius)\n",
    "            #losse = fold.add('vectorMult', multipl, lossEstructura)\n",
    "            losse = lossEstructura\n",
    "            loss = fold.add('vectorAdder', losse, lossAtributo)\n",
    "            loss2 = fold.add('vectorAdder', loss, right_loss)\n",
    "            loss3 = fold.add('vectorAdder', loss2, left_loss)\n",
    "            return loss3\n",
    "            \n",
    "    v1 = fold.add('sampleDecoder', v)\n",
    "    dec = decodeNode (fold, v1, root, flag = 0)\n",
    "    return dec\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SaveBestModel:\n",
    "    \"\"\"\n",
    "    Class to save the best model while training. If the current epoch's \n",
    "    validation loss is less than the previous least less, then save the\n",
    "    model state.\n",
    "    \"\"\"\n",
    "    def __init__(self, best_valid_loss=float('inf')):\n",
    "        self.best_valid_loss = best_valid_loss\n",
    "        \n",
    "    def __call__(\n",
    "        self, current_valid_loss, \n",
    "        epoch, encoder, decoder, optimizer\n",
    "    ):  \n",
    "        if epoch > 50:\n",
    "            if current_valid_loss < self.best_valid_loss:\n",
    "                self.best_valid_loss = current_valid_loss\n",
    "                #'classifier_state_dict': classifier.state_dict(),\n",
    "                torch.save({\n",
    "                    'epoch': epoch+1,\n",
    "                    'encoder_state_dict': encoder.state_dict(),\n",
    "                    'decoder_state_dict': decoder.state_dict(),\n",
    "                    'loss' : self.best_valid_loss,\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    }, 'ablation/IntraP10eps02-best.pth')\n",
    "\n",
    "class SaveLastModel:\n",
    "    \"\"\"\n",
    "    Class to save the model while training. \n",
    "    \"\"\"  \n",
    "    def __call__( self,  epoch, encoder, decoder, optimizer):\n",
    "        torch.save({\n",
    "            'epoch': epoch+1,\n",
    "            'encoder_state_dict': encoder.state_dict(),\n",
    "            'decoder_state_dict': decoder.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            }, 'ablation/IntraP10eps02-last.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def escalon_beta (e, corte):\n",
    "    l = np.linspace(e,e,corte)\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_Level(tree, n_nodes):\n",
    "    max_level = 0  \n",
    "    for x in range(0, n_nodes):\n",
    "        level = mv.getLevel(tree, x)\n",
    "        if level > max_level:\n",
    "            max_level = level\n",
    "        if (level):\n",
    "            node = mv.searchNode(tree, x)\n",
    "            node.level = mv.getLevel(tree, x)\n",
    "        else:\n",
    "            print(x, \"is not present in tree\")\n",
    "    tree_level = []\n",
    "    tree.getTreeLevel(tree, tree_level)\n",
    "    tree_level = [max_level - nodelevel for nodelevel in tree_level]\n",
    "    tree.setTreeLevel(tree, sum(tree_level))\n",
    "    tree.setMaxLevel(tree, max_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(epochs, data_loader, Grassencoder, Grassdecoder, opt):\n",
    " \n",
    "    save_last_model = SaveLastModel()\n",
    "    save_best_model = SaveBestModel()\n",
    "    train_loss_avg = []\n",
    "    betas = escalon_beta(.001, 400000)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "    \n",
    "        beta = betas[epoch]\n",
    "        train_loss_avg.append(0)\n",
    "\n",
    "        epochTotalLoss = 0\n",
    "        epochReconLoss = 0\n",
    "        epochKLDivLoss = 0\n",
    "        epochKLDivLossBeta = 0\n",
    "\n",
    "        for batch_idx, batch in enumerate(data_loader):            \n",
    "            \n",
    "            enc_fold = torch_f.Fold(device)\n",
    "            \n",
    "            enc_fold_nodes = []     \n",
    "            n_nodes = []\n",
    "            for tree in batch: #example es un arbolito\n",
    "                example = list(tree.keys())[0]\n",
    "                n = tree[example]#[0]\n",
    "                n_nodes.append(n)\n",
    "                enc_fold_nodes.append(encodeStructureFold(enc_fold, example))\n",
    "            \n",
    "            enc_fold_nodes = enc_fold.apply(Grassencoder, [enc_fold_nodes])\n",
    "            \n",
    "            enc_fold_nodes = torch.split(enc_fold_nodes[0], 1, 0)\n",
    "            \n",
    "            dec_fold = torch_f.Fold(device)\n",
    "            dec_fold_nodes = []\n",
    "            kld_fold_nodes = []\n",
    "\n",
    "            for tree, fnode in zip(batch, enc_fold_nodes):\n",
    "                example = list(tree.keys())[0]\n",
    "                root_code, kl_div = torch.chunk(fnode, 2, 1)\n",
    "                dec_fold_nodes.append(decodeStructureFoldGrass(dec_fold, root_code, example))\n",
    "                kld_fold_nodes.append(kl_div)\n",
    "                \n",
    "            total_loss = dec_fold.apply(Grassdecoder, [dec_fold_nodes, kld_fold_nodes])\n",
    "            n_nodes = torch.tensor(n_nodes, device = device)\n",
    "            recon_loss = torch.div(total_loss[0], n_nodes)\n",
    "            recon_loss = recon_loss.sum() / len(batch)               # avg. reconstruction loss per example\n",
    "            \n",
    "            kldiv_loss = []\n",
    "            for element in kld_fold_nodes:\n",
    "                l = torch.sum(element)\n",
    "                kldiv_loss.append(l)\n",
    "           \n",
    "            kldiv_loss = sum(kldiv_loss) / len(batch)\n",
    "           \n",
    "            total_loss = recon_loss +  beta*kldiv_loss/10\n",
    "           \n",
    "            opt.zero_grad()\n",
    "            total_loss.backward()\n",
    "            opt.step()\n",
    "            train_loss_avg[-1] += (total_loss.item())\n",
    "            epochTotalLoss += total_loss.item()\n",
    "            epochReconLoss += recon_loss.item()\n",
    "            epochKLDivLoss += kldiv_loss.item()\n",
    "            epochKLDivLossBeta += beta*kldiv_loss.item()\n",
    "\n",
    "        epochTotalLoss /= len(data_loader)\n",
    "        epochReconLoss /= len(data_loader)\n",
    "        epochKLDivLoss /= len(data_loader)\n",
    "        epochKLDivLossBeta  /= len(data_loader)\n",
    "        \n",
    "        \n",
    "        save_best_model(total_loss, epoch, Grassencoder, Grassdecoder, opt)\n",
    "        if epoch % 10 == 0: \n",
    "            wandb.log({'epoch': epoch+1, 'loss': epochTotalLoss, 'kl_div': epochKLDivLoss, 'kl_div (*beta)': epochKLDivLossBeta, 'recon_loss': epochReconLoss, 'beta': beta})\n",
    "        if epoch % 100 == 0:   \n",
    "            save_last_model(epoch, Grassencoder, Grassdecoder, opt)\n",
    "        if epoch % 100 == 0:\n",
    "            print('Epoch [%d / %d] average reconstruction error: %.10f , kl(*beta): %.10f (%.10f), reconstruction loss: %.10f' % (epoch+1, epochs, epochTotalLoss, epochKLDivLoss, epochKLDivLossBeta, epochReconLoss))\n",
    "    return \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FOR LOOP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total parameters encoder  626560\n",
      "total parameters decoder 379911\n",
      "total parameters 1006471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mpaufeldman\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.6 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\User\\Documents\\MICCAI\\VesselVAEMIA\\wandb\\run-20240422_085827-eydcwfp6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/paufeldman/MIA/runs/eydcwfp6' target=\"_blank\">major-snowball-81</a></strong> to <a href='https://wandb.ai/paufeldman/MIA' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/paufeldman/MIA' target=\"_blank\">https://wandb.ai/paufeldman/MIA</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/paufeldman/MIA/runs/eydcwfp6' target=\"_blank\">https://wandb.ai/paufeldman/MIA/runs/eydcwfp6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1 / 20000] average reconstruction error: 0.1736428624 , kl(*beta): 0.0835421911 (0.0000835422), reconstruction loss: 0.1736345077\n",
      "Epoch [101 / 20000] average reconstruction error: 0.0602524769 , kl(*beta): 14.3820766830 (0.0143820767), reconstruction loss: 0.0588142692\n",
      "Epoch [201 / 20000] average reconstruction error: 0.0462159181 , kl(*beta): 18.6930624771 (0.0186930625), reconstruction loss: 0.0443466114\n",
      "Epoch [301 / 20000] average reconstruction error: 0.0362291973 , kl(*beta): 23.1394185638 (0.0231394186), reconstruction loss: 0.0339152553\n",
      "Epoch [401 / 20000] average reconstruction error: 0.0287039385 , kl(*beta): 23.9483304596 (0.0239483305), reconstruction loss: 0.0263091052\n",
      "Epoch [501 / 20000] average reconstruction error: 0.0234066900 , kl(*beta): 26.0541172791 (0.0260541173), reconstruction loss: 0.0208012780\n",
      "Epoch [601 / 20000] average reconstruction error: 0.0222894958 , kl(*beta): 25.9608471680 (0.0259608472), reconstruction loss: 0.0196934111\n",
      "Epoch [701 / 20000] average reconstruction error: 0.0192959667 , kl(*beta): 26.7987872314 (0.0267987872), reconstruction loss: 0.0166160879\n",
      "Epoch [801 / 20000] average reconstruction error: 0.0123302575 , kl(*beta): 24.7872740936 (0.0247872741), reconstruction loss: 0.0098515300\n",
      "Epoch [901 / 20000] average reconstruction error: 0.0107957819 , kl(*beta): 25.4942170715 (0.0254942171), reconstruction loss: 0.0082463601\n",
      "Epoch [1001 / 20000] average reconstruction error: 0.0140099583 , kl(*beta): 24.1082328796 (0.0241082329), reconstruction loss: 0.0115991348\n",
      "Epoch [1101 / 20000] average reconstruction error: 0.0073433587 , kl(*beta): 23.0016191864 (0.0230016192), reconstruction loss: 0.0050431967\n",
      "Epoch [1201 / 20000] average reconstruction error: 0.0080418969 , kl(*beta): 20.1802600098 (0.0201802600), reconstruction loss: 0.0060238708\n",
      "Epoch [1301 / 20000] average reconstruction error: 0.0060236698 , kl(*beta): 21.7217527008 (0.0217217527), reconstruction loss: 0.0038514943\n",
      "Epoch [1401 / 20000] average reconstruction error: 0.0051286907 , kl(*beta): 20.8467794800 (0.0208467795), reconstruction loss: 0.0030440126\n",
      "Epoch [1501 / 20000] average reconstruction error: 0.0054070092 , kl(*beta): 20.3564486694 (0.0203564487), reconstruction loss: 0.0033713641\n",
      "Epoch [1601 / 20000] average reconstruction error: 0.0039141281 , kl(*beta): 18.0816622162 (0.0180816622), reconstruction loss: 0.0021059618\n",
      "Epoch [1701 / 20000] average reconstruction error: 0.0046041617 , kl(*beta): 18.1661865997 (0.0181661866), reconstruction loss: 0.0027875430\n",
      "Epoch [1801 / 20000] average reconstruction error: 0.0032635700 , kl(*beta): 16.6863108444 (0.0166863108), reconstruction loss: 0.0015949388\n",
      "Epoch [1901 / 20000] average reconstruction error: 0.0028549704 , kl(*beta): 15.0789740372 (0.0150789740), reconstruction loss: 0.0013470728\n",
      "Epoch [2001 / 20000] average reconstruction error: 0.0034060935 , kl(*beta): 17.7463527298 (0.0177463527), reconstruction loss: 0.0016314582\n",
      "Epoch [2101 / 20000] average reconstruction error: 0.0029292881 , kl(*beta): 14.4738378525 (0.0144738379), reconstruction loss: 0.0014819041\n",
      "Epoch [2201 / 20000] average reconstruction error: 0.0025903060 , kl(*beta): 15.2928799438 (0.0152928799), reconstruction loss: 0.0010610179\n",
      "Epoch [2301 / 20000] average reconstruction error: 0.0024099091 , kl(*beta): 14.4566011810 (0.0144566012), reconstruction loss: 0.0009642489\n",
      "Epoch [2401 / 20000] average reconstruction error: 0.0047963551 , kl(*beta): 14.2229327393 (0.0142229327), reconstruction loss: 0.0033740617\n",
      "Epoch [2501 / 20000] average reconstruction error: 0.0022534474 , kl(*beta): 13.1148644257 (0.0131148644), reconstruction loss: 0.0009419609\n",
      "Epoch [2601 / 20000] average reconstruction error: 0.0028201249 , kl(*beta): 16.1557011032 (0.0161557011), reconstruction loss: 0.0012045547\n",
      "Epoch [2701 / 20000] average reconstruction error: 0.0020991929 , kl(*beta): 13.5273055267 (0.0135273055), reconstruction loss: 0.0007464623\n",
      "Epoch [2801 / 20000] average reconstruction error: 0.0062051737 , kl(*beta): 14.6037342453 (0.0146037342), reconstruction loss: 0.0047448003\n",
      "Epoch [2901 / 20000] average reconstruction error: 0.0053565167 , kl(*beta): 16.1682800293 (0.0161682800), reconstruction loss: 0.0037396886\n",
      "Epoch [3001 / 20000] average reconstruction error: 0.0089041401 , kl(*beta): 15.3623263168 (0.0153623263), reconstruction loss: 0.0073679074\n",
      "Epoch [3101 / 20000] average reconstruction error: 0.0020789499 , kl(*beta): 12.1595098495 (0.0121595098), reconstruction loss: 0.0008629988\n",
      "Epoch [3201 / 20000] average reconstruction error: 0.0025044625 , kl(*beta): 13.1041464233 (0.0131041464), reconstruction loss: 0.0011940477\n",
      "Epoch [3301 / 20000] average reconstruction error: 0.0044970861 , kl(*beta): 15.2023619080 (0.0152023619), reconstruction loss: 0.0029768498\n",
      "Epoch [3401 / 20000] average reconstruction error: 0.0030613722 , kl(*beta): 14.7061614227 (0.0147061614), reconstruction loss: 0.0015907559\n",
      "Epoch [3501 / 20000] average reconstruction error: 0.0017082998 , kl(*beta): 12.5598440933 (0.0125598441), reconstruction loss: 0.0004523153\n",
      "Epoch [3601 / 20000] average reconstruction error: 0.0028227255 , kl(*beta): 15.8874103165 (0.0158874103), reconstruction loss: 0.0012339844\n",
      "Epoch [3701 / 20000] average reconstruction error: 0.0016675497 , kl(*beta): 12.2224480438 (0.0122224480), reconstruction loss: 0.0004453048\n",
      "Epoch [3801 / 20000] average reconstruction error: 0.0020871021 , kl(*beta): 14.2925960541 (0.0142925961), reconstruction loss: 0.0006578424\n",
      "Epoch [3901 / 20000] average reconstruction error: 0.0030327955 , kl(*beta): 14.6022589874 (0.0146022590), reconstruction loss: 0.0015725695\n",
      "Epoch [4001 / 20000] average reconstruction error: 0.0018705737 , kl(*beta): 12.8097655106 (0.0128097655), reconstruction loss: 0.0005895970\n",
      "Epoch [4101 / 20000] average reconstruction error: 0.0023243067 , kl(*beta): 13.8667939377 (0.0138667939), reconstruction loss: 0.0009376272\n",
      "Epoch [4201 / 20000] average reconstruction error: 0.0030298499 , kl(*beta): 13.3571606445 (0.0133571606), reconstruction loss: 0.0016941338\n",
      "Epoch [4301 / 20000] average reconstruction error: 0.0017350435 , kl(*beta): 13.3982765961 (0.0133982766), reconstruction loss: 0.0003952157\n",
      "Epoch [4401 / 20000] average reconstruction error: 0.0014872383 , kl(*beta): 11.6561549377 (0.0116561549), reconstruction loss: 0.0003216227\n",
      "Epoch [4501 / 20000] average reconstruction error: 0.0020468330 , kl(*beta): 12.8927560425 (0.0128927560), reconstruction loss: 0.0007575573\n",
      "Epoch [4601 / 20000] average reconstruction error: 0.0021216869 , kl(*beta): 14.9423898315 (0.0149423898), reconstruction loss: 0.0006274479\n",
      "Epoch [4701 / 20000] average reconstruction error: 0.0018190978 , kl(*beta): 13.7414693069 (0.0137414693), reconstruction loss: 0.0004449508\n",
      "Epoch [4801 / 20000] average reconstruction error: 0.0060641171 , kl(*beta): 19.3512625122 (0.0193512625), reconstruction loss: 0.0041289908\n",
      "Epoch [4901 / 20000] average reconstruction error: 0.0057614407 , kl(*beta): 14.3196228027 (0.0143196228), reconstruction loss: 0.0043294783\n",
      "Epoch [5001 / 20000] average reconstruction error: 0.0015591856 , kl(*beta): 12.8375345230 (0.0128375345), reconstruction loss: 0.0002754321\n",
      "Epoch [5101 / 20000] average reconstruction error: 0.0018882869 , kl(*beta): 14.4203107834 (0.0144203108), reconstruction loss: 0.0004462557\n",
      "Epoch [5201 / 20000] average reconstruction error: 0.0013637218 , kl(*beta): 10.9067271805 (0.0109067272), reconstruction loss: 0.0002730490\n",
      "Epoch [5301 / 20000] average reconstruction error: 0.0044590516 , kl(*beta): 13.0471542740 (0.0130471543), reconstruction loss: 0.0031543361\n",
      "Epoch [5401 / 20000] average reconstruction error: 0.0034434250 , kl(*beta): 12.8137228012 (0.0128137228), reconstruction loss: 0.0021620527\n",
      "Epoch [5501 / 20000] average reconstruction error: 0.0036737619 , kl(*beta): 16.8362548828 (0.0168362549), reconstruction loss: 0.0019901364\n",
      "Epoch [5601 / 20000] average reconstruction error: 0.0014114243 , kl(*beta): 11.2838219452 (0.0112838219), reconstruction loss: 0.0002830420\n",
      "Epoch [5701 / 20000] average reconstruction error: 0.0023738286 , kl(*beta): 11.3874243927 (0.0113874244), reconstruction loss: 0.0012350861\n",
      "Epoch [5801 / 20000] average reconstruction error: 0.0014738234 , kl(*beta): 12.3488943481 (0.0123488943), reconstruction loss: 0.0002389338\n",
      "Epoch [5901 / 20000] average reconstruction error: 0.0025949567 , kl(*beta): 11.2238243484 (0.0112238243), reconstruction loss: 0.0014725742\n",
      "Epoch [6001 / 20000] average reconstruction error: 0.0014475948 , kl(*beta): 12.3763159180 (0.0123763159), reconstruction loss: 0.0002099632\n",
      "Epoch [6101 / 20000] average reconstruction error: 0.0062998447 , kl(*beta): 14.6570827103 (0.0146570827), reconstruction loss: 0.0048341363\n",
      "Epoch [6201 / 20000] average reconstruction error: 0.0015974392 , kl(*beta): 12.9938388443 (0.0129938388), reconstruction loss: 0.0002980553\n",
      "Epoch [6301 / 20000] average reconstruction error: 0.0016001658 , kl(*beta): 12.3224140549 (0.0123224141), reconstruction loss: 0.0003679243\n",
      "Epoch [6401 / 20000] average reconstruction error: 0.0019547008 , kl(*beta): 13.0343495178 (0.0130343495), reconstruction loss: 0.0006512658\n",
      "Epoch [6501 / 20000] average reconstruction error: 0.0019119260 , kl(*beta): 12.1193272400 (0.0121193272), reconstruction loss: 0.0006999932\n",
      "Epoch [6601 / 20000] average reconstruction error: 0.0014725194 , kl(*beta): 11.4541022110 (0.0114541022), reconstruction loss: 0.0003271091\n",
      "Epoch [6701 / 20000] average reconstruction error: 0.0012311237 , kl(*beta): 10.7207974625 (0.0107207975), reconstruction loss: 0.0001590439\n",
      "Epoch [6801 / 20000] average reconstruction error: 0.0012437966 , kl(*beta): 10.7160633850 (0.0107160634), reconstruction loss: 0.0001721902\n",
      "Epoch [6901 / 20000] average reconstruction error: 0.0013579848 , kl(*beta): 11.9390301514 (0.0119390302), reconstruction loss: 0.0001640817\n",
      "Epoch [7001 / 20000] average reconstruction error: 0.0017800153 , kl(*beta): 11.7704614258 (0.0117704614), reconstruction loss: 0.0006029690\n",
      "Epoch [7101 / 20000] average reconstruction error: 0.0014567825 , kl(*beta): 11.9301137924 (0.0119301138), reconstruction loss: 0.0002637711\n",
      "Epoch [7201 / 20000] average reconstruction error: 0.0014182762 , kl(*beta): 11.7801916504 (0.0117801917), reconstruction loss: 0.0002402570\n",
      "Epoch [7301 / 20000] average reconstruction error: 0.0016384281 , kl(*beta): 13.5244924545 (0.0135244925), reconstruction loss: 0.0002859788\n",
      "Epoch [7401 / 20000] average reconstruction error: 0.0043174475 , kl(*beta): 11.4038373184 (0.0114038373), reconstruction loss: 0.0031770636\n",
      "Epoch [7501 / 20000] average reconstruction error: 0.0013080836 , kl(*beta): 11.0946311951 (0.0110946312), reconstruction loss: 0.0001986204\n",
      "Epoch [7601 / 20000] average reconstruction error: 0.0016074277 , kl(*beta): 13.4070158768 (0.0134070159), reconstruction loss: 0.0002667260\n",
      "Epoch [7701 / 20000] average reconstruction error: 0.0015568998 , kl(*beta): 12.9459241867 (0.0129459242), reconstruction loss: 0.0002623073\n",
      "Epoch [7801 / 20000] average reconstruction error: 0.0033297761 , kl(*beta): 12.7935385513 (0.0127935386), reconstruction loss: 0.0020504222\n",
      "Epoch [7901 / 20000] average reconstruction error: 0.0026670687 , kl(*beta): 13.6363967896 (0.0136363968), reconstruction loss: 0.0013034289\n",
      "Epoch [8001 / 20000] average reconstruction error: 0.0013946599 , kl(*beta): 12.2860419083 (0.0122860419), reconstruction loss: 0.0001660557\n",
      "Epoch [8101 / 20000] average reconstruction error: 0.0012936582 , kl(*beta): 11.3491766357 (0.0113491766), reconstruction loss: 0.0001587405\n",
      "Epoch [8201 / 20000] average reconstruction error: 0.0016229910 , kl(*beta): 11.1050157166 (0.0111050157), reconstruction loss: 0.0005124893\n",
      "Epoch [8301 / 20000] average reconstruction error: 0.0016126648 , kl(*beta): 13.1792171478 (0.0131792171), reconstruction loss: 0.0002947430\n",
      "Epoch [8401 / 20000] average reconstruction error: 0.0014739694 , kl(*beta): 11.4640351105 (0.0114640351), reconstruction loss: 0.0003275658\n",
      "Epoch [8501 / 20000] average reconstruction error: 0.0012149900 , kl(*beta): 10.2323305130 (0.0102323305), reconstruction loss: 0.0001917568\n",
      "Epoch [8601 / 20000] average reconstruction error: 0.0015011662 , kl(*beta): 10.3149885178 (0.0103149885), reconstruction loss: 0.0004696673\n",
      "Epoch [8701 / 20000] average reconstruction error: 0.0014700621 , kl(*beta): 12.8447044754 (0.0128447045), reconstruction loss: 0.0001855916\n",
      "Epoch [8801 / 20000] average reconstruction error: 0.0018713595 , kl(*beta): 11.2345143890 (0.0112345144), reconstruction loss: 0.0007479080\n",
      "Epoch [8901 / 20000] average reconstruction error: 0.0014689311 , kl(*beta): 13.0203378296 (0.0130203378), reconstruction loss: 0.0001668972\n",
      "Epoch [9001 / 20000] average reconstruction error: 0.0012047148 , kl(*beta): 10.4617567444 (0.0104617567), reconstruction loss: 0.0001585391\n",
      "Epoch [9101 / 20000] average reconstruction error: 0.0012942446 , kl(*beta): 11.5042779160 (0.0115042779), reconstruction loss: 0.0001438167\n",
      "Epoch [9201 / 20000] average reconstruction error: 0.0011822538 , kl(*beta): 10.6735499954 (0.0106735500), reconstruction loss: 0.0001148987\n",
      "Epoch [9301 / 20000] average reconstruction error: 0.0012986886 , kl(*beta): 10.6396598816 (0.0106396599), reconstruction loss: 0.0002347225\n",
      "Epoch [9401 / 20000] average reconstruction error: 0.0016929068 , kl(*beta): 12.8136582565 (0.0128136583), reconstruction loss: 0.0004115409\n",
      "Epoch [9501 / 20000] average reconstruction error: 0.0015653574 , kl(*beta): 12.1614322281 (0.0121614322), reconstruction loss: 0.0003492141\n",
      "Epoch [9601 / 20000] average reconstruction error: 0.0037361234 , kl(*beta): 10.7642370987 (0.0107642371), reconstruction loss: 0.0026596997\n",
      "Epoch [9701 / 20000] average reconstruction error: 0.0013863557 , kl(*beta): 11.2185759354 (0.0112185759), reconstruction loss: 0.0002644981\n",
      "Epoch [9801 / 20000] average reconstruction error: 0.0028825603 , kl(*beta): 12.7012402725 (0.0127012403), reconstruction loss: 0.0016124362\n",
      "Epoch [9901 / 20000] average reconstruction error: 0.0011634854 , kl(*beta): 10.3519009781 (0.0103519010), reconstruction loss: 0.0001282952\n",
      "Epoch [10001 / 20000] average reconstruction error: 0.0011733482 , kl(*beta): 10.3938555908 (0.0103938556), reconstruction loss: 0.0001339626\n",
      "Epoch [10101 / 20000] average reconstruction error: 0.0013439231 , kl(*beta): 12.0098077393 (0.0120098077), reconstruction loss: 0.0001429423\n",
      "Epoch [10201 / 20000] average reconstruction error: 0.0011871280 , kl(*beta): 10.7500774384 (0.0107500774), reconstruction loss: 0.0001121202\n",
      "Epoch [10301 / 20000] average reconstruction error: 0.0013047081 , kl(*beta): 11.6998291397 (0.0116998291), reconstruction loss: 0.0001347251\n",
      "Epoch [10401 / 20000] average reconstruction error: 0.0012570979 , kl(*beta): 10.6016648483 (0.0106016648), reconstruction loss: 0.0001969313\n",
      "Epoch [10501 / 20000] average reconstruction error: 0.0027464280 , kl(*beta): 11.4449214935 (0.0114449215), reconstruction loss: 0.0016019358\n",
      "Epoch [10601 / 20000] average reconstruction error: 0.0023077379 , kl(*beta): 13.1146875000 (0.0131146875), reconstruction loss: 0.0009962691\n",
      "Epoch [10701 / 20000] average reconstruction error: 0.0017916085 , kl(*beta): 12.8899042511 (0.0128899043), reconstruction loss: 0.0005026180\n",
      "Epoch [10801 / 20000] average reconstruction error: 0.0018528837 , kl(*beta): 12.9431991196 (0.0129431991), reconstruction loss: 0.0005585637\n",
      "Epoch [10901 / 20000] average reconstruction error: 0.0011602683 , kl(*beta): 10.5475089645 (0.0105475090), reconstruction loss: 0.0001055173\n",
      "Epoch [11001 / 20000] average reconstruction error: 0.0012713345 , kl(*beta): 10.3188660431 (0.0103188660), reconstruction loss: 0.0002394478\n",
      "Epoch [11101 / 20000] average reconstruction error: 0.0012197714 , kl(*beta): 11.1040692139 (0.0111040692), reconstruction loss: 0.0001093644\n",
      "Epoch [11201 / 20000] average reconstruction error: 0.0030489654 , kl(*beta): 12.9683098602 (0.0129683099), reconstruction loss: 0.0017521344\n",
      "Epoch [11301 / 20000] average reconstruction error: 0.0014217325 , kl(*beta): 11.9704637146 (0.0119704637), reconstruction loss: 0.0002246861\n",
      "Epoch [11401 / 20000] average reconstruction error: 0.0012606574 , kl(*beta): 11.4162126541 (0.0114162127), reconstruction loss: 0.0001190361\n",
      "Epoch [11501 / 20000] average reconstruction error: 0.0012856274 , kl(*beta): 11.7010766983 (0.0117010767), reconstruction loss: 0.0001155196\n",
      "Epoch [11601 / 20000] average reconstruction error: 0.0011577344 , kl(*beta): 10.4247890091 (0.0104247890), reconstruction loss: 0.0001152554\n",
      "Epoch [11701 / 20000] average reconstruction error: 0.0012637483 , kl(*beta): 11.7812347031 (0.0117812347), reconstruction loss: 0.0000856247\n",
      "Epoch [11801 / 20000] average reconstruction error: 0.0014621475 , kl(*beta): 13.1171662903 (0.0131171663), reconstruction loss: 0.0001504308\n",
      "Epoch [11901 / 20000] average reconstruction error: 0.0014721331 , kl(*beta): 12.2259177017 (0.0122259177), reconstruction loss: 0.0002495413\n",
      "Epoch [12001 / 20000] average reconstruction error: 0.0012626496 , kl(*beta): 11.5945986938 (0.0115945987), reconstruction loss: 0.0001031897\n",
      "Epoch [12101 / 20000] average reconstruction error: 0.0016879010 , kl(*beta): 11.5955909348 (0.0115955909), reconstruction loss: 0.0005283418\n",
      "Epoch [12201 / 20000] average reconstruction error: 0.0029899554 , kl(*beta): 13.7668735123 (0.0137668735), reconstruction loss: 0.0016132679\n",
      "Epoch [12301 / 20000] average reconstruction error: 0.0010810710 , kl(*beta): 9.9078314590 (0.0099078315), reconstruction loss: 0.0000902878\n",
      "Epoch [12401 / 20000] average reconstruction error: 0.0013839467 , kl(*beta): 11.8471099472 (0.0118471099), reconstruction loss: 0.0001992356\n",
      "Epoch [12501 / 20000] average reconstruction error: 0.0012655844 , kl(*beta): 11.7543618393 (0.0117543618), reconstruction loss: 0.0000901481\n",
      "Epoch [12601 / 20000] average reconstruction error: 0.0013422127 , kl(*beta): 11.5747592926 (0.0115747593), reconstruction loss: 0.0001847367\n",
      "Epoch [12701 / 20000] average reconstruction error: 0.0012072294 , kl(*beta): 10.6985466385 (0.0106985466), reconstruction loss: 0.0001373747\n",
      "Epoch [12801 / 20000] average reconstruction error: 0.0053281897 , kl(*beta): 13.6536465073 (0.0136536465), reconstruction loss: 0.0039628249\n",
      "Epoch [12901 / 20000] average reconstruction error: 0.0013310588 , kl(*beta): 11.9114818573 (0.0119114819), reconstruction loss: 0.0001399105\n",
      "Epoch [13001 / 20000] average reconstruction error: 0.0013039035 , kl(*beta): 11.7523980713 (0.0117523981), reconstruction loss: 0.0001286636\n",
      "Epoch [13101 / 20000] average reconstruction error: 0.0014931792 , kl(*beta): 12.8858406830 (0.0128858407), reconstruction loss: 0.0002045950\n",
      "Epoch [13201 / 20000] average reconstruction error: 0.0011732363 , kl(*beta): 10.6535682297 (0.0106535682), reconstruction loss: 0.0001078793\n",
      "Epoch [13301 / 20000] average reconstruction error: 0.0014686433 , kl(*beta): 11.7617415619 (0.0117617416), reconstruction loss: 0.0002924690\n",
      "Epoch [13401 / 20000] average reconstruction error: 0.0012493399 , kl(*beta): 11.4255954742 (0.0114255955), reconstruction loss: 0.0001067802\n",
      "Epoch [13501 / 20000] average reconstruction error: 0.0011605297 , kl(*beta): 10.4702297592 (0.0104702298), reconstruction loss: 0.0001135067\n",
      "Epoch [13601 / 20000] average reconstruction error: 0.0011878101 , kl(*beta): 10.8446352768 (0.0108446353), reconstruction loss: 0.0001033465\n",
      "Epoch [13701 / 20000] average reconstruction error: 0.0021789204 , kl(*beta): 13.4576808548 (0.0134576809), reconstruction loss: 0.0008331522\n",
      "Epoch [13801 / 20000] average reconstruction error: 0.0012047519 , kl(*beta): 11.0336080933 (0.0110336081), reconstruction loss: 0.0001013910\n",
      "Epoch [13901 / 20000] average reconstruction error: 0.0015604843 , kl(*beta): 11.6589499664 (0.0116589500), reconstruction loss: 0.0003945892\n",
      "Epoch [14001 / 20000] average reconstruction error: 0.0014371255 , kl(*beta): 12.4604944611 (0.0124604945), reconstruction loss: 0.0001910760\n",
      "Epoch [14101 / 20000] average reconstruction error: 0.0022202238 , kl(*beta): 12.5730453110 (0.0125730453), reconstruction loss: 0.0009629191\n",
      "Epoch [14201 / 20000] average reconstruction error: 0.0010874040 , kl(*beta): 9.9972179413 (0.0099972179), reconstruction loss: 0.0000876822\n",
      "Epoch [14301 / 20000] average reconstruction error: 0.0011704465 , kl(*beta): 10.7350204849 (0.0107350205), reconstruction loss: 0.0000969443\n",
      "Epoch [14401 / 20000] average reconstruction error: 0.0015715065 , kl(*beta): 11.7277337265 (0.0117277337), reconstruction loss: 0.0003987330\n",
      "Epoch [14501 / 20000] average reconstruction error: 0.0011353642 , kl(*beta): 10.5805329895 (0.0105805330), reconstruction loss: 0.0000773108\n",
      "Epoch [14601 / 20000] average reconstruction error: 0.0011160882 , kl(*beta): 10.3594890594 (0.0103594891), reconstruction loss: 0.0000801392\n",
      "Epoch [14701 / 20000] average reconstruction error: 0.0017715936 , kl(*beta): 12.9007066727 (0.0129007067), reconstruction loss: 0.0004815228\n",
      "Epoch [14801 / 20000] average reconstruction error: 0.0014198463 , kl(*beta): 12.7352073669 (0.0127352074), reconstruction loss: 0.0001463255\n",
      "Epoch [14901 / 20000] average reconstruction error: 0.0014009027 , kl(*beta): 12.1413572311 (0.0121413572), reconstruction loss: 0.0001867669\n",
      "Epoch [15001 / 20000] average reconstruction error: 0.0012335400 , kl(*beta): 11.4034310913 (0.0114034311), reconstruction loss: 0.0000931969\n",
      "Epoch [15101 / 20000] average reconstruction error: 0.0014600328 , kl(*beta): 11.6166741180 (0.0116166741), reconstruction loss: 0.0002983653\n",
      "Epoch [15201 / 20000] average reconstruction error: 0.0013143558 , kl(*beta): 12.2576045609 (0.0122576046), reconstruction loss: 0.0000885952\n",
      "Epoch [15301 / 20000] average reconstruction error: 0.0037805552 , kl(*beta): 12.8954248428 (0.0128954248), reconstruction loss: 0.0024910126\n",
      "Epoch [15401 / 20000] average reconstruction error: 0.0012907762 , kl(*beta): 10.7583485413 (0.0107583485), reconstruction loss: 0.0002149413\n",
      "Epoch [15501 / 20000] average reconstruction error: 0.0012527242 , kl(*beta): 11.5582342148 (0.0115582342), reconstruction loss: 0.0000969007\n",
      "Epoch [15601 / 20000] average reconstruction error: 0.0025235462 , kl(*beta): 13.7611516571 (0.0137611517), reconstruction loss: 0.0011474309\n",
      "Epoch [15701 / 20000] average reconstruction error: 0.0013783516 , kl(*beta): 11.9033830261 (0.0119033830), reconstruction loss: 0.0001880132\n",
      "Epoch [15801 / 20000] average reconstruction error: 0.0098750450 , kl(*beta): 12.9004614258 (0.0129004614), reconstruction loss: 0.0085849988\n",
      "Epoch [15901 / 20000] average reconstruction error: 0.0011752413 , kl(*beta): 10.7425453949 (0.0107425454), reconstruction loss: 0.0001009867\n",
      "Epoch [16001 / 20000] average reconstruction error: 0.0013110011 , kl(*beta): 11.8046403885 (0.0118046404), reconstruction loss: 0.0001305370\n",
      "Epoch [16101 / 20000] average reconstruction error: 0.0012036777 , kl(*beta): 11.2270169449 (0.0112270169), reconstruction loss: 0.0000809760\n",
      "Epoch [16201 / 20000] average reconstruction error: 0.0013177255 , kl(*beta): 10.6411277771 (0.0106411278), reconstruction loss: 0.0002536126\n",
      "Epoch [16301 / 20000] average reconstruction error: 0.0014163057 , kl(*beta): 12.1303662491 (0.0121303662), reconstruction loss: 0.0002032690\n",
      "Epoch [16401 / 20000] average reconstruction error: 0.0012667997 , kl(*beta): 11.3666775131 (0.0113666775), reconstruction loss: 0.0001301319\n",
      "Epoch [16501 / 20000] average reconstruction error: 0.0023458085 , kl(*beta): 12.6968047333 (0.0126968047), reconstruction loss: 0.0010761279\n",
      "Epoch [16601 / 20000] average reconstruction error: 0.0010994501 , kl(*beta): 10.2943191910 (0.0102943192), reconstruction loss: 0.0000700181\n",
      "Epoch [16701 / 20000] average reconstruction error: 0.0012908022 , kl(*beta): 11.2125614929 (0.0112125615), reconstruction loss: 0.0001695459\n",
      "Epoch [16801 / 20000] average reconstruction error: 0.0012260264 , kl(*beta): 11.3867179871 (0.0113867180), reconstruction loss: 0.0000873545\n",
      "Epoch [16901 / 20000] average reconstruction error: 0.0011905316 , kl(*beta): 10.9022839737 (0.0109022840), reconstruction loss: 0.0001003031\n",
      "Epoch [17001 / 20000] average reconstruction error: 0.0012751878 , kl(*beta): 11.7724122238 (0.0117724122), reconstruction loss: 0.0000979465\n",
      "Epoch [17101 / 20000] average reconstruction error: 0.0012163468 , kl(*beta): 11.0552577591 (0.0110552578), reconstruction loss: 0.0001108209\n",
      "Epoch [17201 / 20000] average reconstruction error: 0.0012853663 , kl(*beta): 11.6446038818 (0.0116446039), reconstruction loss: 0.0001209058\n",
      "Epoch [17301 / 20000] average reconstruction error: 0.0012835813 , kl(*beta): 11.7725803375 (0.0117725803), reconstruction loss: 0.0001063232\n",
      "Epoch [17401 / 20000] average reconstruction error: 0.0013570457 , kl(*beta): 12.0762398148 (0.0120762398), reconstruction loss: 0.0001494216\n",
      "Epoch [17501 / 20000] average reconstruction error: 0.0012594107 , kl(*beta): 12.0340137100 (0.0120340137), reconstruction loss: 0.0000560092\n",
      "Epoch [17601 / 20000] average reconstruction error: 0.0016015634 , kl(*beta): 14.2722901154 (0.0142722901), reconstruction loss: 0.0001743343\n",
      "Epoch [17701 / 20000] average reconstruction error: 0.0012876127 , kl(*beta): 11.9943426895 (0.0119943427), reconstruction loss: 0.0000881783\n",
      "Epoch [17801 / 20000] average reconstruction error: 0.0011260272 , kl(*beta): 10.7983327103 (0.0107983327), reconstruction loss: 0.0000461938\n",
      "Epoch [17901 / 20000] average reconstruction error: 0.0031576135 , kl(*beta): 12.2605240250 (0.0122605240), reconstruction loss: 0.0019315610\n",
      "Epoch [18001 / 20000] average reconstruction error: 0.0014003397 , kl(*beta): 11.8054043198 (0.0118054043), reconstruction loss: 0.0002197991\n",
      "Epoch [18101 / 20000] average reconstruction error: 0.0013807391 , kl(*beta): 12.8562657547 (0.0128562658), reconstruction loss: 0.0000951125\n",
      "Epoch [18201 / 20000] average reconstruction error: 0.0038073398 , kl(*beta): 13.1996598434 (0.0131996598), reconstruction loss: 0.0024873737\n",
      "Epoch [18301 / 20000] average reconstruction error: 0.0015871710 , kl(*beta): 10.8950038147 (0.0108950038), reconstruction loss: 0.0004976705\n",
      "Epoch [18401 / 20000] average reconstruction error: nan , kl(*beta): nan (nan), reconstruction loss: nan\n",
      "Epoch [18501 / 20000] average reconstruction error: nan , kl(*beta): nan (nan), reconstruction loss: nan\n",
      "Epoch [18601 / 20000] average reconstruction error: nan , kl(*beta): nan (nan), reconstruction loss: nan\n",
      "Epoch [18701 / 20000] average reconstruction error: nan , kl(*beta): nan (nan), reconstruction loss: nan\n",
      "Epoch [18801 / 20000] average reconstruction error: nan , kl(*beta): nan (nan), reconstruction loss: nan\n",
      "Epoch [18901 / 20000] average reconstruction error: nan , kl(*beta): nan (nan), reconstruction loss: nan\n",
      "Epoch [19001 / 20000] average reconstruction error: nan , kl(*beta): nan (nan), reconstruction loss: nan\n",
      "Epoch [19101 / 20000] average reconstruction error: nan , kl(*beta): nan (nan), reconstruction loss: nan\n",
      "Epoch [19201 / 20000] average reconstruction error: nan , kl(*beta): nan (nan), reconstruction loss: nan\n",
      "Epoch [19301 / 20000] average reconstruction error: nan , kl(*beta): nan (nan), reconstruction loss: nan\n",
      "Epoch [19401 / 20000] average reconstruction error: nan , kl(*beta): nan (nan), reconstruction loss: nan\n",
      "Epoch [19501 / 20000] average reconstruction error: nan , kl(*beta): nan (nan), reconstruction loss: nan\n",
      "Epoch [19601 / 20000] average reconstruction error: nan , kl(*beta): nan (nan), reconstruction loss: nan\n",
      "Epoch [19701 / 20000] average reconstruction error: nan , kl(*beta): nan (nan), reconstruction loss: nan\n",
      "Epoch [19801 / 20000] average reconstruction error: nan , kl(*beta): nan (nan), reconstruction loss: nan\n",
      "Epoch [19901 / 20000] average reconstruction error: nan , kl(*beta): nan (nan), reconstruction loss: nan\n"
     ]
    }
   ],
   "source": [
    "torch.set_printoptions(precision=10)\n",
    "p = 10\n",
    "eps = 2\n",
    "t_list = os.listdir(\"data/paper/IntraP\" + str(p) + \"eps0\" + str(eps) )[:100]\n",
    "dataset = tDataset(t_list, \"data/paper/IntraP\" + str(p) + \"eps0\" + str(eps) )\n",
    "data_loader = DataLoader(dataset, batch_size = batch_size, shuffle=True, collate_fn=my_collate)\n",
    "\n",
    "\n",
    "mult = mv.numberNodes(data_loader, batch_size)\n",
    "feature_size = 64\n",
    "latent_size = feature_size\n",
    "hidden_size_encoder = 512\n",
    "hidden_size_decoder = 256\n",
    "\n",
    "Grassencoder = mv.GRASSEncoder(input_size = 4, feature_size=feature_size, hidden_size=hidden_size_encoder)\n",
    "Grassencoder = Grassencoder.to(device)\n",
    "Grassdecoder = mv.GRASSDecoder(latent_size=latent_size, hidden_size=hidden_size_decoder, mult = mult)\n",
    "Grassdecoder = Grassdecoder.to(device)\n",
    "\n",
    "mv.setLevel(data_loader)\n",
    "\n",
    "##loop parameters\n",
    "epochs = 20000\n",
    "learning_rate = 1e-4\n",
    "params = list(Grassencoder.parameters()) + list(Grassdecoder.parameters()) \n",
    "opt = torch.optim.Adam(params, lr=learning_rate) \n",
    "total_paramse = sum(param.numel() for param in Grassencoder.parameters())\n",
    "total_paramsd = sum(param.numel() for param in Grassdecoder.parameters())\n",
    "print(\"total parameters encoder \", total_paramse)\n",
    "print(\"total parameters decoder\", total_paramsd)\n",
    "print(\"total parameters\", total_paramse + total_paramsd)\n",
    "\n",
    "Grassencoder.train()\n",
    "Grassdecoder.train()\n",
    "\n",
    "config = {\n",
    "\"learning_rate\": learning_rate,\n",
    "\"epochs\": epochs,\n",
    "\"batch_size\": batch_size,\n",
    "\"dataset\": t_list,\n",
    "\"number of trees\": len(data_loader)*batch_size,\n",
    "\"optim\": opt,\n",
    "\"latent_size\" : latent_size,\n",
    "\"params\":total_paramse + total_paramsd,\n",
    "\"prof\": p,\n",
    "}\n",
    "wandb.init(project=\"MIA\", entity=\"paufeldman\", config = config)\n",
    "\n",
    "train_model(epochs, data_loader, Grassencoder, Grassdecoder, opt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('py_torc')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8f3e717cd274da89498094fde320e6eab1bf0f52911d27cf47473187acb3fe8a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
